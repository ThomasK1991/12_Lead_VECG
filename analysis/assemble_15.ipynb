{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Disentangled Representational Learning of Single Lead Electrocardiogram Signals using Variational Autoencoder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook evaluates the properties and accuracy of the trained VECG model in several aspects. The structure follows the three main objectives:\n",
    "\n",
    "1. investigation of **Disentanglement**\n",
    "2. evaluation of **Anomaly Detection** accuracy and explainability\n",
    "3. improvements through the use of **Personalization**\n",
    "\n",
    "The results are summarized in a corresponding article, which the authors ask to be cited when using the results of this work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General\n",
    "\n",
    "This section of for imports, getting an overview of all experiments, and loading the most suitable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-05 16:27:27.653374: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-05 16:27:27.659114: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-05 16:27:27.699660: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-05 16:27:27.699704: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-05 16:27:27.699732: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-05 16:27:27.707801: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-05 16:27:27.713265: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-05 16:27:29.216676: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Project Root: /users/newc6477/VAE/12_Lead_VECG\n",
      "‚úÖ Updated sys.path:\n",
      "['/users/newc6477/Benchmark_ISIBrno/ENTER/envs/my_env/lib/python310.zip', '/users/newc6477/Benchmark_ISIBrno/ENTER/envs/my_env/lib/python3.10', '/users/newc6477/Benchmark_ISIBrno/ENTER/envs/my_env/lib/python3.10/lib-dynload', '', '/users/newc6477/Benchmark_ISIBrno/ENTER/envs/my_env/lib/python3.10/site-packages', '/users/newc6477/Benchmark_ISIBrno/ENTER/envs/my_env/lib/python3.10/site-packages/setuptools/_vendor', '/users/newc6477/VAE/12_Lead_VECG', '/users/newc6477/VAE/12_Lead_VECG/src']\n",
      "‚úÖ Successfully imported `Helper` and `Visualizations`\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "from absl import logging as absl_logging\n",
    "import json\n",
    "import tensorflow as tf\n",
    "\n",
    "# ‚úÖ Ensure Correct TensorFlow Configuration\n",
    "os.environ['TFDS_DATA_DIR'] = r\"/data/newc6477/VAE/Single_Beat/15_percent_Physionet/\"\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = \"0\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n",
    "\n",
    "# ‚úÖ Ensure Correct Working Directory\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "print(f\"üìÇ Project Root: {PROJECT_ROOT}\")\n",
    "\n",
    "# ‚úÖ Ensure `src/` is in Python's Path\n",
    "SRC_DIR = os.path.join(PROJECT_ROOT, \"src\")\n",
    "if SRC_DIR not in sys.path:\n",
    "    sys.path.append(SRC_DIR)\n",
    "\n",
    "print(f\"‚úÖ Updated sys.path:\\n{sys.path}\")\n",
    "\n",
    "# ‚úÖ Suppress Warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "absl_logging.set_verbosity(absl_logging.ERROR)\n",
    "\n",
    "# ‚úÖ Import Modules\n",
    "try:\n",
    "    from src.utils.helper import Helper\n",
    "    from src.evaluate.visualizations import Visualizations\n",
    "    print(\"‚úÖ Successfully imported `Helper` and `Visualizations`\")\n",
    "except ModuleNotFoundError as e:\n",
    "    print(f\"‚ùå Import Error: {e}\")\n",
    "    print(\"üîç Check if `src/` has `__init__.py` and is in `sys.path`.\")\n",
    "\n",
    "# ‚úÖ Import Other Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from neurokit2.signal import signal_smooth\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The resolution for saving images\n",
    "DPI = 300\n",
    "\n",
    "# The source path of the experiments and models\n",
    "PATH = r\"/users/newc6477/VAE/12_Lead_VECG/results/full_15/test_is_split1\"\n",
    "\n",
    "# Some operations take some time in computation.\n",
    "# Therefore, the stored intermediate results can be used to skip the respective computation.\n",
    "USE_PRECOMPUTED = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever a dataset is used within this work, e.g., for loading or embedding, it needs to be declared as a dictionary. The keys are a name (array of datasets to be loaded), the split, the shuffle size, and the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loading model for I from /users/newc6477/VAE/12_Lead_VECG/results/full_15/test_is_split1/I/2025-04-02_22-42-54/model_best.keras\n",
      "‚úÖ Loading model for II from /users/newc6477/VAE/12_Lead_VECG/results/full_15/test_is_split1/II/2025-04-03_02-02-15/model_best.keras\n",
      "‚úÖ Loading model for III from /users/newc6477/VAE/12_Lead_VECG/results/full_15/test_is_split1/III/2025-04-03_07-36-41/model_best.keras\n",
      "‚úÖ Loading model for aVR from /users/newc6477/VAE/12_Lead_VECG/results/full_15/test_is_split1/aVR/2025-04-03_11-04-51/model_best.keras\n",
      "‚úÖ Loading model for aVF from /users/newc6477/VAE/12_Lead_VECG/results/full_15/test_is_split1/aVF/2025-04-03_15-57-48/model_best.keras\n",
      "‚úÖ Loading model for V1 from /users/newc6477/VAE/12_Lead_VECG/results/full_15/test_is_split1/V1/2025-04-03_21-35-05/model_best.keras\n",
      "‚úÖ Loading model for V2 from /users/newc6477/VAE/12_Lead_VECG/results/full_15/test_is_split1/V2/2025-04-03_14-48-29/model_best.keras\n",
      "‚úÖ Loading model for V3 from /users/newc6477/VAE/12_Lead_VECG/results/full_15/test_is_split1/V3/2025-04-03_15-47-52/model_best.keras\n",
      "‚úÖ Loading model for V4 from /users/newc6477/VAE/12_Lead_VECG/results/full_15/test_is_split1/V4/2025-04-02_23-37-54/model_best.keras\n",
      "‚úÖ Loading model for V5 from /users/newc6477/VAE/12_Lead_VECG/results/full_15/test_is_split1/V5/2025-04-03_02-59-20/model_best.keras\n",
      "‚úÖ Loading model for V6 from /users/newc6477/VAE/12_Lead_VECG/results/full_15/test_is_split1/V6/2025-04-03_07-18-08/model_best.keras\n"
     ]
    }
   ],
   "source": [
    "BASE = '/users/newc6477/VAE/12_Lead_VECG/results/full_15/test_is_split1'\n",
    "\n",
    "# Path to the JSON file containing best timestamps for each lead\n",
    "json_path = \"best_folders.json\"\n",
    "\n",
    "# Load best folder names from JSON\n",
    "with open(json_path, \"r\") as f:\n",
    "    best_folders = json.load(f)\n",
    "\n",
    "# Load models dynamically into a dictionary\n",
    "models = {}\n",
    "for lead_key, folder in best_folders.items():\n",
    "    # Strip \"lead_\" prefix ‚Üí \"lead_I\" ‚Üí \"I\"\n",
    "    lead = lead_key.replace(\"lead_\", \"\")\n",
    "    \n",
    "    model_path = os.path.join(BASE, lead, folder, \"model_best.keras\")\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"‚úÖ Loading model for {lead} from {model_path}\")\n",
    "        models[lead] = tf.keras.models.load_model(model_path, compile=False)\n",
    "    else:\n",
    "        print(f\"‚ùå Warning: Model not found for {lead} at {model_path}\")\n",
    "\n",
    "\n",
    "# If needed, convert to a list\n",
    "model_list = list(models.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_splits = ['split2', 'split3', 'split4', 'split5']\n",
    "dataset_config = {\n",
    "    'name': ['physionet'],\n",
    "    'split': train_splits,\n",
    "    'shuffle_size': 1024,\n",
    "    'batch_size': 1024,\n",
    "}\n",
    "test_splits = ['split1']\n",
    "dataset_test = {\n",
    "    'name': ['physionet'],\n",
    "    'split': test_splits,\n",
    "    'shuffle_size': 1024,\n",
    "    'batch_size': 1024,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ Loading dataset: physionet\n",
      "  ‚§∑ Using splits: ['split2', 'split3', 'split4', 'split5']\n",
      "üîç Processing lead I...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute '_encoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_physionet_train, ld \u001b[38;5;241m=\u001b[39m \u001b[43mHelper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#df_physionet_validation, _ = Helper.get_embeddings(model, dataset_physionet_validation)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m df_physionet_test, _ \u001b[38;5;241m=\u001b[39m Helper\u001b[38;5;241m.\u001b[39mget_embeddings(models, dataset_test)\n",
      "File \u001b[0;32m~/VAE/12_Lead_VECG/src/utils/helper.py:438\u001b[0m, in \u001b[0;36mHelper.get_embeddings\u001b[0;34m(models, datasets)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lead, model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(lead_names, models):\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müîç Processing lead \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlead\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 438\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encoder\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(Helper\u001b[38;5;241m.\u001b[39mdata_generator([train], lead\u001b[38;5;241m=\u001b[39mlead, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m    439\u001b[0m     df \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Extract embeddings\u001b[39;00m\n\u001b[1;32m    440\u001b[0m     ld \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute '_encoder'"
     ]
    }
   ],
   "source": [
    "df_physionet_train, ld = Helper.get_embeddings(models, dataset_config)\n",
    "#df_physionet_validation, _ = Helper.get_embeddings(model, dataset_physionet_validation)\n",
    "df_physionet_test, _ = Helper.get_embeddings(models, dataset_test)\n",
    "\n",
    "df_physionet_train = df_physionet_train[0]\n",
    "#df_physionet_validation = df_physionet_validation[0]\n",
    "df_physionet_test = df_physionet_test[0]\n",
    "print(type(df_physionet_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Performing Grid Search...\n",
      "‚úÖ Best k found: {'estimator__n_neighbors': 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Prepare feature matrix and labels\n",
    "X_train = df_physionet_train.iloc[:, :ld].values  \n",
    "X_test = df_physionet_test.iloc[:, :ld].values  \n",
    "y_train = np.array(df_physionet_train['diagnostic'].tolist(), dtype=int)  \n",
    "y_test = np.array(df_physionet_test['diagnostic'].tolist(), dtype=int)  \n",
    "\n",
    "# Define KNN model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Wrap it inside MultiOutputClassifier\n",
    "multi_label_knn = MultiOutputClassifier(knn, n_jobs=-1)\n",
    "\n",
    "# Define Grid Search parameters for 'k'\n",
    "param_grid = {\n",
    "    \"estimator__n_neighbors\": [3, 5, 7, 9, 11]  # Testing different values of k\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    multi_label_knn, param_grid, scoring=\"accuracy\", cv=5, n_jobs=-1\n",
    ")\n",
    "\n",
    "# Perform the Grid Search\n",
    "print(\"üîç Performing Grid Search...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameter\n",
    "print(\"‚úÖ Best k found:\", grid_search.best_params_)\n",
    "\n",
    "# Use the best model\n",
    "best_knn = grid_search.best_estimator_\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred = best_knn.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Overall Accuracy: 0.28701067615658366\n",
      "‚úÖ F1 Score (Macro): 0.18481069405830997\n",
      "‚úÖ F1 Score (Micro): 0.38977989160491094\n",
      "‚úÖ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.21      0.27       791\n",
      "           1       0.44      0.35      0.39      1155\n",
      "           2       0.04      0.00      0.01       272\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.38      0.12      0.18       124\n",
      "           5       0.67      0.53      0.60       580\n",
      "           6       0.26      0.13      0.18       319\n",
      "           7       0.03      0.02      0.02       186\n",
      "           8       0.31      0.30      0.30       740\n",
      "           9       0.29      0.18      0.22       249\n",
      "          10       0.00      0.00      0.00        30\n",
      "          11       0.03      0.01      0.01       208\n",
      "          12       0.03      0.01      0.02       222\n",
      "          13       0.00      0.00      0.00       128\n",
      "          14       0.53      0.56      0.55      3135\n",
      "          15       0.11      0.03      0.05       574\n",
      "          16       0.15      0.66      0.24        89\n",
      "          17       0.10      0.01      0.02        99\n",
      "          18       0.07      0.10      0.08       164\n",
      "          19       0.14      0.06      0.08       261\n",
      "          20       0.05      0.03      0.04       203\n",
      "          21       0.07      0.09      0.08       296\n",
      "          22       0.58      0.74      0.65      1247\n",
      "          23       0.55      0.72      0.63      1473\n",
      "          24       0.18      0.15      0.16      1229\n",
      "          25       0.03      0.04      0.03       288\n",
      "\n",
      "   micro avg       0.40      0.38      0.39     14068\n",
      "   macro avg       0.21      0.20      0.18     14068\n",
      "weighted avg       0.37      0.38      0.37     14068\n",
      " samples avg       0.38      0.35      0.35     14068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "\n",
    "# Calculate accuracy for each label separately\n",
    "accuracy_per_label = (y_pred == y_test).mean(axis=0)\n",
    "\n",
    "# Calculate overall accuracy (percentage of completely correct multi-label predictions)\n",
    "overall_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Compute F1-score (macro & micro average)\n",
    "f1_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "f1_micro = f1_score(y_test, y_pred, average=\"micro\")\n",
    "\n",
    "# Generate classification report\n",
    "class_report = classification_report(y_test, y_pred, target_names=[str(i) for i in range(y_test.shape[1])])\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"‚úÖ Overall Accuracy:\", overall_accuracy)\n",
    "print(\"‚úÖ F1 Score (Macro):\", f1_macro)\n",
    "print(\"‚úÖ F1 Score (Micro):\", f1_micro)\n",
    "print(\"‚úÖ Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   7%|‚ñã         | 1/15 [00:02<00:32,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Epoch 1/15 - Train Loss: 0.1199 | Val Loss: 0.0866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  13%|‚ñà‚ñé        | 2/15 [00:04<00:30,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Epoch 2/15 - Train Loss: 0.0770 | Val Loss: 0.0735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|‚ñà‚ñà        | 3/15 [00:07<00:28,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Epoch 3/15 - Train Loss: 0.0631 | Val Loss: 0.0654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  27%|‚ñà‚ñà‚ñã       | 4/15 [00:09<00:25,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Epoch 4/15 - Train Loss: 0.0529 | Val Loss: 0.0591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  33%|‚ñà‚ñà‚ñà‚ñé      | 5/15 [00:11<00:23,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Epoch 5/15 - Train Loss: 0.0453 | Val Loss: 0.0562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|‚ñà‚ñà‚ñà‚ñà      | 6/15 [00:14<00:21,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Epoch 6/15 - Train Loss: 0.0396 | Val Loss: 0.0536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 7/15 [00:16<00:18,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Epoch 7/15 - Train Loss: 0.0351 | Val Loss: 0.0530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 8/15 [00:18<00:16,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Epoch 8/15 - Train Loss: 0.0314 | Val Loss: 0.0528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 9/15 [00:21<00:14,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Epoch 9/15 - Train Loss: 0.0282 | Val Loss: 0.0533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 10/15 [00:23<00:11,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Epoch 10/15 - Train Loss: 0.0256 | Val Loss: 0.0517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 11/15 [00:25<00:09,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Epoch 11/15 - Train Loss: 0.0233 | Val Loss: 0.0529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 12/15 [00:28<00:07,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Epoch 12/15 - Train Loss: 0.0214 | Val Loss: 0.0530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 13/15 [00:30<00:04,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Epoch 13/15 - Train Loss: 0.0193 | Val Loss: 0.0550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 14/15 [00:32<00:02,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Epoch 14/15 - Train Loss: 0.0177 | Val Loss: 0.0561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:35<00:00,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Epoch 15/15 - Train Loss: 0.0133 | Val Loss: 0.0545\n",
      "üìà Saved training+validation loss plot as 'vae_train_val_loss.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAHqCAYAAACZcdjsAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAklNJREFUeJzs3Xd4FOXax/Hv7qaTnpBCDR1C6E06Kk0RARWwoIDHLjYUj3hUxHKwv3hExXLsB8WKDZGIIlV6kd57CklIAqRn5/1jk4WQBDYh2U35fa5rJDv7zMw9Txace59mMgzDQERERERE5CKYXR2AiIiIiIhUf0osRERERETkoimxEBERERGRi6bEQkRERERELpoSCxERERERuWhKLERERERE5KIpsRARERERkYumxEJERERERC6aEgsREREREbloSixExOUmTJhAVFRUuY59+umnMZlMFRtQNbd48WJMJhOLFy+273O0jg8cOIDJZOKjjz6q0JiioqKYMGFChZ5T5HwK/x58/fXXrg5FpNZQYiEipTKZTA5tZz/A1jZWq5VXXnmFFi1a4O3tTbNmzbj77rs5deqUQ8e3b9+eRo0aYRhGqWV69+5NeHg4eXl5FRV2pVixYgVPP/00qamprg7F7qOPPsJkMrF27VpXh+KQ5cuXM2rUKMLDw/H09CQqKoo777yTQ4cOuTq0Ygof3EvbvvjiC1eHKCJO5ubqAESk6vr000+LvP7kk0+IjY0ttr9NmzYXdZ333nsPq9VarmOfeOIJHnvssYu6/sV4/fXXmTJlCiNHjmTKlCkcPHiQzz//nH/+85/4+vpe8PibbrqJxx57jKVLl9KvX79i7x84cICVK1cyadIk3NzK/0/2xdSxo1asWMH06dOZMGECgYGBRd7buXMnZrO+yzqfN954gwceeICmTZty3333ERkZyfbt23n//feZO3cu8+fPp1evXq4Os5j777+fbt26Fdvfs2dPF0QjIq6kxEJESjVu3Lgir//66y9iY2OL7T9XRkYGPj4+Dl/H3d29XPEBuLm5XdQD98X64osvaNu2Ld9++629S9azzz7r8EP8jTfeyNSpU5kzZ06JicXnn3+OYRjcdNNNFxXnxdRxRfD09HTp9au65cuX8+CDD9KnTx8WLFhQ5O/P3XffTe/evbnuuuvYunUrQUFBTovr9OnT1KlT57xl+vbty3XXXeekiESkKtPXRyJyUQYMGEBMTAzr1q2jX79++Pj48PjjjwPw/fffM2zYMOrVq4enpyfNmjXj2WefJT8/v8g5zu3/X9jP/5VXXuHdd9+lWbNmeHp60q1bN9asWVPk2JLGWJhMJiZNmsS8efOIiYnB09OTtm3bsmDBgmLxL168mK5du+Ll5UWzZs145513yjRuw2w2Y7Vai5Q3m80OJzsNGzakX79+fP311+Tm5hZ7f86cOTRr1owePXpw8OBB7rnnHlq1aoW3tzchISGMHj2aAwcOXPA6JY2xSE1NZcKECQQEBBAYGMj48eNL7Ma0efNmJkyYQNOmTfHy8iIiIoJbb72V5ORke5mnn36aKVOmANCkSRN7d5jC2EoaY7Fv3z5Gjx5NcHAwPj4+XHLJJfz8889FyhR2t/nyyy95/vnnadCgAV5eXlx++eXs2bPngvftqA0bNnDFFVfg7++Pr68vl19+OX/99VeRMrm5uUyfPp0WLVrg5eVFSEgIffr0ITY21l4mPj6eiRMn0qBBAzw9PYmMjGTEiBEX/B09++yzmEwmPv7442JJebNmzXjppZeIi4vjnXfeAeCVV17BZDJx8ODBYueaOnUqHh4enDhxwr5v1apVDB06lICAAHx8fOjfvz/Lly8vclzh537btm3ceOONBAUF0adPH4fq70IK/07+73//o1WrVnh5edGlSxeWLFlSrKwjvwuwfX4feughoqKi8PT0pEGDBtxyyy0kJSUVKWe1Wi/42dm9ezfXXnstEREReHl50aBBA66//nrS0tIq5P5Fagu1WIjIRUtOTuaKK67g+uuvZ9y4cYSHhwO2/u2+vr5MnjwZX19ffv/9d5566inS09N5+eWXL3jeOXPmcPLkSe68805MJhMvvfQS11xzDfv27bvgN/DLli3j22+/5Z577sHPz4///Oc/XHvttRw6dIiQkBDA9gAzdOhQIiMjmT59Ovn5+TzzzDPUrVvX4XufOHEid955J++88w533nmnw8ed7aabbuKOO+7g119/5aqrrrLv//vvv9myZQtPPfUUAGvWrGHFihVcf/31NGjQgAMHDvD2228zYMAAtm3bVqZWIsMwGDFiBMuWLeOuu+6iTZs2fPfdd4wfP75Y2djYWPbt28fEiROJiIhg69atvPvuu2zdupW//voLk8nENddcw65du/j888/5v//7P0JDQwFKrcuEhAR69epFRkYG999/PyEhIXz88cdcffXVfP3114waNapI+RdeeAGz2cwjjzxCWloaL730EjfddBOrVq1y+J5Ls3XrVvr27Yu/vz+PPvoo7u7uvPPOOwwYMIA///yTHj16ALYH7xkzZnDbbbfRvXt30tPTWbt2LevXr2fQoEEAXHvttWzdupX77ruPqKgoEhMTiY2N5dChQ6UOns/IyGDRokX07duXJk2alFhm7Nix3HHHHfz000889thjjBkzhkcffZQvv/zSntAV+vLLLxk8eLC9ZeP333/niiuuoEuXLkybNg2z2cyHH37IZZddxtKlS+nevXuR40ePHk2LFi3497//fd6xP4VOnjxZ7GEeICQkpEjC/eeffzJ37lzuv/9+PD09eeuttxg6dCirV68mJiamTL+LU6dO0bdvX7Zv386tt95K586dSUpK4ocffuDIkSP2zx9c+LOTk5PDkCFDyM7O5r777iMiIoKjR4/y008/kZqaSkBAwAXrQEQKGCIiDrr33nuNc//Z6N+/vwEYs2fPLlY+IyOj2L4777zT8PHxMbKysuz7xo8fbzRu3Nj+ev/+/QZghISEGCkpKfb933//vQEYP/74o33ftGnTisUEGB4eHsaePXvs+zZt2mQAxhtvvGHfN3z4cMPHx8c4evSofd/u3bsNNze3YucszWOPPWZ4eHgYFovF+Pbbbx065lwpKSmGp6enccMNNxQ7N2Ds3LnTMIyS63PlypUGYHzyySf2fX/88YcBGH/88Yd937l1PG/ePAMwXnrpJfu+vLw8o2/fvgZgfPjhh/b9JV33888/NwBjyZIl9n0vv/yyARj79+8vVr5x48bG+PHj7a8ffPBBAzCWLl1q33fy5EmjSZMmRlRUlJGfn1/kXtq0aWNkZ2fby77++usGYPz999/FrnW2Dz/80ACMNWvWlFpm5MiRhoeHh7F37177vmPHjhl+fn5Gv3797Ps6dOhgDBs2rNTznDhxwgCMl19++bwxnWvjxo0GYDzwwAPnLde+fXsjODjY/rpnz55Gly5dipRZvXp1kc+D1Wo1WrRoYQwZMsSwWq32chkZGUaTJk2MQYMG2fcV/l0693NYmsLfTWlbXFycvWzhvrVr19r3HTx40PDy8jJGjRpl3+fo7+Kpp54ygBL/zhXep6OfnQ0bNhiA8dVXXzl03yJSOnWFEpGL5unpycSJE4vt9/b2tv9c+K1m3759ycjIYMeOHRc879ixY4v0J+/bty9g60JzIQMHDqRZs2b21+3bt8ff399+bH5+Pr/99hsjR46kXr169nLNmzfniiuuuOD5Af7zn//w2muvsXz5cm644Qauv/56Fi5cWKSMp6cnTz755HnPExQUxJVXXskPP/zA6dOnAVuLwhdffEHXrl1p2bIlULQ+c3NzSU5Opnnz5gQGBrJ+/XqHYi40f/583NzcuPvuu+37LBYL9913X7GyZ183KyuLpKQkLrnkEoAyX/fs63fv3r1IVxtfX1/uuOMODhw4wLZt24qUnzhxIh4eHvbXZfksnE9+fj4LFy5k5MiRNG3a1L4/MjKSG2+8kWXLlpGeng5AYGAgW7duZffu3SWey9vbGw8PDxYvXlykG9KFnDx5EgA/P7/zlvPz87PHAra/H+vWrWPv3r32fXPnzsXT05MRI0YAsHHjRnbv3s2NN95IcnIySUlJJCUlcfr0aS6//HKWLFlSbDzQXXfd5XDsAE899RSxsbHFtuDg4CLlevbsSZcuXeyvGzVqxIgRI/j111/Jz88v0+/im2++oUOHDsVatoBi3Rgv9NkpbJH49ddfycjIKNO9i0hRSixE5KLVr1+/yP+4C23dupVRo0YREBCAv78/devWtQ/8dqTvcqNGjYq8LkwyHHloO/fYwuMLj01MTCQzM5PmzZsXK1fSvnNlZmYybdo0brvtNrp27WrvWjJq1CiWLVsG2Ppt5+Tk2LtvnM9NN93E6dOn+f777wHbDEsHDhwoMmg7MzOTp556ioYNG+Lp6UloaCh169YlNTW1zH3BDx48SGRkZLGZq1q1alWsbEpKCg888ADh4eF4e3tTt25de5ed8vZBP3jwYInXKpxh7NyxAxfzWTif48ePk5GRUWosVquVw4cPA/DMM8+QmppKy5YtadeuHVOmTGHz5s328p6enrz44ov88ssvhIeH069fP1566SXi4+PPG0NhQlGYYJTm5MmTRZKP0aNHYzabmTt3LmBLRr/66iv7+ATAngSNHz+eunXrFtnef/99srOzi/0OS+uOVZp27doxcODAYtu5/ya0aNGi2LEtW7YkIyOD48ePl+l3sXfvXnv3qQu50GenSZMmTJ48mffff5/Q0FCGDBnCm2++qfEVIuWgxEJELtrZ32gXSk1NpX///mzatIlnnnmGH3/8kdjYWF588UUAh2ZNslgsJe43HOj3fTHHOmL79u2kpqbav7l3c3Pj66+/JiYmhmHDhrF+/XreffddwsLC7P3vz+eqq64iICCAOXPmALbxJRaLheuvv95e5r777uP5559nzJgxfPnllyxcuJDY2FhCQkIqdSrZMWPG8N5773HXXXfx7bffsnDhQvtA+MqewrZQZf8+HdGvXz/27t3LBx98QExMDO+//z6dO3fm/ffft5d58MEH2bVrFzNmzMDLy4snn3ySNm3asGHDhlLP27x5c9zc3IokKefKzs5m586dREdH2/fVq1ePvn378uWXXwK2WdsOHTrE2LFj7WUKfz8vv/xyia0KsbGxxZLLkv4+V2eOfHZeffVVNm/ezOOPP05mZib3338/bdu25ciRI84KU6RG0OBtEakUixcvJjk5mW+//bbINKr79+93YVRnhIWF4eXlVeLMQo7MNlTY3aLwG1SAOnXqMH/+fPr06cOQIUPIysriueeec2iqVU9PT6677jo++eQTEhIS+Oqrr7jsssuIiIiwl/n6668ZP348r776qn1fVlZWuRaka9y4MYsWLeLUqVNFHix37txZpNyJEydYtGgR06dPtw8iB0rsDlSWFdAbN25c7FqAvYtc48aNHT7Xxahbty4+Pj6lxmI2m2nYsKF9X3BwMBMnTmTixImcOnWKfv368fTTT3PbbbfZyzRr1oyHH36Yhx9+mN27d9OxY0deffVVPvvssxJjqFOnDpdeeim///47Bw8eLPHev/zyS7Kzs4sM7gdbd6h77rmHnTt3MnfuXHx8fBg+fHiRWAD8/f0ZOHBg2SqngpX0mdm1axc+Pj72Qf6O/i6aNWvGli1bKjS+du3a0a5dO5544glWrFhB7969mT17Ns8991yFXkekJlOLhYhUisJvCc/+VjAnJ4e33nrLVSEVYbFYGDhwIPPmzePYsWP2/Xv27OGXX3654PHt2rUjPDycWbNmkZiYaN8fEhLChx9+SFJSEpmZmUUe8i7kpptuIjc3lzvvvJPjx48XW7vCYrEU+4b+jTfeKDZ9ryOuvPJK8vLyePvtt+378vPzeeONN4pdE4q3DMycObPYOQvXO3Ak0bnyyitZvXo1K1eutO87ffo07777LlFRUUW+ma9MFouFwYMH8/333xeZEjYhIYE5c+bQp08fe7eis6fXBduYkObNm5OdnQ3YZnfKysoqUqZZs2b4+fnZy5TmiSeewDAMJkyYQGZmZpH39u/fz6OPPkpkZGSxmceuvfZaLBYLn3/+OV999RVXXXVVkXUnunTpQrNmzXjllVdKXA3++PHj542rIq1cubLImJzDhw/z/fffM3jwYCwWS5l+F9deey2bNm3iu+++K3adsrZipaenF1vVvl27dpjN5gv+3kSkKLVYiEil6NWrF0FBQYwfP577778fk8nEp59+6tSuKxfy9NNPs3DhQnr37s3dd99Nfn4+s2bNIiYmho0bN573WDc3N2bNmsXYsWNp164dd955J40bN2b79u188MEHtGvXjiNHjjBixAiWL19ufyA6n/79+9OgQQO+//57vL29ueaaa4q8f9VVV/Hpp58SEBBAdHQ0K1eu5LfffrNPn1sWw4cPp3fv3jz22GMcOHCA6Ohovv3222L9yv39/e1jBXJzc6lfvz4LFy4sseWpcGDuv/71L66//nrc3d0ZPnx4iQusPfbYY3z++edcccUV3H///QQHB/Pxxx+zf/9+vvnmmwpfpfuDDz4ocR2TBx54gOeee47Y2Fj69OnDPffcg5ubG++88w7Z2dm89NJL9rLR0dEMGDCALl26EBwczNq1a/n666+ZNGkSYPv2/fLLL2fMmDFER0fj5ubGd999R0JCQpEubSXp168fr7zyCpMnT6Z9+/ZMmDCByMhIduzYYV81ff78+cUWxwsLC+PSSy/ltdde4+TJk0W6QYFtTZX333+fK664grZt2zJx4kTq16/P0aNH+eOPP/D39+fHH38sb7UCsHTp0mIJFdgmTGjfvr39dUxMDEOGDCky3SzA9OnT7WUc/V1MmTKFr7/+mtGjR3PrrbfSpUsXUlJS+OGHH5g9ezYdOnRwOP7ff/+dSZMmMXr0aFq2bEleXh6ffvopFouFa6+9tjxVIlJ7uWYyKhGpjkqbbrZt27Ylll++fLlxySWXGN7e3ka9evWMRx991Pj1118vOBVq4XSzJU3bCRjTpk2zvy5tutl777232LHnTnlqGIaxaNEio1OnToaHh4fRrFkz4/333zcefvhhw8vLq5RaKGrJkiXGkCFDDH9/f8PT09OIiYkxZsyYYWRkZBi//PKLYTabjcGDBxu5ubkOnW/KlCkGYIwZM6bYeydOnDAmTpxohIaGGr6+vsaQIUOMHTt2FLsvR6abNQzDSE5ONm6++WbD39/fCAgIMG6++Wb71JtnTzd75MgRY9SoUUZgYKAREBBgjB492jh27Fix34VhGMazzz5r1K9f3zCbzUWmni2p7vfu3Wtcd911RmBgoOHl5WV0797d+Omnn4qUKbyXc6cCLfyMnB1nSQqnmy1tO3z4sGEYhrF+/XpjyJAhhq+vr+Hj42NceumlxooVK4qc67nnnjO6d+9uBAYGGt7e3kbr1q2N559/3sjJyTEMwzCSkpKMe++912jdurVRp04dIyAgwOjRo4fx5ZdfnjfGsy1ZssQYMWKEERoaari7uxuNGjUybr/9duPAgQOlHvPee+8ZgOHn52dkZmaWWGbDhg3GNddcY4SEhBienp5G48aNjTFjxhiLFi2ylyn8u3T8+HGHYr3QdLNnfzYK/05+9tlnRosWLQxPT0+jU6dORT6jhRz5XRiG7fM7adIko379+oaHh4fRoEEDY/z48UZSUlKR+C702dm3b59x6623Gs2aNTO8vLyM4OBg49JLLzV+++03h+pBRM4wGUYV+vpQRKQKGDly5HmnFRWRsjGZTNx7773MmjXL1aGISCXSGAsRqdXO7c++e/du5s+fz4ABA1wTkIiISDWlMRYiUqs1bdqUCRMm0LRpUw4ePMjbb7+Nh4cHjz76qKtDExERqVaUWIhIrTZ06FA+//xz4uPj8fT0pGfPnvz73/8ucTEvERERKZ3GWIiIiIiIyEXTGAsREREREbloSixEREREROSiaYxFCaxWK8eOHcPPzw+TyeTqcEREREREXMIwDE6ePEm9evUuuHipEosSHDt2jIYNG7o6DBERERGRKuHw4cM0aNDgvGWUWJTAz88PsFWgv7+/i6OpPnJzc1m4cCGDBw/G3d3d1eHUCqpz51J9O5fq27lU386l+nY+1Xn5pKen07BhQ/vz8fkosShBYfcnf39/JRZlkJubi4+PD/7+/voL6ySqc+dSfTuX6tu5VN/Opfp2PtX5xXFkeIAGb4uIiIiIyEVTYiEiIiIiIhdNiYWIiIiIiFw0jbEQERERkTLLz88nNzfX1WE4LDc3Fzc3N7KyssjPz3d1OFWGu7s7FoulQs6lxEJEREREHGYYBvHx8aSmpro6lDIxDIOIiAgOHz6sdcrOERgYSERExEXXixILEREREXFYYVIRFhaGj49PtXlIt1qtnDp1Cl9f3wsu9FZbGIZBRkYGiYmJAERGRl7U+ZRYiIiIiIhD8vPz7UlFSEiIq8MpE6vVSk5ODl5eXkoszuLt7Q1AYmIiYWFhF9UtSrUqIiIiIg4pHFPh4+Pj4kikIhX+Pi92zIwSCxEREREpk+rS/UkcU1G/TyUWIiIiIiJy0ZRYiIiIiIiUUVRUFDNnznR1GFWKyxOLN998k6ioKLy8vOjRowerV68utezWrVu59tpriYqKwmQylfjLnDFjBt26dcPPz4+wsDBGjhzJzp07K/EOKla+1WDl3mS+33iUlXuTybcarg5JREREpEI583nHZDJhMpmwWCwEBQVhsVjs+0wmE08//XS5zrtmzRruuOOOi4ptwIABPPjggxd1jqrEpbNCzZ07l8mTJzN79mx69OjBzJkzGTJkCDt37iQsLKxY+YyMDJo2bcro0aN56KGHSjznn3/+yb333ku3bt3Iy8vj8ccfZ/DgwWzbto06depU9i1dlAVb4pj+4zbi0rLs+yIDvJg2PJqhMRc3/ZeIiIhIVeDs5524uDjANivUJ598wowZM4p86ezr62v/2TAM8vPzcXO78CNy3bp1KzzW6s6lLRavvfYat99+OxMnTiQ6OprZs2fj4+PDBx98UGL5bt268fLLL3P99dfj6elZYpkFCxYwYcIE2rZtS4cOHfjoo484dOgQ69atq8xbuWgLtsRx92fri/wlA4hPy+Luz9azYEuciyITERERqRiueN6JiIiwb/7+/phMJvvrHTt24Ofnxy+//EKXLl3w9PRk2bJl7N27lxEjRhAeHo6vry/dunXjt99+K3Lec7tCmUwm3n//fUaNGoWPjw8tWrTghx9+uKjYv/nmG9q2bYunpydRUVG8+uqrRd5/6623aNGiBV5eXoSHh3PdddfZ3/v6669p164d3t7ehISEMHDgQE6fPn1R8VyIy1oscnJyWLduHVOnTrXvM5vNDBw4kJUrV1bYddLS0gAIDg4utUx2djbZ2dn21+np6YBtyi1nLFWfbzV4+oetlNQIaAAmYPqPWxnQIgSLuerOwlBYV86oM7FRnTuX6tu5VN/Opfp2rupa37m5uRiGgdVqxWq1YhgGmbn5Dh2bbzWYdoHnnad/2ErPpsEOPe94u1vKNJuRYZy5stVqLfLnY489xksvvUTTpk0JCgri8OHDDB06lGeffRZPT08+/fRThg8fzvbt22nUqFGRcxaeA2D69Om88MILvPjii8yaNYubbrqJ/fv3n/c59NxzFFq3bh1jxoxh2rRpjBkzhhUrVjBp0iSCgoKYMGECa9eu5f777+fjjz+mV69epKSksGzZMqxWK3Fxcdxwww28+OKLjBw5kpMnT7Js2TLy8/NLvFbh7zI3N7fYOhZl+Yy6LLFISkoiPz+f8PDwIvvDw8PZsWNHhVzDarXy4IMP0rt3b2JiYkotN2PGDKZPn15s/8KFC50yT/PuNBPx6aUvRmIAcWnZzJq7gBYBVX/MRWxsrKtDqHVU586l+nYu1bdzqb6dq7rVt5ubGxEREZw6dYqcnBwyc/Lp+dpfFXJuA4hPz6bDM79dsCzAysmX4O1R9sXcDMOwf4mckZEBwD//+U969OhhL9OkSROaNGlif/3II4/wzTff8OWXX9rHVVitVrKysuznArj++usZNmyY/ZxvvPEGixcvZuDAgSXGkpeXR05OTpFzFHrppZfo378/999/PwDXXHMNGzdu5OWXX+aaa65h586d+Pj40K9fP/z8/AgKCqJZs2akp6ezZ88e8vLyGDhwIMHBwQQHB9O4cWOsVmuJ18rJySEzM5MlS5aQl5dX5L3COnJEjV55+95772XLli0sW7bsvOWmTp3K5MmT7a/T09Np2LAhgwcPxt/fv7LD5MfNcbDt7wuWa9q2I1e2r7pjLXJzc4mNjWXQoEG4u7u7OpxaQXXuXKpv51J9O5fq27mqa31nZWVx+PBhfH198fLywi0n78IHVRI/fz98PBx/lC1ssTCZTPbnu8IvkPv27Vvkme/UqVNMnz6d+fPnExcXR15eHpmZmRw/ftxezmw24+XlVeS4rl272l/7+/vj7+/PqVOnSn2edHNzw8PDo8T39+7dy9VXX13kvUsvvZTZs2dTp04drr76al5++WU6d+7MkCFDGDJkiL0bVq9evbj88svp06cPgwcPZtCgQVx33XUEBQWVGEdWVhbe3t7069cPLy+vIu+VlIiUxmWJRWhoKBaLhYSEhCL7ExISiIiIuOjzT5o0iZ9++oklS5bQoEGD85b19PQsccyGu7u7U/6yRwY6Nqg8MrBOtfjHx1n1Jmeozp1L9e1cqm/nUn07V3Wr7/z8fEwmE2azGbPZTB1Pd7Y9M8ShY1fvT2HCh2suWO6jid3o3qT0rkOFytoV6uwuQGazuciffn5+9p8BHn30UWJjY3nllVdo3rw53t7eXHfddeTm5hYpV1gXhTw9PYu9f/Z1SnLuOc733tlxBwQEsH79ehYvXszChQt5+umneeaZZ1izZg2BgYHExsayYsUKFi5cyJtvvsmTTz7JqlWrirTEnH1ek8lU4uexLJ9Plw3e9vDwoEuXLixatMi+z2q1smjRInr27Fnu8xqGwaRJk/juu+/4/fffS6y8qqZ7k2AiA7wo7a+GCdtsCY78JRMRERFxFpPJhI+Hm0Nb3xZ1HXre6duirkPnq8zVv5cvX86ECRMYNWoU7dq1IyIiggMHDlTa9UrSpk0bli9fXiyuli1b2sdBuLm5MXDgQF566SU2b97MgQMH+P333wHb76Z3795Mnz6dDRs24OHhwXfffVepMbu0K9TkyZMZP348Xbt2pXv37sycOZPTp08zceJEAG655Rbq16/PjBkzAFv/r23bttl/Pnr0KBs3bsTX15fmzZsDtu5Pc+bM4fvvv8fPz4/4+HgAAgIC8Pb2dsFdXpjFbGLa8Gju/mw9JihxUNO04dFVeuC2iIiIyPmc73mn8AmnqjzvtGjRgm+//Zbhw4djMpl48sknSxz0XBGOHz/Oxo0bi+yLjIzk4Ycfplu3bjz77LOMHTuWlStXMmvWLN566y0AfvrpJ/bt20e/fv0ICgpi/vz5WK1WWrVqxapVq1i0aBGDBw8mLCyMVatWcfz4cdq0aVMp91DIpdPNjh07lldeeYWnnnqKjh07snHjRhYsWGAf0H3o0CH73MMAx44do1OnTnTq1Im4uDheeeUVOnXqxG233WYv8/bbb5OWlsaAAQOIjIy0b3PnznX6/ZXF0JhI3h7XmYiAov3aLCZ466bOWsdCREREqr3SnnciArx4e1zVed557bXXCAoKolevXgwfPpwhQ4bQuXPnSrnWnDlz7M+3hdt7771H586d+fLLL/niiy+IiYnhqaee4plnnmHChAkABAYG8u2333LZZZfRpk0bZs+ezeeff07btm3x9/dnyZIlXHnllbRs2ZInnniCV199lSuuuKJS7qGQyTh77i0BbINUAgICSEtLc8rg7bPlWw1W70/haGoGj3+7hZx8Kz/d14eY+gFOjaM8cnNzmT9/PldeeWW16i9ananOnUv17Vyqb+dSfTtXda3vrKws9u/fT5MmTYoN8i2LwuedxJNZhPnZuntXdktF4YxI/v7+5x3zUBud7/dalufiGj0rVHVkMZvo2SwECCF2WwK/bk1g4baEapFYiIiIiDjizPOO1CRK16qwwdG22bEWbo13cSQiIiIiIuenxKIKu6x1GBaziR3xJzmc4vjiJCIiIiIizqbEogoLquNBtyjbQiYLtyVcoLSIiIiIiOsosaji1B1KRERERKoDJRZV3KBo29S7aw6kkHI6x8XRiIiIiIiUTIlFFdcw2IfoSH+sBvy+I9HV4YiIiIiIlEiJRTVQ2Gqh7lAiIiIiUlUpsagGBre1JRZLdh8nMyffxdGIiIiIiBSnxKIaiI70p36gN1m5VpbuPu7qcERERERqnQEDBvDggw+6OowqTYlFNWAymeytFrGadlZERESqq9TDcGxj6Vvq4Qq/5PDhwxk6dGiJ7y1duhSTycTmzZsv+jofffQRgYGBF32e6szN1QGIYwZFh/Ph8gP8tj2BvHwrbhblhCIiIlKNpB6GWV0gL7v0Mm6eMGkdBDassMv+4x//4Nprr+XIkSP4+/sXee/DDz+ka9eutG/fvsKuV5vp6bSa6B4VTIC3Oycycll38ISrwxEREREpm4zk8ycVYHs/I7lCL3vVVVdRt25dPv744yL7T506xVdffcU//vEPkpOTueGGG6hfvz4+Pj60a9eOzz//vELjOHToECNGjMDX1xd/f3/GjBlDQsKZniibNm3i0ksvxc/PD39/f7p06cLatWsBOHjwIMOHDycoKIg6derQtm1b5s+fX6HxVQQlFtWEm8XM5W3CAK3CLSIiIlWEYUDOace2vEzHzpmX6dj5DMOh07m5uXHLLbfw8ccfY5x1zFdffUV+fj433HADWVlZdOnShZ9//pktW7Zwxx13cPPNN7N69ery1EoxVquVESNGkJKSwp9//klsbCz79u1j7Nix9jI33XQTDRo0YM2aNaxbt47HHnsMd3d3AO69916ys7NZsmQJf//9Ny+++CK+vr4VEltFUleoamRwdATfrj9K7LYEnhjWBpPJ5OqQREREpDbLzYB/16vYc35Q8niIYh4/Bh51HCp666238vLLL7N8+XKuvPJKwNYN6tprryUgIICAgAAeeeQRe/n77ruPX3/9lS+//JLu3buX+RbOtWjRIv7++2/2799Pw4a2bl6ffPIJbdu2Zc2aNXTr1o1Dhw4xZcoUWrduDUCLFi3sxx86dIhrr72Wdu3aAdC0adOLjqkyqMWiGunXMhRPNzOHUjLYmXDS1eGIiIiIVAutW7emV69efPbZZwDs2bOHpUuX8o9//AOA/Px8nn32Wdq1a0dwcDC+vr78+uuvHDp0qEKuv337dho2bGhPKgCio6MJDAxk+/btAEyePJnbbruNgQMH8sILL7B371572fvvv5/nnnuO3r17M23atAoZbF4Z1GJRjfh4uNG3RSi/bU9k4dYEWkf4X/ggERERkcri7mNrOXBE/GbHWiNuXQARDgymdvdx7LoFJk6cyAMPPMDJkyf58MMPadasGf379wfg5Zdf5vXXX2fmzJm0a9eOOnXq8OCDD5KTk1Oma1yMp59+mhtvvJGff/6ZX375hWnTpvHFF18watQobrvtNoYMGcLPP//MwoULmTFjBq+++ir33Xef0+JzhFosqpnB0REALNymVbhFRETExUwmW3ckRzY3b8fO6ebt2PnK2CV8zJgxmM1m5syZwyeffMKtt95q71a+fPlyRowYwbhx4+jQoQNNmzZl165dZa2NUrVp04bDhw9z+PCZ6XS3bdtGamoq0dHR9n0tW7bkoYceYuHChVxzzTV8+OGH9vcaNmzIXXfdxbfffsvDDz/Me++9V2HxVRS1WFQzl7cJw2yCLUfTOZqaSf1AB/+SioiIiNRivr6+jBo1in/961+kp6czYcIE+3stWrTg66+/ZsWKFQQFBfHaa6+RkJBQ5KHfEfn5+WzcuLHIPk9PTwYOHEi7du246aabmDlzJnl5edxzzz3079+frl27kpmZyZQpU7juuuto0qQJR44cYc2aNVx77bUAPPjgg1xxxRW0bNmSEydO8Mcff9CmTZuLrZIKpxaLaibE15MujYMA+E2zQ4mIiEh14RNiW6fifNw8beUqybhx4zhx4gRDhgyhXr0zg86feOIJOnfuzJAhQxgwYAARERGMHDmyzOc/deoUnTp1KrINHz4ck8nE999/T1BQEP369WPgwIE0bdqUuXPnAmCxWEhOTuaWW26hZcuWjBkzhiuuuILp06cDtoTl3nvvpU2bNgwdOpSWLVvy1ltvVUidVCS1WFRDg6MjWHPgBAu3xTO+V5SrwxERERG5sMCGtsXvzrdOhU9IhS6Od67u3buTn5+P2Vz0u/Xg4GDmzZt33mMXL1583vcnTJhQpBXkXI0aNeL7778v8T0PD4/zrpvxxhtvnPfaVYUSi2poUHQ4z8/fzl/7UkjLyCXAx93VIYmIiIhcWGDDSk0cxLXUFaoaigqtQ6twP/KtBr/vVHcoEREREXE9JRbV1KDocABiNc5CRERERKoAJRbV1OC2tsRi8c7jZOXmuzgaEREREantlFhUU+3qBxDh70VGTj4r9ia5OhwRERERqeWUWFRTJpPJ3mqxcKu6Q4mIiIjzWK1WV4cgFaiifp+aFaoaGxQdzicrD/Lb9gTyrQYWc9lWoBQREREpCw8PD8xmM8eOHaNu3bp4eHjYV6+u6qxWKzk5OWRlZRWbbra2MgyDnJwcjh8/jtlsxsPD46LOp8SiGuvRJAQ/LzeSTuWw8fAJujQOdnVIIiIiUoOZzWaaNGlCXFwcx44dc3U4ZWIYBpmZmXh7e1ebZMhZfHx8aNSo0UUnXEosqjEPNzOXtQ7j+43HWLg1QYmFiIiIVDoPDw8aNWpEXl4e+fnVZwKZ3NxclixZQr9+/XB31xpghSwWC25ubhWSbCmxqOYGR0fYEottCTx2RWtl4CIiIlLpTCYT7u7u1eoB3WKxkJeXh5eXV7WKuzpRB7Nqrn+runhYzOxPOs3e46dcHY6IiIiI1FJKLKo5X083ejUPAeBXzQ4lIiIiIi6ixKIGGBwdAcBCrcItIiIiIi6ixKIGGBgdhskEmw6nkpCe5epwRERERKQWUmJRA4T5edGxYSAAsWq1EBEREREXUGJRQ6g7lIiIiIi4khKLGmJw23AAVu5NIj0r18XRiIiIiEhto8SihmhW15dmdeuQm2+weOdxV4cjIiIiIrWMEosaZFBBdyiNsxARERERZ1NiUYMUdof6Y0ci2Xn5Lo5GRERERGoTJRY1SMcGgdT18+RUdh5/7UtxdTgiIiIiUososahBzGYTg6JtrRYLt8a7OBoRERERqU2UWNQwgwsSi9htCVithoujEREREZHaQolFDdOzWQi+nm4knsxm89E0V4cjIiIiIrWEEosaxtPNQv9WdQF1hxIRERER51FiUQMVdofSKtwiIiIi4ixKLGqgS1uH4W4xsSfxFPuOn3J1OCIiIiJSCyixqIH8vdy5pGkIoMXyRERERMQ5lFjUUOoOJSIiIiLOpMSihhpYkFisP3SCxJNZLo5GRERERGo6JRY1VGSANx0aBGAYsGh7oqvDEREREZEaTolFDTborMXyREREREQqkxKLGmxw2wgAlu1J4lR2noujEREREZGaTIlFDdYizJeoEB9y8qws2XXc1eGIiIiISA2mxKIGM5lM9lYLrcItIiIiIpVJiUUNVzjO4vcdieTmW10cjYiIiIjUVEosarjOjYIIqeNBelYeq/enuDocEREREamhXJ5YvPnmm0RFReHl5UWPHj1YvXp1qWW3bt3KtddeS1RUFCaTiZkzZ170OWs6i9nEwDYFi+WpO5SIiIiIVBKXJhZz585l8uTJTJs2jfXr19OhQweGDBlCYmLJ6y5kZGTQtGlTXnjhBSIiIirknLXB4LZnpp01DMPF0YiIiIhITeTSxOK1117j9ttvZ+LEiURHRzN79mx8fHz44IMPSizfrVs3Xn75Za6//no8PT0r5Jy1Qe/moXi7WziWlsXWY+muDkdEREREaiA3V104JyeHdevWMXXqVPs+s9nMwIEDWblypVPPmZ2dTXZ2tv11errt4Ts3N5fc3NxyxVKVWIC+LUJYuC2RX/4+Rqswn0q5TmFd1YQ6qy5U586l+nYu1bdzqb6dS/XtfKrz8ilLfbkssUhKSiI/P5/w8PAi+8PDw9mxY4dTzzljxgymT59ebP/ChQvx8amch3BnC8sxARa+Xb2Xltm7KvVasbGxlXp+KU517lyqb+dSfTuX6tu5VN/Opzovm4yMDIfLuiyxqEqmTp3K5MmT7a/T09Np2LAhgwcPxt/f34WRVZxeGbl8/uJi4jIg5pIBNAqu+IQpNzeX2NhYBg0ahLu7e4WfX4pTnTuX6tu5VN/Opfp2LtW386nOy6ewJ48jXJZYhIaGYrFYSEhIKLI/ISGh1IHZlXVOT0/PEsdsuLu715gPXt0Ad7pHBbNyXzJ/7Ermtr4BlXatmlRv1YXq3LlU386l+nYu1bdzqb6dT3VeNmWpK5cN3vbw8KBLly4sWrTIvs9qtbJo0SJ69uxZZc5ZkxTODrVwW8IFSoqIiIiIlI1LZ4WaPHky7733Hh9//DHbt2/n7rvv5vTp00ycOBGAW265pchA7JycHDZu3MjGjRvJycnh6NGjbNy4kT179jh8ztqscBXutQdSSD6VfYHSIiIiIiKOc+kYi7Fjx3L8+HGeeuop4uPj6dixIwsWLLAPvj506BBm85nc59ixY3Tq1Mn++pVXXuGVV16hf//+LF682KFz1mYNgnxoW8+frcfSWbQjkTFdG7o6JBERERGpIVw+eHvSpElMmjSpxPcKk4VCUVFRDi3wdr5z1naDosPZeiydhVsTlFiIiIiISIVxaVcocb7B0bZB7Mv2HCczJ9/F0YiIiIhITaHEopZpE+lHgyBvsnKtLNl93NXhiIiIiEgNocSiljGZTPZWi4VbNTuUiIiIiFQMJRa1UOHsUIt2JJCXb3VxNCIiIiJSEyixqIW6RQUR6ONOakYuaw+ecHU4IiIiIlIDKLGohdwsZi5vXbBYnrpDiYiIiEgFUGJRS51ZhTveoSl8RURERETOR4lFLdW3RSiebmaOnMhke9xJV4cjIiIiItWcEotaysfDjb4t6gIQu03doURERETk4iixqMXO7g4lIiIiInIxlFjUYpe3DsNsgq3H0jlyIsPV4YiIiIhINabEohYL8fWka+NgQN2hREREROTiKLGo5Qq7QymxEBEREZGLocSilitchXvV/hRSM3JcHI2IiIiIVFdKLGq5xiF1aB3hR77V4Pcdia4OR0RERESqKSUWYm+10CrcIiIiIlJeSiyEwdERACzZfZys3HwXRyMiIiIi1ZESCyGmvj+RAV5k5OSzfE+Sq8MRERERkWpIiYVgMpkYrO5QIiIiInIRlFgIAIMKukP9tj2BfKvh4mhEREREpLpRYiEA9GgajJ+XG8mnc9hw6ISrwxERERGRakaJhQDgbjFzeeswABZqsTwRERERKSMlFmI3uK2tO9SvW+MxDHWHEhERERHHKbEQu34t6+LhZuZgcga7E0+5OhwRERERqUaUWIidr6cbvZuFALBwa7yLoxERERGR6kSJhRRR2B0qVuMsRERERKQMlFhIEZe3CcNkgk1H0ohLy3R1OCIiIiJSTSixkCLC/Lzo3CgIgN/UaiEiIiIiDlJiIcUMKlyFW4mFiIiIiDhIiYUUM7ggsVi5N5m0zFwXRyMiIiIi1YESCymmaV1fmof5kmc1WLwz0dXhiIiIiEg1oMRCSjRY3aFEREREpAyUWEiJCsdZLN6RSHZevoujEREREZGqTomFlKhDg0DC/Dw5nZPPyr3Jrg5HRERERKo4N1cHIAVSD0PGeR7gfUIgsKHTwjGbTQyKDud/qw6xcFsCA1qFOe3aIiIiIlL9KLGoClIPw6wukJddehk3T5i0zqnJxeC2Efxv1SFityXw3IgYzGaT064tIiIiItWLukJVBRnJ508qwPb++Vo0KsElTYPx9XTj+MlsNh5Jdeq1RURERKR6UWIhpfJ0szCgVV0AYjU7lIiIiIichxILOa/BbSMAWLg13sWRiIiIiEhVpsRCzmtAq7q4W0zsPX6aPYmnXB2OiIiIiFRRSizkvPy93LmkaQig7lAiIiIiUjolFnJBhd2hYrepO5SIiIiIlEyJRXVyMs4llx3UxrYK94bDqSSmZ7kkBhERERGp2pRYVAU+IbZ1Ki7kxwchZV+lh3OuiAAvOjQMxDDgt+2JTr++iIiIiFR9WiCvKghsaFv8rrR1Kk4nwc8PQ+oB+HAYTPgJQpo5NcTB0eFsOpzKwm3x3NijkVOvLSIiIiJVn1osqorAhlCvY8lbi4Hwj4VQtzWcPAYfXgnHdzk1vMHRtu5QK/Ykcyo7z6nXFhEREZGqT4lFdeEXDuN/grC2cCoePhoGiTucdvnmYb40Ca1DTr6VP3ced9p1RURERKR6UGJRnfjWhfE/Qng7OJ1oSy4Stjrl0iaTyd5qsVCzQ4mIiIjIOZRYVDd1QmD8DxDZATKS4KOrIG6zUy49qCCx+H1HIjl5VqdcU0RERESqByUW1ZFPMNzyPdTrDJkp8PFwOLax0i/bqVEQob4enMzKY9X+Ugaai4iIiEitpMSiuvIOglvmQYNukJUKn1wNR9dV6iUtZhMDC9a00CrcIiIiInI2JRbVmVcAjPsWGl4CWWnwyUg4vKZSLzm4bcE4i60JGIZRqdcSERERkepDiUV15+UP476Bxr0hOx0+HQWH/qq0y/VqFoqPh4X49Cz+PppWadcRERERkepFiUVN4OkLN30FTfpBzkn49Bo4sKxSLuXlbqF/y7qArdVCRERERASUWNQcHnXghrnQ9FLIPQ2fXQf7/qyUSxV2h9I4CxEREREppMSiJvHwgRu+gOYDIS8T5oyBvb9X+GUuaxWOxWxiZ8JJDiSdrvDzi4iIiEj1o8SipnH3guvnQIshkJcFc66H3b9V6CUCfNzp0SQYUKuFiIiIiNgosaiJ3Dxh7GfQahjkZ8MXN8DOBRV6Ca3CLSIiIiJnc3li8eabbxIVFYWXlxc9evRg9erV5y3/1Vdf0bp1a7y8vGjXrh3z588v8v6pU6eYNGkSDRo0wNvbm+joaGbPnl2Zt1A1uXnAmI+hzdWQnwNzx8H2nyrs9IPaRgCw7uAJkk5lV9h5RURERKR6cmliMXfuXCZPnsy0adNYv349HTp0YMiQISQmJpZYfsWKFdxwww384x//YMOGDYwcOZKRI0eyZcsWe5nJkyezYMECPvvsM7Zv386DDz7IpEmT+OGHH5x1W1WHxR2u+wDaXgPWXPhqPGz7vkJOXT/Qm5j6/lgN+H17yb8vEREREak9XJpYvPbaa9x+++1MnDjR3rLg4+PDBx98UGL5119/naFDhzJlyhTatGnDs88+S+fOnZk1a5a9zIoVKxg/fjwDBgwgKiqKO+64gw4dOlywJaTGsrjDNe9Bu9FgzYOvJsKWbyrk1IPa2Fot1B1KRERERNxcdeGcnBzWrVvH1KlT7fvMZjMDBw5k5cqVJR6zcuVKJk+eXGTfkCFDmDdvnv11r169+OGHH7j11lupV68eixcvZteuXfzf//1fqbFkZ2eTnX2mO096ejoAubm55Obmluf2qp6rZmHBjPnvuRjf3EZ+bg5GzHUXdcrLWoXwf7/B0t1JpJ3OxN1kW4m7xtRZNVBY16pz51B9O5fq27lU386l+nY+1Xn5lKW+XJZYJCUlkZ+fT3h4eJH94eHh7Nixo8Rj4uPjSywfH3/mG/M33niDO+64gwYNGuDm5obZbOa9996jX79+pcYyY8YMpk+fXmz/woUL8fHxKcttVW2WK+gYHEfjlCVYvr+bDRvWczikT7lPZxgQ4mkhOdvK63Nj6RBiSyxiY2MrKmJxkOrcuVTfzqX6di7Vt3Opvp1PdV42GRkZDpd1WWJRWd544w3++usvfvjhBxo3bsySJUu49957qVevHgMHDizxmKlTpxZpCUlPT6dhw4YMHjwYf39/Z4XuHMaV5P/yCJYNn9Dp0Hu0b9cWo+NN5T7dJvNOPlxxkBM+DRg0qDWxsbEMGjQId3f3CgxaSpObm6s6dyLVt3Opvp1L9e1cqm/nU52XT2FPHke4LLEIDQ3FYrGQkFB0HYSEhAQiIiJKPCYiIuK85TMzM3n88cf57rvvGDZsGADt27dn48aNvPLKK6UmFp6ennh6ehbb7+7uXjM/eMNfBzcPTGvex+3nB8BkQNeJ5TrVkJhIPlxxkN93JmEyW4AaXG9VmOrcuVTfzqX6di7Vt3Opvp1PdV42Zakrlw3e9vDwoEuXLixatMi+z2q1smjRInr27FniMT179ixSHmzNWYXlC8dEmM1Fb8tisWC1Wiv4DqoxsxmufAV63G17/dODsPq9cp2qa+MggnzcScvMZe3B1AoLUURERESqF5d2hZo8eTLjx4+na9eudO/enZkzZ3L69GkmTrR9e37LLbdQv359ZsyYAcADDzxA//79efXVVxk2bBhffPEFa9eu5d133wXA39+f/v37M2XKFLy9vWncuDF//vknn3zyCa+99prL7rNKMplg6AwwW2DlLJj/iG3WqEvuLtNp3CxmLm8TztfrjvDbjkQ6V1K4IiIiIlK1uTSxGDt2LMePH+epp54iPj6ejh07smDBAvsA7UOHDhVpfejVqxdz5szhiSee4PHHH6dFixbMmzePmJgYe5kvvviCqVOnctNNN5GSkkLjxo15/vnnueuuu5x+f1WeyQSDn7NNSbvs/2DBY7bkotd9ZTrN4OiCxGJ7Ip1aV1KsIiIiIlKluXzw9qRJk5g0aVKJ7y1evLjYvtGjRzN69OhSzxcREcGHH35YUeHVfCYTXD4NzG6w5GVY+IQtuejzkMOn6NuiLp5uJo6mZvHbUROh+1Po2TwMi9lUiYGLiIiISFXi0gXypIowmeCyJ2DA47bXvz0Nf77s8OF/7koEbEnET4ctjPtgLX1e/J0FW+IqPlYRERERqZKUWMgZA/4Jlz1p+/mP5+CPGbbFKs5jwZY47v5sPdl5RQfHx6dlcfdn65VciIiIiNQSSiykqH6PwMCCxQL/fAF+f67U5CLfajD9x22U9G7hvuk/biPfev7kRERERESqPyUWUlyfB2HIv20/L30FfptWYnKxen8KcWlZpZ7GAOLSsli9P6Vy4hQRERGRKkOJhZSs571wxUu2n5e/bhvUfU5ykXiy9KSiPOVEREREpPpSYiGl63EnDHvV9vPKWbbpaM9KLsL8vBw6jaPlRERERKT6UmIh59ftNhj+OmCCVbPh54ehYBXz7k2CiQzw4nyTyvp4WOgWFeSUUEVERETEdZRYyIV1mQAjZgEmWPtf+OlBsFqxmE1MGx4NUGpykZGTz8sLd2JcYHYpEREREanelFiIYzqNg1GzwWSG9R/DD/eBNZ+hMZG8Pa4zEQFFuztFBnhxQ/eGALzz5z5m/rbbFVGLiIiIiJO4fOVtqUY6XG9bofvb22HjZ7YVuke+xdCYSAZFR7ByTyILl65icN8e9pW3m4f58exP23h90W483c3cM6C5q+9CRERERCqBWiykbNpdB9d9ACYLbP4Cvr0D8vOwmE30aBJMl1CDHk2CsZhtnaP+0acJjw5tBcBLC3by32X7XRm9iIiIiFQStVhI2bUdZUssvp4IW76G00lw+ZNghYCMAxC3CdwKPlo+IdwzoDlZuVb+s2g3z/60DS93Mzf1aOzSWxARERGRiqXEQson+moY9hr8eD/sXwzvL8YdGACw86xybp4waR0PDWxBdl4+7/y5j399twVPNwvXdWngishFREREpBKoK5SUX2SHC5fJy4aMZEwmE48Nbc2EXlEAPPr1Jn7YdKxy4xMRERERp1FiIU5jMtmmp72heyOsBjw0dyMLtsS7OiwRERERqQBKLMSpTCYTz4+M4ZrO9cm3Gtz3+Xr+2JHo6rBERERE5CIpsRCnM5tNvHRte4a1jyQ33+DOz9axbHeSq8MSERERkYugxEIq35r/Qm5mkV1uFjMzx3ZkUHQ4OXlWbvtkDav2JbsoQBERERG5WEospPJt+ATe7A47fymy291iZtaNnejfsi5ZuVZu/WgN6w+dcFGQIiIiInIxlFhI5atTF1IPwefXw5zr4cQB+1uebhbeubkLvZqFcDonn/EfrGbL0TTXxSoiIiIi5aLEQsrPJ8S2TsX5uHnC+J+h94NgdoNdv8CbPeDPlyA3CwAvdwvvj+9Kt6ggTmblMe6/q9gRn1758YuIiIhIhdECeVJ+gQ1h0jrIsI2NyM3LY/ny5fTu3Rv3s1beJrAhDJoOHW+Enx+GA0vhj+dh0+dwxcvQYiA+Hm58MKEb4/67mk2HUxn3/iq+uKMnzcN8XXiDIiIiIuIotVjIxQlsCPU62rbIDqT5RNkWzivcF9jwTNm6rWD8j3Dtf8E3AlL2wf+uhbnjIPUwfl7ufDKxO9GR/iSdyuGm9//iYPJpl9yWiIiIiJSNEgtxLpMJ2l0Hk9ZAz0lgssD2H22Du5e+RoCHwWe39aBluC8J6dnc+N4qjpzIcHXUIiIiInIBSizENbz8YcjzcNdSaNQLcjNg0XR4uxfBCSv47LYeNA2tw9HUTG56fxXxaVmujlhEREREzkOJhbhWeFuYOB9GvWObPSp5N3wygrAFd/H5DY1oGOzNweQMbnz/L46fzHZ1tCIiIiJSCiUW4nomE3S4HiathR53gckMW78j/KM+/Nh5Aw393dh3/DQ3/3cVJ07nuDpaERERESmBEgupOrwD4YoX4Y4/oUF3yD1N4LJnWOT7BEPr7GZH/Elu/mAVaZm5ro5URERERM5RrsTi8OHDHDlyxP569erVPPjgg7z77rsVFpjUYpHt4dZfYcSb4BOCR8ouZudP4y3vt0k4epAJH67mVHaeq6MUERERkbOUK7G48cYb+eOPPwCIj49n0KBBrF69mn/9618888wzFRqg1FJmM3QaZ+se1fUfgIkrjaX87vUIHY9+zm0f/EVGjpILERERkaqiXInFli1b6N69OwBffvklMTExrFixgv/973989NFHFRmf1HY+wXDVa3D771CvM35kMs39U6bF3c3L731CVm6+qyMUEREREcqZWOTm5uLp6QnAb7/9xtVXXw1A69atiYuLq7joRArV7wy3LYKrZpLnGUgb8yGmHX+ItTOvJyctwdXRiYiIiNR65Uos2rZty+zZs1m6dCmxsbEMHToUgGPHjhESElKhAYrYmc3QdSJu968nocX1APQ5vZDc1zuTv+pdsKr1QkRERMRVypVYvPjii7zzzjsMGDCAG264gQ4dOgDwww8/2LtIiVSaOiGE3/QOGwZ/zRajCXWsp7D8MgXjvUvhyFpXRyciIiJSK7mV56ABAwaQlJREeno6QUFB9v133HEHPj4+FRacyPl06jWIRQHz+erzl5hsmUtA3CZ4/3LofAtc/jTUUeuZiIiIiLOUq8UiMzOT7Oxse1Jx8OBBZs6cyc6dOwkLC6vQAEXO5/K29bhk7D8ZlPsaX+X1s+1c/wnM6gJrPwSr1bUBioiIiNQS5UosRowYwSeffAJAamoqPXr04NVXX2XkyJG8/fbbFRqgyIVc0S6Sf43px6P5d3Fd9lPEezeHzBPw04O2Foyj610dooiIiEiNV67EYv369fTt2xeAr7/+mvDwcA4ePMgnn3zCf/7znwoNUMQRIzrW58Vr2rPWaE3vE9P4rfFDGB5+cGw9vHcZ/PQQZKS4OkwRERGRGqtcYywyMjLw8/MDYOHChVxzzTWYzWYuueQSDh48WKEBijhqTLeGZOfl8+T3W7ltZzf+1W8It2d9CJvnwtoPYNv3MOgZ6HCjbYap1MOQkVz6CX1CILCh825AREREpBorV2LRvHlz5s2bx6hRo/j111956KGHAEhMTMTf379CAxQpi5t7RpGdZ+W5n7fz/JIU8q/4J3dNuAV+fgSOb4fv77WNweg7Bb68CfKySz+ZmydMWqfkQkRERMQB5eoK9dRTT/HII48QFRVF9+7d6dmzJ2BrvejUqVOFBihSVrf1bcqUIa0AeOGXHXx4tD7ctRQGPwcevnB4FcwZff6kAmzvn69FQ0RERETsytVicd1119GnTx/i4uLsa1gAXH755YwaNarCghMpr3svbU5Wbj5v/L6H6T9uw9PNwo297oOYa+HXf8HWb10dooiIiEiNUq7EAiAiIoKIiAiOHDkCQIMGDbQ4nlQpkwe1JDvPyrtL9vGveX/j6Wbm2i4NYPSH0Lg3zH/Y1SGKiIiI1Bjl6gpltVp55plnCAgIoHHjxjRu3JjAwECeffZZrFo3QKoIk8nE1CtaM75nYwwDpny9iR83HbO92aCra4MTERERqWHK1WLxr3/9i//+97+88MIL9O7dG4Bly5bx9NNPk5WVxfPPP1+hQYqUl8lkYtrwtmTnWflizWEenLsRDzczQ4IufCwAhlGp8YmIiIjUFOVKLD7++GPef/99rr76avu+9u3bU79+fe655x4lFlKlmM0mnh/Vjuw8K99tOMqkOeuZc5U33Rw5+KtbYMBUaDcaLO6VHaqIiIhItVWurlApKSm0bt262P7WrVuTkqJFyKTqsZhNvHxde4a1iyQ33+DfP2937MDUQzDvbvhPJ1j1LuRkVG6gIiIiItVUuRKLDh06MGvWrGL7Z82aRfv27S86KJHK4GYxM/P6jgxsE05CXh2yjQu0QFg8oc9DUCcM0g7DL1NgZjtY+ipkpTknaBEREZFqolxdoV566SWGDRvGb7/9Zl/DYuXKlRw+fJj58+dXaIAiFcndYubNmzpx+ydWLt31KkGmk8XKmAr+fGRUTwZ07wL9H4ONn8Hy120tGIuegWUzodttcMk94FvXqfcgIiIiUhWVq8Wif//+7Nq1i1GjRpGamkpqairXXHMNW7du5dNPP63oGEUqlKebhbdu7EySJYytRpNi25aCP6cuSiXfaoC7ly2JuG8DjHoX6raB7HRY9hrMjIH5U2wJh4iIiEgtVu51LOrVq1dskPamTZv473//y7vvvnvRgYlUpr+PppGTX/rUyAYQl5bF6v0p9GwWYttpcYMOY20DuXf9YusSdXQdrH4X1n4A7cZAnwehbiun3IOIiIhIVVKuFguR6i7xZFb5y5nN0HoY3LYIbvkBmg4Aax5smgNv9oC54+Do+ooNWERERKSKU2IhtVKYn9fFlzOZoGl/uOV7uP13aH0VYMD2H+G9S+GTkbB/idbCEBERkVpBiYXUSt2bBBMZ4GUfqF2Sun6edG8S7NgJ63eB6/8H96yCDjeAyQL7/oCPh8N/B8GO+aBV6UVERKQGK9MYi2uuuea876empl5MLCJOYzGbmDY8mrs/W48J25iKc6Vl5vLT5mOM6Fjf8ROHtYZRs22L6q14A9Z/AkfWwBc3QFi0bfrattfYxmuIiIiI1CBlarEICAg479a4cWNuueWWyopVpEINjYnk7XGdiQgo2t0p3N+TluG+5ORZeeCLjTwx72+y8/LLdvKgxjDsFXjwb+j9IHj4QeI2+PZ2eKMzrPkv5Do2zkNERESkOijT16YffvhhZcUh4hJDYyIZFB3B6v0pJJ7MIszPy9796f9idzHrjz189tchNh9J480bO9Mw2KdsF/ALh0HTbS0Va96Dv96G1IPw82T480XoeS90vRU8/Srh7kREREScR2MspNazmE30bBbCiI716dksBIvZhMVs4pEhrfhwYjcCfdzZfCSNYf9Zym/bEsp3Ee9A6DcFHtwCV7wE/g3gVALEPgX/FwO/Pw+nkyv0vkREREScyeWJxZtvvklUVBReXl706NGD1atXn7f8V199RevWrfHy8qJdu3YlrvS9fft2rr76agICAqhTpw7dunXj0CEtYCZld2mrMH6+vy8dGwaSnpXHbZ+sZcYv28k7zxoY5+XhAz3uhPs3wIg3IaQFZKXCkpdsi+0tmAppRyv0HkREREScwaWJxdy5c5k8eTLTpk1j/fr1dOjQgSFDhpCYmFhi+RUrVnDDDTfwj3/8gw0bNjBy5EhGjhzJli1b7GX27t1Lnz59aN26NYsXL2bz5s08+eSTeHk5Nr2oyLnqB3rz5Z09mdArCoB3/tzHje+tIiH9IsZIuHlAp3Fw7yoY/TFEdoDcDPjrLXi9A3w/CZL3VswNiIiIiDiBSxOL1157jdtvv52JEycSHR3N7Nmz8fHx4YMPPiix/Ouvv87QoUOZMmUKbdq04dlnn6Vz587MmjXLXuZf//oXV155JS+99BKdOnWiWbNmXH311YSFhTnrtqQG8nAz8/TVbXnzxs74erqx+kAKw/6zlBV7ki7uxGYLtB0Jd/wJ476Fxn3AmgsbPoVZXeGrCRC3uegxqYfh2EbbFreJgIwDELfpzL7UwxcXk4iIiEg5uGzOy5ycHNatW8fUqVPt+8xmMwMHDmTlypUlHrNy5UomT55cZN+QIUOYN28eAFarlZ9//plHH32UIUOGsGHDBpo0acLUqVMZOXJkqbFkZ2eTnZ1tf52eng5Abm4uubm55bzD2qewrmpynQ1uE0qLu3pw/xeb2JFwinH/XcX9lzXn7n5NMJvPtyqGAxr3g8b9MB1ZjXn5TMx7FsLW72Drd1ibDcTa+0EM/wa4vd0DU77t8+oODADYeeY0hsWTvLtXQUCDi4tHiqkNn/GqRPXtXKpv51J9O5/qvHzKUl8uSyySkpLIz88nPDy8yP7w8HB27NhR4jHx8fEllo+PjwcgMTGRU6dO8cILL/Dcc8/x4osvsmDBAq655hr++OMP+vfvX+J5Z8yYwfTp04vtX7hwIT4+ZZwFSIiNjXV1CJXuH43ha6uZVcfNzFy0h1/X7WJccyu+7hV0Ab9x+LfuR4uEn6h/YhXmvb9h3vsbqV6NCMzPPu+hpvxslsf+QJpPVAUFI+eqDZ/xqkT17Vyqb+dSfTuf6rxsMjIyHC5bo1bpshasbDxixAgeeughADp27MiKFSuYPXt2qYnF1KlTi7SEpKen07BhQwYPHoy/v3/lB15D5ObmEhsby6BBg3B3r6gn7KprJPD1+qM8/eN2tqfCrN0+vD62PZ0aBlbgVe4iL2Uf5r9mYd78BYFZjk1C0Lt3b9u4DalQte0z7mqqb+dSfTuX6tv5VOflU9iTxxEuSyxCQ0OxWCwkJBSdvjMhIYGIiIgSj4mIiDhv+dDQUNzc3IiOji5Spk2bNixbtqzUWDw9PfH09Cy2393dXR+8cqhN9XZDjyg6Ngrmnv+tZ3/SaW58fw2PX9mGib2jMJkusmtUofBWMOINuPRx2/S0f395wUPc3dyglvwOXKE2fcarAtW3c6m+nUv17Xyq87IpS125bPC2h4cHXbp0YdGiRfZ9VquVRYsW0bNnzxKP6dmzZ5HyYGvOKizv4eFBt27d2LlzZ5Eyu3btonHjxhV8ByI2bSL9+WFSb4a1iyTPavDMT9u453/rSc+q4D6c/pG2BfUc8feXcHi1VvcWERERp3FpV6jJkyczfvx4unbtSvfu3Zk5cyanT59m4sSJANxyyy3Ur1+fGTNmAPDAAw/Qv39/Xn31VYYNG8YXX3zB2rVreffdd+3nnDJlCmPHjqVfv35ceumlLFiwgB9//JHFixe74hallvDzcmfWjZ3otiKI5+dv55ct8WyPS+etm7oQXc8F3elWvmnbzO4Q0Q4adCvYukBQE6io1hQRERGRAi5NLMaOHcvx48d56qmniI+Pp2PHjixYsMA+QPvQoUOYzWcaVXr16sWcOXN44oknePzxx2nRogXz5s0jJibGXmbUqFHMnj2bGTNmcP/999OqVSu++eYb+vTp4/T7k9rFZDIxoXcTOjQM5N7/redAcgaj3lrOsyNiGNOtoXODadwbknbB6eNwbL1tW/2O7T2fkIIkoyvU7wr1O4NXgHPjExERkRrH5YO3J02axKRJk0p8r6RWhtGjRzN69OjznvPWW2/l1ltvrYjwRMqsU6Mgfr6/Lw99uZHFO4/z6DebWX0ghWdHxODtYXFOEEP+bRu8nXoIjqyBI2vh6FrbehcZybBrgW0DwAR1W9sSjQZdbUlH3da2NTZEREREHOTyxEKkJgqq48EH47vx9p97eXXhTr5ed4QtR9N486bONKvrW/4T+4SAmyfknWfKWTdPWzmTCYIa27Z219ney8uG+L8Lko2ChCP1IBzfbts2fGor5+EL9Tqd1YWqK/hqkUkREREpnRILkUpiNpu499LmdGoUyP2fb2RH/EmufmMZL17Xnqva1yvfSQMbwqR1tlYHIDcvj+XLl9O7d2/bTFBgSyoCS+l65eZ5pmWCu237TiXaEowja2ytGkfXQ84pOLDUttmv3fhMi0aDbraxG27FZ1MrVephe9wlOl/cIiIiUuUpsRCpZL2ahTL//j5M+nwDq/enMGnOBtYeOMHjV7bBw60cE7MFNjzzAJ6bS5rPUVu3p/JOnecbBq2vtG0A1nw4vuNMsnFkre116kHbtuUbWzmLB0S0P9Oi0aCrLfkoaWB46mGY1eXCLS2T1im5EBGRinP2l1p5eQRkHLB1C3bkyzgpMyUWIk4Q5u/FnNt68GrsLt5evJePVhxgw+FU3ryxEw2Cqtjq7mYLhLe1bV3G2/ZlpdlaMo6uPZNwZCQXtHCshVUFx9apW3xguKefrez5kgqwvZ+RrH/gRUSkYpzzpZY7MADg7FUJ9KVWhVJiIeIkbhYz/xzamq6Ng5j85SY2HU5l2H+W8X9jO3BZ63BXh3d+XgHQ7FLbBmAYcOLAWa0aa2xjN04fh53zbRsAJgiLhuAoFwUuIiK1lr7UcjolFiJOdnmbcH66rw+T5qxn05E0bv1oLfcMaMbkQS1xs7hszcqyMZkguIlta18wS1tuFsRvLjowPO0wJG61bSIiUn1pnJw4QImFiAs0DPbhy7t68u+ft/PxyoO8tXgv6w+d4D83dCLMz8vV4ZWPuxc07G7bCp2MtyUYO36GTXMufI5l/wfNLoPI9lC3je2cIiLiWlVpnFx+LmSk2JKcjKSCP5PP7Dt91r6T8Y6dc837ti68AQ0goBEE1AePOpV7HzWUEgsRF/F0szB9RAxdo4J57JvN/LUvhWH/WcZ/ru9Ez2Yhrg6vYvhFQJurbP9YO5JYbJtn2wDMbhDaypZkRLS3zUIV0Q68AysxYBERKaayuhRZrZCVelaicKFkIQWy0y7qVkq04dMz060X8gkpSDQaFmwNbPdWmHzUCS15spKKUk1biJRYiLjY8A71iK7nzz2frWdnwkluev8vHh7cirv7N8NsrsR/tKqi9mNt3zDFb4bME2e6UW36/EyZwMa2BCOyw5mEw79e5f4DLyIiF5abCScOFk0KiiQK5yQLmSlgWMtxIRP4BNserkvb6oTarv3dXRc+XZsRkJdl676behhyTp6JN25Tyce4eRUkGaUkH/4NwM2jHPdG1WohKiMlFiJVQLO6vsy7tzdPzNvCN+uP8PKvO1l7IIX/G9uRQJ9y/sNUHV1yD9TraBscnn4U4jbbkoz4v20/px06M+3tjp/OHOcTcibJKEw4Qppp9XARkYpgzXes3IdDy3d+T/9zEoXQkhOHOqG2P70CHPv3/dhGx67fd7Lt/z2FMlMh7Ygt0Sj8M/Wsn0/G2xKR5D22rUQm8A0/q5WjsJvVWcmHV2DJX4pV40HnSixEqghvDwuvjG5P9yZBPPn9Vv7YeZxh/1nGmzd1pmPDQFeHd3HKsmI42P6hLfyHuHB9DbB905WwpWjCcXyn7R/XfX/YtkLuPrYpcyPaF3Snagdhbcs+bkNzoItIbWC12r7QSd4DKXshuWBL2Qsp+x0/j8WzIAE4N1EIKZ4s1AkF7+Dyf7NfWbwDbVtETMnv5+XY6irtyFkJyNnJxxHIy4RT8bbtyJqSz+Phd04Xq4LkIzezsu6s0imxEKlCTCYTY7s1IqZ+APf8bz0HkzMYPXsFTwyL5paejTFV1+4+56wYXiJHHtB9gqFJP9tWKDcTEredadWI3wwJWyE348wMVYVMFqjbqmC8xlkJh3dQydfTHOjiqGraH1pqGcOAU4lnJQ97CpKHfbYtL+vizn/rAmh4SdXpmlrWL7Uc5eZxZmbEkhiG7d+Dc1s6zn6dkWTrcnV8u22rIZRYiFRBbesF8ON9fXj0q80s2BrPtB+2svpACi9e2x5fz2r61/bsFcMrkrs31O9i2wpZ823/s4wvSDQKE46MZFsSkrgNNs89Uz6gUdFB4pHtwb9+tW6O1oOuE1Xj/tDiZM5qAc1IKWhxOLv1YY8tecg5VfpxZncIioKQ5rbupCHNILiZ7bM9Z/SFr+vmXXWSCij2pVZuXh7Lly+nd+/euFdmq7PJZGuNqRMK9TqVXCYno6DV49zk44jtd3UyrmJjcpJq+oQiUvP5e7nz9rjOfLD8ADPmb+fnzXFsP5bOW+M60zrCn3yrwar9KaxLMhGyP4WezcOw1LbB3qUxW6BuS9vW7jrbPsOw/UNt70ZVkHCkHrSN3Ug7VHTchnew7X+w1VF1ftCtjl3PqnMCWl1Vx8S5oltAs08WTRjsrQ97bZNflMZkhsBGtoQhpJktiSj8OaAhWEp4NHR0rEJVdPaXWrm5pPkctY3Fc3d3bVwePhDawrad69hGeLe/00OqCEosRKowk8nEP/o0oWPDQCbNWc++pNOMfHM5Y7s2ZOG2BOLSsgALn+xeS2SAF9OGRzM0JtLVYVdNJpNt9ij/etDqrAGGmam2blTxf59JNo7vsM1Wkpni2LkXvwBBjW3znnv42jbPgj896oCnX/H33Dwr5TaB6vugq65n4ojqmjiX5+9lbqZtfEORrksFScTpxPOfy78+BDc90/oQXJBEBDUu+78/ldWlSGocJRYi1UCXxkH8fH9fHpy7kSW7jvPxyoPFysSnZXH3Z+t5e1xnJRdl4R0ITfratkK5WbY+r9t/hqUvX/gcu34p+3XN7iUkHee8ticnhe+d+9rvzM8edapWF4TycGVCZBi2hbfyss7ass/8mZt51uvC9wr2OTqw1dGZdeT8qmvi7Kilr0JWmq31If3I+cvWqXsmYQhpeqb1Ibip7RvxilJR4+SkxlNiIVJNBNfx4L+3dKXTs7Gcys4r9r4BmIDpP25jUHSEukVdDHevgn6xJscSi263g5c/ZJ+y9V/OOVXw8+nir/MKZvuw5toWhspKraCgTWcSErOD/7Qvf902HaLZYktKTJaCny227hLmgj/tP1tK2Gcu4TjzOec4Z3+x4wrOV+q0jefYvwSSdp+TBJwvEch2rBxGuWvfIe8PtK3oa5/95ew58At+9gqo3Bhqk6PrbANkrfkFWx4YZ/1cbF/h/hL2GWcfc6F9pZwrK92xuLf/UPS1V0DR7kohzQtaIpo59/NSWePkpLhq3EKkxEKkGll78ESJSUUhA4hLy2L1/pSas3p3ddBpXNE50M8nP68g2Sgh6SjyumBf9smz3jvndWE5DNtWeLyjtn5bjputAmKfrPxruHnZ/sft5nXW5ln0T/eC/TmnYKcjrVbWMzPDlKZw+snSEg//emCpwL7hVW1MS35eweJpxwu2pLN+Lnh94oBj5/p5cqWGWmk63QyNe51pifAJrv6tkVI21biFSImFSDWSeNKxqQAdLScuYHE7M0d6RTAM29S6ZycdxzbCj/dd+NhOt9hmLTGsBd+qFvxpWG3fsNp/tp751tU49+dzy5awv8hx1hLOUbA/L8v2DfOFhLezPWy5exd/2C8pCXD3LjkxKK2sxaNsD3LHNjqWWNz0je0bZvuiW2fNgZ9+1PYQccHpJ03gF1l64hHQwDZ9siPxO2NMi2FAdnrJCcKpxOLJQ+YJKqzlKKgpeNaxteCZLLY/zW62lrMi+wpazorsM58pf+6+Mp+rYF/qYceS4m63Of5FhdRc1bSFSImFSDUS5ufY4m6HUzIwDKP6rntRVVSH5miT6cwYC98w2z7D6tix3f5RtR5gHJ0JZcSsqhW3o+qE2uJu2K3k98+efvLcxKPw5/wcOHnMth1ZXfJ53H3On3j417d9bss7ViG3IAEsrUXh3J/zc8pYUaaCxdPqFkzZWfesLdTWUhf7xIVPM/rDqvU5qc4zK4k4SImFSDXSvUkwkQFexKdlnfc7vVcW7uKvfSk8cVUbWkf4Oy2+GsdVc6BL9VJRCej5pp8EW6tORtJZicbR4onH6URbC1bSLttWGt9w25TKjlj4hC05KEwWsh0cK3A2T/9zkoTSfq5ra3ExW0o/lx7QRaosJRYi1YjFbGLa8Gju/mw9Jop2GChsmxgUHc7incdZtieJK19fyg3dGzF5UEtCfCtxetOarKrOgX4+1aGlpSZxVn9os9nWKuUbVnRByLPlZhW0epTQ1SrtiK07Tl4mnEqwbY44sLT4PovHhROEwtc+obbxKLWd/l5KLaDEQqSaGRoTydvjOjP9x20F61jYRJy1jsWh5AxeWLCd+X/H879Vh/hh4zHuu7w543tF4el2nm8CpWaorgP/qvODV1XpD+3udWbF5JIYhm0cQ9ph2L8UFv7rwufsOxnqdS6aMHj6u25AcXX9nKgFVGoBJRYi1dDQmEgGRUewck8iC5euYnDfHkVW3m4U4sNbN3Vh1b5knv15G1uOpvPv+Tv436pDPH5lGwZHh2v8RU1XVR50y0IPXpXPZLINfPcJtiUZjmgzomqNVaiuiTNUzxZQkTJQYiFSTVnMJno0CSZ5u0GPJsElrlvRo2kIP9zbh2/WH+GlX3dyMDmDOz9dxyVNg3nyqmja1tOc+VLF6MFLHFEdE2eRWsDs6gBEpHKZzSZGd23I4kcGMOnS5ni4mflrXwpXvbGMx77ZzPGTF5gVRkRERMQBSixEaok6nm48MqQVvz/cn6vaR2IY8MWaw1z6ymLeWryHrNx8V4coIs5UOFbhfKriWAURqbLUFUqklmkQ5MOsGzszoVcKz/60jU1H0nhpwU7mFIy/uCImQuMvRGoDjWkRkQqmxEKkluoaFcx39/Tm+01HefGXnRw5kck9/1tP9yjb+It2DTT+QqTG05gWEalA6golUouZzSZGdWrA74/054HLW+Dlbmb1gRSufnMZj3y1iYT0rAufRERERAQlFiIC+Hi48dCglvz+8ABGdqyHYcDX645w6SuLmfX7bo2/EBERkQtSYiEidvUCvZl5fSe+u6cXnRoFkpGTzysLd3H5q3/yw6ZjGI7Oey8iIiK1jhILESmmU6Mgvr27F69f35F6AV4cTc3k/s83cN3slWw8nOrq8ERERKQKUmIhIiUymUyM6FifRQ8P4OFBLfF2t7Du4AlGvrmcyXM3EpeW6eoQRUREpApRYiEi5+XtYeG+y1vwxyMDuLZzAwC+3XCUS19ZzMzfdpGZo/EXIiIiosRCRBwUEeDFq2M68MOk3nRtHERWrpWZv+3mslcXM2/DUaxWjb8QERGpzZRYiEiZtG8QyFd39WTWjZ2oH+hNXFoWD87dyDVvr2DdwROuDk9ERERcRImFiJSZyWTiqvb1WPRwf6YMaUUdDwsbD6dy7dsruP/zDRxN1fgLERGR2kaJhYiUm5e7hXsvbc4fUwYwtmtDTCb4YdMxLntlMa8u3Mnp7DxXhygiIiJOosRCRC5amJ8XL17Xnh8n9aFHk2Cy86y88fseLn1lMV+vO1Jk/EW+1WDl3mS+33iUlXuTydfYDBERkRrBzdUBiEjNEVM/gC/uuIRft8bz/PztHE7J5JGvNvHxigM8NTya5FPZTP9xG3FpWfZjIgO8mDY8mqExkS6MXERERC6WEgsRqVAmk4mhMZFc2jqMj5Yf4I3f9/D30TRGz15ZYvn4tCzu/mw9b4/rrORCRESkGlNXKBGpFJ5uFu7s34w/HhnA2G4NSy1X2BFq+o/b1C1KRESkGlNiISKVqq6fJyM71j9vGQOIS8ti9f4U5wQlIiIiFU6JhYhUusSTWRcuBCSkO1ZOREREqh4lFiJS6cL8vBwqN+OX7fx32X7Ss3IrOSIRERGpaEosRKTSdW8STGSAF6bzlDEBCenZPPvTNi759yKenLeFPYknnRWiiIiIXCQlFiJS6SxmE9OGRwMUSy5MBdvM6zvy/KgYWob7kpGTz6d/HWTga0u4+b+r+G1bggZ2i4iIVHGablZEnGJoTCRvj+tcbB2LiHPWsbixeyNW7k3moxUH+G17Akt3J7F0dxKNgn24pWdjRndtSIC3u6tuQ0REREqhxEJEnGZoTCSDoiNYvT+FxJNZhPl50b1JMBbzmXYMk8lEr+ah9GoeyuGUDD776yBfrDnMoZQMnvt5O68u3MU1neszoVcULcL9XHg3IiIicjYlFiLiVBaziZ7NQhwq2zDYh6lXtuHBgS2Zt/EoH684wI74k/xv1SH+t+oQvZuHML5nFJe3CS+SnIiIiIjzKbEQkSrP28PCDd0bcX23hqzan8JHyw+wcFs8y/cks3xPMg2CvLmlZ2PGdm1EgI+6SYmIiLiCEgsRqTZMJhOXNA3hkqYhHDmRwWd/HeKLNYc4ciKTf8/fwWuxuxjVqQETekXRKkLdpERERJxJs0KJSLXUIMiHx65ozV9TL+fFa9vRJtKfrFwrn68+xJCZS7j+3ZUs2BJPXr7V1aGKiIjUCmqxEJFqzcvdwthujRjTtSGr96fw8coD/Lo1gb/2pfDXvhTqB3pzc8/GXN+tIYE+Hq4OV0REpMZSYiEiNYLJZKJH0xB6NA3hWGomn/11kM9XH+JoaiYv/LKDmb/tYmTH+ozvFUWbSH9XhysiIlLjqCuUiNQ49QK9eXRoa1ZOvZyXrmtP23q2blJfrDnMFa8vZew7K/nl7zh1kxIREalAarEQkRrLy93CmK4NGd2lAWsPnuCjFQdYsCWeVftTWLU/hXoBXozr2ZjruzUiuI66SYmIiFyMKtFi8eabbxIVFYWXlxc9evRg9erV5y3/1Vdf0bp1a7y8vGjXrh3z588vtexdd92FyWRi5syZFRy1iFQXJpOJblHBvHljZ5b981ImXdqckDoeHEvL4qUFO+k5YxGPfr2JrcfSSj1HvtVg1f4U1iWZWLU/hXyr4cQ7EBERqfpcnljMnTuXyZMnM23aNNavX0+HDh0YMmQIiYmJJZZfsWIFN9xwA//4xz/YsGEDI0eOZOTIkWzZsqVY2e+++46//vqLevXqVfZtiEg1ERngzSNDWrH8sct4ZXQH2tUPIDvPypdrjzDsP8sYM3slP2+OI/esblILtsTR58XfGffBWj7ZbWHcB2vp8+LvLNgS58I7ERERqVpcnli89tpr3H777UycOJHo6Ghmz56Nj48PH3zwQYnlX3/9dYYOHcqUKVNo06YNzz77LJ07d2bWrFlFyh09epT77ruP//3vf7i7a8EsESnKy93CdV0a8MOk3nxzdy+Gd6iHm9nE6gMp3DtnPX1f/IM3/9jDV2sPc/dn64lLyypyfHxaFnd/tl7JhYiISAGXjrHIyclh3bp1TJ061b7PbDYzcOBAVq5cWeIxK1euZPLkyUX2DRkyhHnz5tlfW61Wbr75ZqZMmULbtm0vGEd2djbZ2dn21+np6QDk5uaSm5tblluq1QrrSnXmPKrzitG+ni+vXRfDPwc35/M1R/hizRHi07N4+dedpR5jACZg+o9bGdAiBIvZ5LR4awt9vp1L9e1cqm/nU52XT1nqy6WJRVJSEvn5+YSHhxfZHx4ezo4dO0o8Jj4+vsTy8fHx9tcvvvgibm5u3H///Q7FMWPGDKZPn15s/8KFC/Hx8XHoHHJGbGysq0OodVTnFacl8HgMbEg2sfCImcSs0hMGA4hLy2bW3AW0CNCYi8qiz7dzqb6dS/XtfKrzssnIyHC4bI2bFWrdunW8/vrrrF+/HpPJsW8Qp06dWqQVJD09nYYNGzJ48GD8/TXfvaNyc3OJjY1l0KBB6n7mJKrzynM10HlzHJO/+vuCZZu27ciV7SMrP6haRp9v51J9O5fq2/lU5+VT2JPHES5NLEJDQ7FYLCQkJBTZn5CQQERERInHREREnLf80qVLSUxMpFGjRvb38/Pzefjhh5k5cyYHDhwodk5PT088PT2L7Xd3d9cHrxxUb86nOq8ckYF1HCr35bqj+Hh6MKBVXbzcLZUcVe2jz7dzqb6dS/XtfKrzsilLXbl08LaHhwddunRh0aJF9n1Wq5VFixbRs2fPEo/p2bNnkfJga9IqLH/zzTezefNmNm7caN/q1avHlClT+PXXXyvvZkSkxuneJJjIAC8u1Pb5174U7vpsHV2f+43Jczfy+44EcvK0+J6IiNQuLu8KNXnyZMaPH0/Xrl3p3r07M2fO5PTp00ycOBGAW265hfr16zNjxgwAHnjgAfr378+rr77KsGHD+OKLL1i7di3vvvsuACEhIYSEhBS5hru7OxEREbRq1cq5Nyci1ZrFbGLa8Gju/mw9JmxjKgoVJhv/vKI1yaey+XlzHMfSsvh2w1G+3XCUAG93hraNYHiHelzSNBg3i8sn4RMREalULk8sxo4dy/Hjx3nqqaeIj4+nY8eOLFiwwD5A+9ChQ5jNZ/6H3KtXL+bMmcMTTzzB448/TosWLZg3bx4xMTGuugURqcGGxkTy9rjOTP9xW5EpZyMCvJg2PJqhMbaxFVOvaMP6Qyf4aXMcP22OI+lUNnPXHmbu2sOE+npwRUwkV7WPpFtUMGbNICUiIjWQyxMLgEmTJjFp0qQS31u8eHGxfaNHj2b06NEOn7+kcRUiIo4aGhPJoOgIVu5JZOHSVQzu24OezcOKTDFrNpvoGhVM16hgnrwqmlX7k/lxUxwLtsSRdCqHT/86yKd/HSTC34sr20UyvEMkHRsGOjzJhIiISFVXJRILEZGqzmI20aNJMMnbDXo0CT7vuhUWs4lezULp1SyUZ0a0ZfmeJH7aHMevW+OJT8/ig+X7+WD5fhoEeXNV+3oM7xBJdKS/kgwREanWlFiIiFQid4uZAa3CGNAqjOdHxbBkVxI/bjrGb9sTOHIik9l/7mX2n3tpGlqHqzrUY3j7SFqE+7k6bBERkTJTYiEi4iSebhYGRYczKDqczJx8ft+RyE+bj/H7jkT2JZ3mP4t2859Fu2kd4cdV7SO5qn09okIdm/JWRETE1ZRYiIi4gLeHhWHtIxnWPpJT2Xn8ti2BHzcdY8nu4+yIP8mO+JO8snAX7eoHMLxDJMPa16N+oLerwxYRESmVEgsRERfz9XRjZKf6jOxUn7SMXH7dGs+Pm4+xYm8yfx9N4++jafx7/g66NA7iqvaRDGsXSZi/l6vDFhERKUKJhYhIFRLg486Ybg0Z060hyaey+WVLPD9tPsaq/SmsO3iCdQdP8MxP2+jRJJjhHepxRUwkwXU8Sj1fvtVg9f4UEk9mEebnRfcLDDwXEREpLyUWIiJVVIivJ+Muacy4SxqTkJ7F/L/j+HHTMdYfSuWvfSn8tS+Fp77fSu/moVzVPpIhbSMI8Ha3H79gS1yx9Tciz1l/Q0REpKIosRARqQbC/b2Y2LsJE3s34ciJDH4uWIjv76NpLNl1nCW7jvPEd1vo1zKU4R3qYTVg8tyNRVYLB4hPy+Luz9bz9rjOSi5ERKRCKbEQEalmGgT5cGf/ZtzZvxn7k07z06Zj/LQ5jp0JJ/lteyK/bU8s9VgDMAHTf9zGoOgIdYsSEZEKY3Z1ACIiUn5NQutw3+Ut+PWhfix8qB/3X9aciAsM7DaAuLQsVu9PcU6QIiJSKyixEBGpIVqG+zF5cCumXtHaofKLdyaSkZNXyVGJiEhtoa5QIiI1jKNT0b6zZB8fLj9A16gg+raoS98WoURH+mNW9ygRESkHJRYiIjVM9ybBRAZ4EZ+WVWzwdiEfDwuB3u4cS8tixd5kVuxN5sUFEOrrQZ/mofRrWZc+LUIJ89N6GSIi4hglFiIiNYzFbGLa8Gju/mw9JiiSXBS2Rbw2pgND2kawP+k0S3cnsXT3cVbsTSbpVA7zNh5j3sZjALSO8KN/y7r0bVGXrlFBeLlbnH07IiJSTSixEBGpgYbGRPL2uM7F1rGIOGcdi6Z1fWla15fxvaLIybOy/tAJlu4+zpJdSWw5lsaO+JPsiD/JO0v24eVupkeTEPq2sLVotAjzxWRStykREbFRYiEiUkMNjYlkUHSEwytve7iZuaRpCJc0DWHKEEg+lc3yvcks2XWcpbuPk5CezZ+7jvPnruPw83Yi/L3o2yKUvi3r0qd56HlXABcRkZpPiYWISA1mMZvo2SykXMeG+HpydYd6XN2hHoZhsDvxlG0xvt1JrNqXTHx6Fl+tO8JX645gMkG7+gG21owWdenUKAgPN008KCJSmyixEBGRCzKZTLQM96NluB+39W1KVm4+aw6ksHR3Ekt2HWdH/Ek2H0lj85E03vxjL3U8LPRsFkK/gvEZUSE+6jYlIlLDKbEQEZEy83K3FExRW5fHr2xDYnqWfRD40t1JJJ/OKbIKeIMgb/q1rEu/FqH0bBZKgLf7ec+fbzVYtT+FdUkmQvan0LN5mFYJFxGp4pRYiIjIRQvz9+LaLg24tksDrFaDbXHpLNl9nKW7klh7MIUjJzKZs+oQc1YdwmI20bFhoH0QePv6AbhZznSbWrAl7qxB5xY+2b2WyHMGnYuISNWjxEJERCqU2Wwipn4AMfUDuGdAc05n57FqfzJLdtlaNPYeP826gydYd/AEM3/bjb+XG70L1s6wWg2emLel2Pob8WlZ3P3Zet4e11nJhYhIFaXEQkREKlUdTzcuax3OZa3DAThyIoNlu5NYujuJZXuSSMvM5Zct8fyyJb7UcxjY1uCY/uM2BkVHqFuUiEgVpMRCREScqkGQD9d3b8T13RuRbzXYfCSVpbuT+GnzMXYlnCr1OAOIS8ti9f6Ucs90JSIilUeJhYiIuIzFbKJToyA6NQqicYgPD3yx8YLHPDh3A5e3Cad7VDDdmgRTP9C78gMVEZELUmIhIiJVQpifl0PlEtKz7QPBAeoHetO9STDdooLp3iSIZnW1IriIiCsosRARkSqhe5NgIgO8iE/LKjZ4G2xjLML8PZk+vC3rDp1g9YETbDmaxtHUTL7bcJTvNhwFILiOB10bB9G9STDdmwQTHelfZNYpERGpHEosRESkSrCYTUwbHs3dn63HBEWSi8L2h+lXt2VoTCRD29lmhjqdnceGQ6msPpDCmv0prD90gpTTOSzclsDCbQkA1PGw0LlxkL3rVMeGgXi5W5x6byIitYESCxERqTKGxkTy9rjOZ61jYRNRyjoWdTzd6NMilD4tQgHIybPy99E01hQkGmsOpJCelVeweF8SAB4WM+0aBNhaNKKC6RIVhL/X+RfsExGRC1NiISIiVcrQmEgGRUewck8iC5euYnDfHg6vvO3hZqZL4yC6NA7irv7NsFoNdiacZM2BFFbvt22JJ7Pt62i8zV5MJmgd4U+PgnEa3ZoEOTzeQ0REzlBiISIiVY7FbKJHk2CStxv0aBJc7nUrzGYTbSL9aRPpzy09ozAMg0MpGawuaM1YvT+FA8kZbI9LZ3tcOh+tOABAVIjPWQPCg2kU7OPQgPB8q1GQvGQR5udF94uIXUSkulFiISIitYbJZKJxSB0ah9RhdNeGACSmZ7HmwAnWHEhh1f4UdsSncyA5gwPJGXy59ggAYX6e9sHg3aKCaRXuh/mchGHBlrhiXbgiS+nCJSJSEymxEBGRWi3M34th7SMZ1t728J+Wmcv6gydYXdCisflIKokns/lpcxw/bY4DwN/LraDblC3ROJaayf2fbyg2m1V8WhZ3f7aet8d1VnIhIjWeEgsREZGzBHi7c2nrMC5tHQZAVm4+Gw+nsmZ/CqsPpLDu4AnSs/JYtCORRTsSz3suA9uMVtN/3Mag6Ah1ixKRGk2JhYiIyHl4uVu4pGkIlzQNASAv38q2uHT7YPCV+5I5mZVX6vEGEJeWxe/bExjUNsJJUYuIOJ8SCxERkTJws5hp3yCQ9g0Cua1vU77fcJQH5m684HG3f7qOegFeRNcLoG09f2Lq2/6MDPDSSuEiUiMosRAREbkIYf6OT017LC2LY2lZ/LY9wb4vyMedtgXJRnQ9f9rWC6BJaB11mxKRakeJhYiIyEXo3iSYyAAv4tOyig3eBtsYi4gAL+Y/0Jdd8SfZeiy9YEtjT+IpTmTksmxPEsv2JNmP8fGw0CbSn7b1CrcAWoT74ummFcNFpOpSYiEiInIRLGYT04ZHc/dn6zFBkeSisM1h2vBognw86NE0hB4FYzXANjB8V8JJe6Kx9ZhtPY2MnHz7In6F3C0mmof5EVOYbNQPoE2kP76e+l+5iFQN+tdIRETkIg2NieTtcZ2LrWMRcYF1LLzcLfbxGoXyrQb7k06x5eiZZGPrsXTSMnPtC/l9tc5W1mSCqJA6BV2o/Ikp6FIV4utZpvjzrQar9qewLslEyP4Uh1c6FxE5mxILERGRCjA0JpJB0REXvfK2xWxrmWge5sfITvUBMAyDo6mZZ7pRHbUlHPHpWexPOs3+pNP8XLDGBkCEv5e9G1XhYPEGQd4lDhIvurCfhU92r9XCfiJSLkosREREKojFbKJns5ALFywjk8lEgyAfGgT5MOSsKWuTT2UXGbOx9Vg6+5NOE5+eRXx6VpF1NgK83YuM2Whbz5/dCae4d856LewnIhVCiYWIiEg1FeLrSb+WdenXsq5936nsPLbHnWnV2Hosnd2JJ0nLzGXF3mRW7E2+4Hm1sJ+IlIcSCxERkRrE19ONblHBdIsKtu/Lzstnd8KpImM2thxNIzvPWup5Chf2e33RLq7uUI+okDq4WcxOuAMRqa6UWIiIiNRwnm4WYuoHEFM/wL7vuw1HeciBhf3+s2gP/1m0Bw+LmWZhvrSO8KNluB+tI/xoFeGnBf5ExE6JhYiISC0U4eDCfs3q1iEuLYuMnHz7rFRn8/Nyo1W4Hy0jCpKNcFvCEejjURlhi0gVpsRCRESkFnJ0Yb+FD/XHBBw5kcnOhJPsjE9nZ8Ipdsans+/4aU5m5bH24AnWnrXmBkC4v+dZLRv+tAr3o0W4L17uWuRPpKZSYiEiIlILObqwX+HA7UYhPjQK8WFQdLi9XE6elX1Jp9gZf9K+7Yg/ydHUTBLSs0lIz2bp7jMriptN0Dikjr1Vo3BrHOxTrvEb+Vbjoqf3FZGKo8RCRESklirvwn6FPNzMtI7wp3WEf5H9J7Ny2ZVwil0JZxKOnQknSTmdY193Y8HW+CLnaRHma0s0zko6IvxLH79RdP0NG62/IeJaSixERERqscKF/VbuSWTh0lUM7tvjolfe9vNyp0vjILo0DrLvMwyD46ey2RV/ih3x6fakY1fCKTJz8+2zVZ3N38uN1hH+tIzwtXenahXhx8q9Sdz9mdbfEKlqlFiIiIjUchaziR5NgknebtCjkroTmUwmwvy8CPPzok+LUPt+q9Xg8IkMdsSfZFf8SXYk2P7cl3Sa9Kw8Vh9IYfWBlCLnMpsocVyI1t8QcS0lFiIiIuIyZrOJxiF1aBxSp8iq4tl5+ew7fto+bqOwheNoaibWkrKKAoXrbzz+3d/0bRFKVEgdokLr4OupRx6Ryqa/ZSIiIlLleLpZaBPpT5vIouM3vlhziMe++fuCx89dc5i5aw7bX4f6ehIV4kNUaB2ahNahcYiPkg6RCqa/SSIiIlJtNA6u41C5fi1COZ2Tz4Gk0ySfziHpVDZJp7KLTYsLzk868q0Gq/ansC7JRMj+lIse0yJSVSixEBERkWrD0fU3PpzY3f6wnp6Vy8GkDA4kn+ZA0mkOJJ/5uSxJx5k/y590FJ3NysInu9dqNiupMZRYiIiISLVR1vU3APy93GnXIIB2DQKKne/cpGN/8mkOJmdUStKxYEucZrOSGk2JhYiIiFQrF7v+xtmclXQ0CvbhmZ+2aTYrqdGUWIiIiEi1U7j+RmWuvO1I0rE/+TQHy5h0lKRwNqvV+1Po2Sykwu5BxJmUWIiIiEi1ZDGbXPYQXtakY8OhVPYnnb7geSfNWU+7BgE0DfWlad06NK1bh2Z1fQnz8yx1FXKRqqJKJBZvvvkmL7/8MvHx8XTo0IE33niD7t27l1r+q6++4sknn+TAgQO0aNGCF198kSuvvBKA3NxcnnjiCebPn8++ffsICAhg4MCBvPDCC9SrV89ZtyQiIiK1VElJx8q9ydzw3l8XPDb5dA6Ldx5n8c7jRfb7errRJNSWaJyddDQJrYOPR5V4nBNxfWIxd+5cJk+ezOzZs+nRowczZ85kyJAh7Ny5k7CwsGLlV6xYwQ033MCMGTO46qqrmDNnDiNHjmT9+vXExMSQkZHB+vXrefLJJ+nQoQMnTpzggQce4Oqrr2bt2rUuuEMRERGp7RyZzSrM35PXRnfkQMpp9h0/zb7jp9iXdJrDKRmcys7j76Np/H00rdix9QK8aFq3INkIrUOTur40Da1D/UBvzBU8XiPfalRq9zOp3lyeWLz22mvcfvvtTJw4EYDZs2fz888/88EHH/DYY48VK//6668zdOhQpkyZAsCzzz5LbGwss2bNYvbs2QQEBBAbG1vkmFmzZtG9e3cOHTpEo0aNKv+mRERERM7iyGxW069uS+8WofQmtMix2Xn5HE7JYO/xognHvuOnOJGRy7G0LI6lZbFsT1KR4zzdzCW0ctj+9PdyL/M9FJ0q10ZT5crZXJpY5OTksG7dOqZOnWrfZzabGThwICtXrizxmJUrVzJ58uQi+4YMGcK8efNKvU5aWhomk4nAwMAS38/OziY7O9v+Oj09HbB1q8rNzXXwbqSwrlRnzqM6dy7Vt3Opvp1L9V35Lm8VyhvXd+C5+TuITz/z3BER4Mm/rmjN5a1CS6x/M9A4yIvGQV5c1rLomJITGTnsT8pgX9Jp9iedtv98KCWD7DwrO+JPsiP+ZLFzhvp62JKOUB+aFCwM2DTUhwaB3rhZzMXK/7o1gfu+2FTqVLlvXN+BIW3Dy1UvzqLPePmUpb5cmlgkJSWRn59PeHjRD2J4eDg7duwo8Zj4+PgSy8fHx5dYPisri3/+85/ccMMN+Pv7l1hmxowZTJ8+vdj+hQsX4uPj48ityFnObTGSyqc6dy7Vt3Opvp1L9V35/hkNe9NNpOeCvzs08z9N/sF1zD9Y/nP6AG2BtoFAIOQbkJIFiVkmEjMhMdNk/zk910TSqRySTuWw5kDRWassJoNQLwjzMgjzhjBvg1BPg493WwqSiqLdnoyC/z7x7UZyD+RTHXpF6TNeNhkZGQ6XdXlXqMqUm5vLmDFjMAyDt99+u9RyU6dOLdIKkp6eTsOGDRk8eHCpyYgUl5ubS2xsLIMGDcLdvexNrFJ2qnPnUn07l+rbuVTfzuXK+j6ZlceB5NPsS8ooaOWw/Xwg+TRZuVYSMiEh0wSOzZQLmEjNgbrRl9CjSXBlhn5R9Bkvn8KePI5waWIRGhqKxWIhISGhyP6EhAQiIiJKPCYiIsKh8oVJxcGDB/n999/PmyB4enri6elZbL+7u7s+eOWgenM+1blzqb6dS/XtXKpv53JFfQe7uxPs503nqKL7rVaDuPQs2xiOs8ZybDmaxomMC3eHue+LTbQI86N+kDcNgrypH+hNgyAf6gd5Uy/QC083S+XcUBnpM142ZakrlyYWHh4edOnShUWLFjFy5EgArFYrixYtYtKkSSUe07NnTxYtWsSDDz5o3xcbG0vPnj3trwuTit27d/PHH38QEqKFZkRERETOx2w2UT/QlhD0bVHXvt/RqXJPZOSy+kAKHCj5/TA/z4Kkw6cg6fC2vQ60/VmZ0+bmWw1W7U9hXZKJkP0p9GweptmsKoHLu0JNnjyZ8ePH07VrV7p3787MmTM5ffq0fZaoW265hfr16zNjxgwAHnjgAfr378+rr77KsGHD+OKLL1i7di3vvvsuYEsqrrvuOtavX89PP/1Efn6+ffxFcHAwHh4errlRERERkWrI0alyZ93Ymbi0LI6eyORoagZHTmRy9EQmR05kkpmbT+LJbBJPZrPhUGqJ1wmu42Fv6TiTePjYE5DyzGQF585mZeGT3Ws1m1UlcXliMXbsWI4fP85TTz1FfHw8HTt2ZMGCBfYB2ocOHcJsPjM7Qa9evZgzZw5PPPEEjz/+OC1atGDevHnExMQAcPToUX744QcAOnbsWORaf/zxBwMGDHDKfYmIiIjUBI5OldstquTxFYZhcCIjtyDJyOBoqi3ZOHLW65NZeaScziHldA6bjxRfqwPA38uN+me1djSwd7myJR+BPu7FVidfsCWOuz9bX+psVm+P66zkogK5PLEAmDRpUqldnxYvXlxs3+jRoxk9enSJ5aOiojCMkvJpERERESmPoTGRvD2uc7F1LCIc+ObfZDIRXMeD4DoeRVYjP1taZm5BS0dBslGQeBxNtW0pp3NIz8ojPS6d7XElDyb28bAU6WJVL9Cbd//cV2Iri4EtKZr+4zYGRUeoW1QFqRKJhYiIiIhUbUNjIhkUHVEpK28HeLsT4O1OdL2SJ9s5nZ3HscKWjrOSj8LWj+Mns8nIyWd34il2J55y6JoGEJeWxer9KfRspvG4FUGJhYiIiIg4xGI2ueQhvI6nGy3C/WgR7lfi+1m5+RwraN0obO34a18yaw9eeM7c/UmnlFhUECUWIiIiIlKteblbaFrXl6Z1fe37HJ3N6ol5W/hlSzxXxEQypG04Ib7FlyAQxyixEBEREZEa50KzWQG4mU3kWQ2W7k5i6e4knpj3N5c0DeHKdpEMjYkgVElGmSixEBEREZEax5HZrGbd2InWEf78siWe+X/H8ffRNFbsTWbF3mSe+n4L3ZsEM6xdJENiIgjz83LBXVQvSixEREREpEZydDaruwc04+4BzTiUnMEvW+KY/3ccm46k8de+FP7al8JTP2ylW5QtybgiJoIwfyUZJVFiISIiIiI1VuFsViv3JLJw6SoG9+1R6srbjUJ8uLN/M+7s34zDKRks2BLPz3/HsfFwKqv3p7B6fwpP/7iVro2DuLJdJFfERBIRoCSjkBILEREREanRLGYTPZoEk7zdoIeDU+Q2DPbh9n5Nub1fU46mZvLL37aWjPWHUllz4ARrDpxg+o/b6GJPMiKoF+jthLupupRYiIiIiIicR/1Ab27r25Tb+jYlLi2TX/62jclYe/AE6wq2Z3/aRqdGgQwrGPjdIMjH1WE7nRILEREREREHRQZ4c2ufJtzapwnxaVks2BLH/L/jWXMwhQ2HUtlwKJXnft5Oh4aBDGsXwRUxkTQMrh1JhhILEREREZFyiAjwYkLvJkzo3YTE9CwWbI3n581xrD6QwqbDqWw6nMq/5++gfYMArmwXyZUxkTQKqblJhhILEREREZGLFObvxS09o7ilZxSJJ7P4dWsCv/wdx1/7ktl8JI3NR9J44ZcdxNT3tycZUaF1znvOfKvB6v0pJJ7MIszPi+4Ojg9xFSUWIiIiIiIVKMzPi5svaczNlzQm6VQ2v26N55e/41m5L5ktR9PZcjSdlxbsJDrSnyvbRXBlu8giq4YDLNgSV2ya3MhzpsmtapRYiIiIyP+3d/9BUdX7H8dfhx8uKwEJjrCoKJajgmg6/khxpim9qTk0lObVQUL9w9FQwcrBsUgbf6V907IfmE75j78mmzBztCKHLL2pJGk4KurNMYuQupUgDF4ue75/+JX5bpp6O3AOHp6PmZ1hz1n0te9ZWV6e8zkLoIV0vMujjKHdlDG0m/51+Yo+PXFRu8t+0j/++S+d+KlaJ36q1v98elq94yKuHslI8elsVY1mbSq97hPDKy/Va9amUhVMGdgqywXFAgAAALBBzF0eTR6SoMlDEvRb7b/16YlK7S6r1IGzv+hUZY1OVdZoddFphQQZ15UK6eqnhxuSXvzohP6WFNfqTouiWAAAAAA26xDeTn8fnKC/D07Q73X/1qcnrq7J+OLMz/qP/0a14ipT0k+X6nX43K8adk+MfYFvQ5DTAQAAAIC27O727TRxUFdtnDZEy9JTbut7qmrqb/0gm1EsAAAAgFaiW8zNrxR1TaeIsBZO8t+jWAAAAACtxJDEaPmiwvRnqycMXb061JDEaDtj3RaKBQAAANBKBAcZWpSWJEnXlYtr9xelJbW6hdsSxQIAAABoVcb09algykDFRQWe7hQXFdZqLzUrcVUoAAAAoNUZ09envyXF8cnbAAAAAKwJDjJa3SVlb4ZToQAAAABYRrEAAAAAYBnFAgAAAIBlFAsAAAAAllEsAAAAAFhGsQAAAABgGcUCAAAAgGUUCwAAAACWUSwAAAAAWEaxAAAAAGAZxQIAAACAZSFOB2iNTNOUJFVXVzuc5M7S0NCguro6VVdXKzQ01Ok4bQIztxfzthfzthfzthfzth8z/2uu/T587ffjm6FY3EBNTY0kqWvXrg4nAQAAAJxXU1OjqKiomz7GMG+nfrQxfr9fFRUVioiIkGEYTse5Y1RXV6tr1666cOGCIiMjnY7TJjBzezFvezFvezFvezFv+zHzv8Y0TdXU1Cg+Pl5BQTdfRcERixsICgpSly5dnI5xx4qMjOQfrM2Yub2Yt72Yt72Yt72Yt/2Y+X/vVkcqrmHxNgAAAADLKBYAAAAALKNYoNl4PB4tWrRIHo/H6ShtBjO3F/O2F/O2F/O2F/O2HzNveSzeBgAAAGAZRywAAAAAWEaxAAAAAGAZxQIAAACAZRQLWLZixQoNHjxYERER6tSpk9LT01VeXu50rDbjpZdekmEYys3NdTqKa/3444+aMmWKYmJi5PV6lZKSoq+//trpWK7V2Nio/Px8JSYmyuv16p577tGSJUvEksDm8cUXXygtLU3x8fEyDEM7duwI2G+apl544QX5fD55vV6NGjVKZ86ccSasC9xs3g0NDcrLy1NKSorCw8MVHx+vJ598UhUVFc4FvsPd6vX9/82cOVOGYejVV1+1LZ/bUSxg2b59+5Sdna2DBw+qqKhIDQ0Nevjhh1VbW+t0NNcrKSnR22+/rX79+jkdxbV+++03paamKjQ0VHv27NGJEyf0yiuvqEOHDk5Hc62VK1eqoKBAb7zxhk6ePKmVK1dq1apVev31152O5gq1tbXq37+/3nzzzRvuX7VqldauXat169bp0KFDCg8P1+jRo1VfX29zUne42bzr6upUWlqq/Px8lZaW6oMPPlB5ebkeffRRB5K6w61e39cUFhbq4MGDio+PtylZG2ECzayqqsqUZO7bt8/pKK5WU1Nj9uzZ0ywqKjIfeOABMycnx+lIrpSXl2eOGDHC6Rhtyrhx48zp06cHbHv88cfNjIwMhxK5lySzsLCw6b7f7zfj4uLMl19+uWnb77//bno8HnPr1q0OJHSXP877Rg4fPmxKMs+fP29PKBf7s3n/8MMPZufOnc3jx4+b3bp1M9esWWN7NrfiiAWa3aVLlyRJ0dHRDidxt+zsbI0bN06jRo1yOoqr7dy5U4MGDdITTzyhTp06acCAAdqwYYPTsVxt+PDh2rt3r06fPi1JOnbsmPbv36+xY8c6nMz9zp07p8rKyoCfK1FRURo6dKi++uorB5O1HZcuXZJhGLr77rudjuJKfr9fmZmZmj9/vpKTk52O4zohTgeAu/j9fuXm5io1NVV9+/Z1Oo5rbdu2TaWlpSopKXE6iut99913Kigo0NNPP62FCxeqpKREc+fOVbt27ZSVleV0PFdasGCBqqur1bt3bwUHB6uxsVHLli1TRkaG09Fcr7KyUpIUGxsbsD02NrZpH1pOfX298vLyNHnyZEVGRjodx5VWrlypkJAQzZ071+korkSxQLPKzs7W8ePHtX//fqejuNaFCxeUk5OjoqIihYWFOR3H9fx+vwYNGqTly5dLkgYMGKDjx49r3bp1FIsW8t5772nz5s3asmWLkpOTdfToUeXm5io+Pp6Zw7UaGho0ceJEmaapgoICp+O40pEjR/Taa6+ptLRUhmE4HceVOBUKzWb27NnatWuXiouL1aVLF6fjuNaRI0dUVVWlgQMHKiQkRCEhIdq3b5/Wrl2rkJAQNTY2Oh3RVXw+n5KSkgK29enTR99//71Didxv/vz5WrBggSZNmqSUlBRlZmZq3rx5WrFihdPRXC8uLk6SdPHixYDtFy9ebNqH5netVJw/f15FRUUcrWghX375paqqqpSQkND0/nn+/Hk988wz6t69u9PxXIEjFrDMNE3NmTNHhYWF+vzzz5WYmOh0JFcbOXKkysrKArZNmzZNvXv3Vl5enoKDgx1K5k6pqanXXT759OnT6tatm0OJ3K+urk5BQYH/7xUcHCy/3+9QorYjMTFRcXFx2rt3r+677z5JUnV1tQ4dOqRZs2Y5G86lrpWKM2fOqLi4WDExMU5Hcq3MzMzr1iWOHj1amZmZmjZtmkOp3IViAcuys7O1ZcsWffjhh4qIiGg6DzcqKkper9fhdO4TERFx3fqV8PBwxcTEsK6lBcybN0/Dhw/X8uXLNXHiRB0+fFjr16/X+vXrnY7mWmlpaVq2bJkSEhKUnJysb775RqtXr9b06dOdjuYKly9f1tmzZ5vunzt3TkePHlV0dLQSEhKUm5urpUuXqmfPnkpMTFR+fr7i4+OVnp7uXOg72M3m7fP5NGHCBJWWlmrXrl1qbGxseg+Njo5Wu3btnIp9x7rV6/uPxS00NFRxcXHq1auX3VHdyenLUuHOJ+mGt40bNzodrc3gcrMt66OPPjL79u1rejwes3fv3ub69eudjuRq1dXVZk5OjpmQkGCGhYWZPXr0MJ977jnzypUrTkdzheLi4hv+zM7KyjJN8+olZ/Pz883Y2FjT4/GYI0eONMvLy50NfQe72bzPnTv3p++hxcXFTke/I93q9f1HXG62eRmmyUeZAgAAALCGxdsAAAAALKNYAAAAALCMYgEAAADAMooFAAAAAMsoFgAAAAAso1gAAAAAsIxiAQAAAMAyigUAAAAAyygWAABXMQxDO3bscDoGALQ5FAsAQLOZOnWqDMO47jZmzBinowEAWliI0wEAAO4yZswYbdy4MWCbx+NxKA0AwC4csQAANCuPx6O4uLiAW4cOHSRdPU2poKBAY8eOldfrVY8ePfT+++8HfH9ZWZkeeugheb1excTEaMaMGbp8+XLAY959910lJyfL4/HI5/Np9uzZAft/+eUXPfbYY2rfvr169uypnTt3tuyTBgBQLAAA9srPz9f48eN17NgxZWRkaNKkSTp58qQkqba2VqNHj1aHDh1UUlKi7du367PPPgsoDgUFBcrOztaMGTNUVlamnTt36t577w34O1588UVNnDhR3377rR555BFlZGTo119/tfV5AkBbY5imaTodAgDgDlOnTtWmTZsUFhYWsH3hwoVauHChDMPQzJkzVVBQ0LTv/vvv18CBA/XWW29pw4YNysvL04ULFxQeHi5J2r17t9LS0lRRUaHY2Fh17txZ06ZN09KlS2+YwTAMPf/881qyZImkq2Xlrrvu0p49e1jrAQAtiDUWAIBm9eCDDwYUB0mKjo5u+nrYsGEB+4YNG6ajR49Kkk6ePKn+/fs3lQpJSk1Nld/vV3l5uQzDUEVFhUaOHHnTDP369Wv6Ojw8XJGRkaqqqvqrTwkAcBsoFgCAZhUeHn7dqUnNxev13tbjQkNDA+4bhiG/398SkQAA/4c1FgAAWx08ePC6+3369JEk9enTR8eOHVNtbW3T/gMHDigoKEi9evVSRESEunfvrr1799qaGQBwaxyxAAA0qytXrqiysjJgW0hIiDp27ChJ2r59uwYNGqQRI0Zo8+bNOnz4sN555x1JUkZGhhYtWqSsrCwtXrxYP//8s+bMmaPMzEzFxsZKkhYvXqyZM2eqU6dOGjt2rGpqanTgwAHNmTPH3icKAAhAsQAANKuPP/5YPp8vYFuvXr106tQpSVev2LRt2zY99dRT8vl82rp1q5KSkiRJ7du31yeffKKcnBwNHjxY7du31/jx47V69eqmPysrK0v19fVas2aNnn32WXXs2FETJkyw7wkCAG6Iq0IBAGxjGIYKCwuVnp7udBQAQDNjjQUAAAAAyygWAAAAACxjjQUAwDacfQsA7sURCwAAAACWUSwAAAAAWEaxAAAAAGAZxQIAAACAZRQLAAAAAJZRLAAAAABYRrEAAAAAYBnFAgAAAIBlFAsAAAAAlv0v3IEtAVayya0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nn_model import EmbeddingClassifier\n",
    "\n",
    "# Prepare feature matrix and labels\n",
    "X_train = df_physionet_train.iloc[:, :ld].values  \n",
    "X_test = df_physionet_test.iloc[:, :ld].values  \n",
    "y_train = np.array(df_physionet_train['diagnostic'].tolist(), dtype=int)  \n",
    "y_test = np.array(df_physionet_test['diagnostic'].tolist(), dtype=int)  \n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)  # note: float for BCE loss\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Split into train and validation sets\n",
    "val_ratio = 0.2\n",
    "total_samples = X_train_tensor.size(0)\n",
    "val_size = int(val_ratio * total_samples)\n",
    "train_size = total_samples - val_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    TensorDataset(X_train_tensor, y_train_tensor),\n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)  # for reproducibility\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Init model\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = y_train.shape[1]\n",
    "model = EmbeddingClassifier(input_dim=input_dim, output_dim=output_dim)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "\n",
    "# Training loop\n",
    "epochs = 15\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "print(\"üöÄ Starting training...\")\n",
    "for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(xb)\n",
    "        loss = criterion(output, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            output = model(xb)\n",
    "            loss = criterion(output, yb)\n",
    "            total_val_loss += loss.item()\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    print(f\"üìâ Epoch {epoch+1}/{epochs} - Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "# Plot and save loss curves\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, epochs + 1), train_losses, marker='o', label='Train Loss')\n",
    "plt.plot(range(1, epochs + 1), val_losses, marker='s', label='Val Loss')\n",
    "plt.title(\"Training & Validation Loss Over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"vae_train_val_loss.png\")\n",
    "print(\"üìà Saved training+validation loss plot as 'vae_train_val_loss.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Get probabilities from model\n",
    "with torch.no_grad():\n",
    "    logits = model(X_train_tensor)\n",
    "    probs_val = torch.sigmoid(logits).cpu().numpy()\n",
    "\n",
    "# Ground truth\n",
    "y_train = y_train_tensor.cpu().numpy()\n",
    "\n",
    "# Search for optimal thresholds (grid search over 0.0‚Äì1.0)\n",
    "best_thresholds = []\n",
    "for i in range(y_train.shape[1]):\n",
    "    best_f1 = 0\n",
    "    best_thresh = 0.5\n",
    "    for t in np.linspace(0.1, 0.9, 17):  # test thresholds from 0.1 to 0.9\n",
    "        preds = (probs_val[:, i] > t).astype(int)\n",
    "        f1 = f1_score(y_train[:, i], preds, zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_thresh = t\n",
    "    best_thresholds.append(best_thresh)\n",
    "\n",
    "best_thresholds = np.array(best_thresholds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Overall Accuracy: 0.29430604982206404\n",
      "‚úÖ F1 Score (Macro): 0.2343608589329397\n",
      "‚úÖ F1 Score (Micro): 0.42501562557446965\n",
      "‚úÖ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.33      0.30       791\n",
      "           1       0.40      0.38      0.39      1155\n",
      "           2       0.28      0.02      0.03       272\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.57      0.23      0.32       124\n",
      "           5       0.76      0.63      0.69       580\n",
      "           6       0.37      0.22      0.28       319\n",
      "           7       0.10      0.08      0.09       186\n",
      "           8       0.38      0.35      0.36       740\n",
      "           9       0.49      0.30      0.37       249\n",
      "          10       0.00      0.00      0.00        30\n",
      "          11       0.15      0.09      0.11       208\n",
      "          12       0.07      0.03      0.04       222\n",
      "          13       0.01      0.01      0.01       128\n",
      "          14       0.56      0.58      0.57      3135\n",
      "          15       0.03      0.01      0.02       574\n",
      "          16       0.47      0.47      0.47        89\n",
      "          17       0.00      0.00      0.00        99\n",
      "          18       0.05      0.04      0.05       164\n",
      "          19       0.04      0.02      0.03       261\n",
      "          20       0.16      0.11      0.13       203\n",
      "          21       0.19      0.18      0.19       296\n",
      "          22       0.61      0.73      0.66      1247\n",
      "          23       0.62      0.75      0.68      1473\n",
      "          24       0.23      0.20      0.21      1229\n",
      "          25       0.09      0.10      0.09       288\n",
      "\n",
      "   micro avg       0.44      0.41      0.43     14068\n",
      "   macro avg       0.27      0.23      0.23     14068\n",
      "weighted avg       0.41      0.41      0.40     14068\n",
      " samples avg       0.40      0.38      0.38     14068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Get predictions\n",
    "with torch.no_grad():\n",
    "    logits = model(X_test_tensor)\n",
    "    probs = torch.sigmoid(logits)\n",
    "    # Make sure best_thresholds is a torch tensor, same shape as probs\n",
    "    thresholds_tensor = torch.tensor(best_thresholds, dtype=torch.float32).to(probs.device)\n",
    "\n",
    "    # Apply thresholds with broadcasting\n",
    "    y_pred = (probs > thresholds_tensor).int().cpu().numpy()\n",
    "# Convert ground truth to numpy (if it's still a tensor)\n",
    "y_true = y_test_tensor.cpu().numpy()\n",
    "\n",
    "# Compute metrics\n",
    "f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "f1_micro = f1_score(y_true, y_pred, average='micro', zero_division=0)\n",
    "overall_accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Generate classification report (per label)\n",
    "class_report = classification_report(\n",
    "    y_true, y_pred,\n",
    "    target_names=[str(i) for i in range(y_true.shape[1])],\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(\"‚úÖ Overall Accuracy:\", overall_accuracy)\n",
    "print(\"‚úÖ F1 Score (Macro):\", f1_macro)\n",
    "print(\"‚úÖ F1 Score (Micro):\", f1_micro)\n",
    "print(\"‚úÖ Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the multi-class prediction, i.e. the separation of the classes \"sinus\", \"rbbb\", \"lbbb\" and \"avblock\", we used the k-nearest neighbor classification. The hyperparameter $k$ was determined using the Medalcare validation dataset as a cross-validation set. The best result $k$ was then used to train the kNN classifier based on the Medalcare training dataset and on the Medalcare test dataset that had never been used before (i.e. it was never included in any training process, neither in the VAE nor in the kNN process)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 47 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n47 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\Thomas Kaprielian\\Documents\\Master's Thesis\\VECG\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\Thomas Kaprielian\\Documents\\Master's Thesis\\VECG\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\Thomas Kaprielian\\Documents\\Master's Thesis\\VECG\\venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 662, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"c:\\Users\\Thomas Kaprielian\\Documents\\Master's Thesis\\VECG\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\Thomas Kaprielian\\Documents\\Master's Thesis\\VECG\\venv\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 239, in fit\n    return self._fit(X, y)\n  File \"c:\\Users\\Thomas Kaprielian\\Documents\\Master's Thesis\\VECG\\venv\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 478, in _fit\n    X, y = validate_data(\n  File \"c:\\Users\\Thomas Kaprielian\\Documents\\Master's Thesis\\VECG\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2961, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"c:\\Users\\Thomas Kaprielian\\Documents\\Master's Thesis\\VECG\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1387, in check_X_y\n    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n  File \"c:\\Users\\Thomas Kaprielian\\Documents\\Master's Thesis\\VECG\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1397, in _check_y\n    y = check_array(\n  File \"c:\\Users\\Thomas Kaprielian\\Documents\\Master's Thesis\\VECG\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1107, in check_array\n    _assert_all_finite(\n  File \"c:\\Users\\Thomas Kaprielian\\Documents\\Master's Thesis\\VECG\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 104, in _assert_all_finite\n    if _object_dtype_isnan(X).any():\n  File \"c:\\Users\\Thomas Kaprielian\\Documents\\Master's Thesis\\VECG\\venv\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 84, in _object_dtype_isnan\n    return X != X\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[0m best_k \u001b[38;5;241m=\u001b[39m \u001b[43mHelper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_validation_knn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Thomas Kaprielian\\Documents\\Master's Thesis\\VECG\\src\\utils\\helper.py:504\u001b[0m, in \u001b[0;36mHelper.cross_validation_knn\u001b[1;34m(X_train, X_val, y_train_labels, y_val_labels, scoring)\u001b[0m\n",
      "\u001b[0;32m    501\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknn__n_neighbors\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m50\u001b[39m)}\n",
      "\u001b[0;32m    503\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeline, param_grid, cv\u001b[38;5;241m=\u001b[39mps, scoring\u001b[38;5;241m=\u001b[39mscoring)\n",
      "\u001b[1;32m--> 504\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_combined\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_combined\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# Get the best k value\u001b[39;00m\n",
      "\u001b[0;32m    507\u001b[0m best_k \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknn__n_neighbors\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Thomas Kaprielian\\Documents\\Master's Thesis\\VECG\\venv\\lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n",
      "\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n",
      "\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n",
      "\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n",
      "\u001b[0;32m   1387\u001b[0m     )\n",
      "\u001b[0;32m   1388\u001b[0m ):\n",
      "\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Thomas Kaprielian\\Documents\\Master's Thesis\\VECG\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n",
      "\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n",
      "\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n",
      "\u001b[0;32m   1020\u001b[0m     )\n",
      "\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n",
      "\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n",
      "\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Thomas Kaprielian\\Documents\\Master's Thesis\\VECG\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n",
      "\u001b[0;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n",
      "\u001b[0;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m-> 1571\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Thomas Kaprielian\\Documents\\Master's Thesis\\VECG\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1001\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n",
      "\u001b[0;32m    994\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n",
      "\u001b[0;32m    995\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[0;32m    996\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    997\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    998\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n",
      "\u001b[0;32m    999\u001b[0m     )\n",
      "\u001b[1;32m-> 1001\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1003\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n",
      "\u001b[0;32m   1004\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n",
      "\u001b[0;32m   1005\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n",
      "\u001b[0;32m   1006\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n",
      "\u001b[0;32m   1007\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Thomas Kaprielian\\Documents\\Master's Thesis\\VECG\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:517\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n",
      "\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n",
      "\u001b[0;32m    511\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n",
      "\u001b[0;32m    512\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    514\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    515\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    516\u001b[0m     )\n",
      "\u001b[1;32m--> 517\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n",
      "\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m    520\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n",
      "\u001b[0;32m    521\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    522\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    526\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    527\u001b[0m     )\n",
      "\n",
      "\u001b[1;31mValueError\u001b[0m: \n",
      "All the 47 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "47 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Thomas Kaprielian\\Documents\\Master's Thesis\\VECG\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Thomas Kaprielian\\Documents\\Master's Thesis\\VECG\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Thomas Kaprielian\\Documents\\Master's Thesis\\VECG\\venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 662, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\Thomas Kaprielian\\Documents\\Master's Thesis\\VECG\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Thomas Kaprielian\\Documents\\Master's Thesis\\VECG\\venv\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 239, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"c:\\Users\\Thomas Kaprielian\\Documents\\Master's Thesis\\VECG\\venv\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 478, in _fit\n",
      "    X, y = validate_data(\n",
      "  File \"c:\\Users\\Thomas Kaprielian\\Documents\\Master's Thesis\\VECG\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2961, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\Users\\Thomas Kaprielian\\Documents\\Master's Thesis\\VECG\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1387, in check_X_y\n",
      "    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n",
      "  File \"c:\\Users\\Thomas Kaprielian\\Documents\\Master's Thesis\\VECG\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1397, in _check_y\n",
      "    y = check_array(\n",
      "  File \"c:\\Users\\Thomas Kaprielian\\Documents\\Master's Thesis\\VECG\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1107, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"c:\\Users\\Thomas Kaprielian\\Documents\\Master's Thesis\\VECG\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 104, in _assert_all_finite\n",
      "    if _object_dtype_isnan(X).any():\n",
      "  File \"c:\\Users\\Thomas Kaprielian\\Documents\\Master's Thesis\\VECG\\venv\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 84, in _object_dtype_isnan\n",
      "    return X != X\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n"
     ]
    }
   ],
   "source": [
    "best_k = Helper.cross_validation_knn(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "cm, classes, predictions = Visualizations.plot_confustion_matrix(\n",
    "    X_train, X_test, y_train, y_test,\n",
    "    KNeighborsClassifier(n_neighbors=best_k),\n",
    "    '../analysis/media/confusion_matrix_multiclass_medalcare_diagnostic.png',\n",
    "    dpi=DPI,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Helper.calculate_f1(cm, include)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualizations.print_metrics_multiclass(cm, y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with multi-class prediction, the same approach was followed for binary classification, i.e. the \"sinus\" samples were separated from the \"rbbb\", \"lbbb\" and \"avblock\" classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k = Helper.cross_validation_knn(X_train, X_val, y_train_b, y_val_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm, classes, predictions_b = Visualizations.plot_confustion_matrix(\n",
    "    X_train, X_test, y_train_b, y_test_b,\n",
    "    KNeighborsClassifier(n_neighbors=best_k),\n",
    "    '../analysis/media/confusion_matrix_binary_medalcare_diagnostic.png',\n",
    "    dpi=DPI,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualizations.print_metrics_binary(cm, y_test_b, predictions_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we would like to use distribution diagrams to investigate how well the pathologies can be separated along the explainable axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_df = df_medalcare_test[df_medalcare_test.diagnosis.isin(include)].loc[:, list([3, 4, 6, 10]) + ['diagnosis']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_df.diagnosis = pair_df.diagnosis.replace('sinus', 'Sinus').replace('rbbb', 'RBBB').replace('lbbb', 'LBBB').replace('avblock', 'AVBlock').replace('miLCX', 'MI LCX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = {'diagnosis': 'Diagnosis'}\n",
    "pair_df = pair_df.rename(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = {'Sinus': 'tab:orange', 'MI LCX': 'tab:blue', 'LBBB': 'tab:purple', 'RBBB': 'tab:green', 'AVBlock': 'tab:red'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 20\n",
    "pairplot = sns.pairplot(pair_df, hue=\"Diagnosis\", plot_kws={\"s\": 1}, diag_kws={'common_norm': False}, palette=palette, aspect=1.3)\n",
    "\n",
    "for handle in pairplot._legend.legendHandles:\n",
    "    handle.set_markersize(10)\n",
    "sns.move_legend(pairplot, \"upper center\", bbox_to_anchor=(.45, 1.08), ncol=5, frameon=False)\n",
    "for ax in pairplot.axes[:, 0]:\n",
    "    ax.yaxis.set_label_coords(-0.3, 0.5)\n",
    "\n",
    "pairplot.savefig('../analysis/media/anomaly_interpretation_medalcare.png', dpi=DPI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Personalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subjects from the _icentia11k_ data set are used for personalization. For each of the 100 subjects randomly selected from the total dataset, the base model is fine-tuned and the embedding is saved. From the 100 randomly selected samples of the icentia11k dataset, a set of 6 subjects was selected for the analysis of the distribution graphs. 3 samples were selected because they contained a large number of PAC samples, while the other 3 samples were selected because of the frequent occurrence of PVC. All 6 samples also had a high number of normal class ECG beats. A custom color palette is defined for the classes Normal, PVC, and PAC to adhere to consisting coloring throughout the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluate.personalization import fine_tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'name': ['icentia11k'],\n",
    "    'shuffle_size': 1024,\n",
    "    'batch_size': 1024,\n",
    "}\n",
    "\n",
    "splits = [\n",
    "    '107', '5484', '6998', '3984', '3111', '4040', '3013', '6607', '4219', '8750', '5665', '9225',\n",
    "    '8030', '9886', '1851', '1123', '3043', '3369', '6829', '10969', '3088', '9405', '9535', '4993',\n",
    "    '4209', '10937', '6167', '4688', '6877', '10733', '8412', '10146', '10973', '9345', '2514', '2908',\n",
    "    '5938', '5015', '9595', '8769', '4786', '2602', '7779', '2826', '1118', '3485', '2980', '10503',\n",
    "    '7719', '6575', '1722', '7234', '8366', '3948', '5493', '10731', '8111', '2820', '5337', '5369',\n",
    "    '4184', '9403', '9625', '303', '33', '3274', '1941', '9116', '9283', '3522', '4836', '7107', '251',\n",
    "    '9071', '6899', '9733', '9440', '457', '2954', '1839', '5865', '8500', '9559', '1277', '1145', '10107',\n",
    "    '9287', '8443', '9783', '9956', '10090', '3204', '6814', '4553', '6377', '5572', '1178', '5032', '1793', '4453',\n",
    "]\n",
    "\n",
    "subjects = ['2602', '9225', '10973', '1851', '5938', '10146']\n",
    "# use a custom order to stay consistent in the order of presentation\n",
    "custom_sort_order = [2602, 9225, 10973, 1851, 5938, 10146]\n",
    "\n",
    "palette = {'Normal': 'C0', 'PVC': 'C2', 'PAC': 'C1'}\n",
    "\n",
    "ld = 12\n",
    "path_save = '../analysis/personalization/embeddings_vae/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_PRECOMPUTED:\n",
    "    fine_tune(path_model, datasets, splits, ld, path_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personlized Models: Accuracy\n",
    "\n",
    "Let's load the emebddings from the personalzed computations and train a kNN on the train set (80 % of the complete dataset) and save the confusion matrix based on the test set (remaining 20 %)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confustion_matrix(X_train, X_test, y_train, y_test, predictor, path, dpi, normalize=False, cmap='Greens'):\n",
    "        predictor.fit(X_train.fillna(0), y_train)\n",
    "        predictions = predictor.predict(X_test.fillna(0))\n",
    "        cm = confusion_matrix(y_test, predictions, labels=predictor.classes_)\n",
    "        return cm, predictor.classes_, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_PRECOMPUTED:\n",
    "    for k in glob.glob('../analysis/personalization/embeddings_vae/*.csv'):\n",
    "        try:\n",
    "            df_pers = pd.read_csv(k)\n",
    "            df_pers[\"beat_b\"] = df_pers.beat.replace(0.0, 'Normal').replace(1.0, 'Unclassified').replace(2.0, 'Anomal').replace(3.0, 'Anomal')\n",
    "            df_pers.beat = df_pers.beat.replace(0.0, 'Normal').replace(1.0, 'Unclassified').replace(2.0, 'PAC').replace(3.0, 'PVC')\n",
    "            df_pers = df_pers[df_pers.beat != 'Unclassified'].drop('Unnamed: 0', axis=1)\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                        df_pers.iloc[:, :ld],\n",
    "                        df_pers.beat,\n",
    "                        test_size=0.2,\n",
    "                        random_state=42,\n",
    "                        stratify=df_pers.beat,\n",
    "                    )\n",
    "            cm, classes, prediction = plot_confustion_matrix(\n",
    "                        X_train, X_test, y_train, y_test,\n",
    "                        KNeighborsClassifier(n_neighbors=13),\n",
    "                        '../analysis/media/test.png',\n",
    "                        dpi=10,\n",
    "                    )\n",
    "            pred_df = pd.DataFrame(cm, columns=classes, index=classes)\n",
    "            pred_df.to_csv('../analysis/personalization/confusion_matrices/' + k.split('/')[-1])\n",
    "            \n",
    "            if df_pers.groupby('beat_b')['beat_b'].count()['Anomal'] > 500:\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                        df_pers.iloc[:, :ld],\n",
    "                        df_pers.beat_b,\n",
    "                        test_size=0.2,\n",
    "                        random_state=42,\n",
    "                        stratify=df_pers.beat_b,\n",
    "                    )\n",
    "                cm, classes, prediction = plot_confustion_matrix(\n",
    "                        X_train, X_test, y_train, y_test,\n",
    "                        KNeighborsClassifier(n_neighbors=13),\n",
    "                        '../analysis/media/test.png',\n",
    "                        dpi=10,\n",
    "                    )\n",
    "                pred_df = pd.DataFrame(cm, columns=classes, index=classes)\n",
    "                pred_df.to_csv('../analysis/personalization/confusion_matrices_b/' + k.split('/')[-1])\n",
    "        except Exception as e:\n",
    "            print('Skipped', e)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to merge the confusion matrices to evaluate the overall goodness of fit. Therefore, we load the confusion matrices and:\n",
    "1. sum them element by element and then normalize them per row\n",
    "2. normalize them per subject and row and then sum them together\n",
    "\n",
    "Both versions offer a different view of the matter. However, the latter (2) offers a more unbiased way to evaluate performance, as highly unbalanced class distributions are not as significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df_unbiased = pd.DataFrame()\n",
    "files = glob.glob('../analysis/personalization/confusion_matrices/*.csv')\n",
    "files_b = glob.glob('../analysis/personalization/confusion_matrices_b/*.csv')\n",
    "individual_f1_scores = []\n",
    "index_and_columns = ['Normal', 'PAC', 'PVC']\n",
    "index_and_columns_b = ['Normal', 'Anomal']\n",
    "\n",
    "for i, k in enumerate(files):\n",
    "    temp = pd.read_csv(k, index_col=0)\n",
    "    temp = temp.reindex(index=index_and_columns, columns=index_and_columns, fill_value=0)\n",
    "    df = df.add(temp, fill_value=0)\n",
    "\n",
    "for i, k in enumerate(files_b):\n",
    "    temp = pd.read_csv(k, index_col=0)\n",
    "    temp = temp.reindex(index=index_and_columns_b, columns=index_and_columns_b, fill_value=0)\n",
    "    individual_f1_result = Helper.calculate_f1(temp.to_numpy(), temp.columns)\n",
    "    individual_f1_scores.append(individual_f1_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Helper.calculate_f1(df.to_numpy(), df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_metrics_b = {\n",
    "    'Macro F1': 0,\n",
    "    'Precision': {'Normal': 0, 'Anomal': 0},\n",
    "    'Recall': {'Normal': 0, 'Anomal': 0},\n",
    "    'F1 Scores': {'Normal': 0, 'Anomal': 0},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Helper.average_metrics(individual_f1_scores, avg_metrics_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personlized Models: Inter-subject patterns\n",
    "\n",
    "We load the embedding (of the base model) of all subjects from the convenience sample and embed them in a 2-dimensional space using TSNE. Due to computational limitations, only a small portion (20%) of the total available data is used. However, the uniform subsample should capture the overall distribution well enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_PRECOMPUTED:\n",
    "    df = Helper.get_icentia_embedding(subjects, model)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "            df,\n",
    "            df.subject,\n",
    "            test_size=0.2,\n",
    "            random_state=42,\n",
    "            stratify=df.subject,\n",
    "        )\n",
    "    \n",
    "    X_embedded = TSNE(n_components=2).fit_transform(X_test.iloc[:,:ld].fillna(0.0))\n",
    "    X_embedded = pd.DataFrame(X_embedded, columns=['Projected Axis 1', 'Projected Axis 2'])\n",
    "    X_embedded['Beat'] = X_test.beat.values\n",
    "    X_embedded['Subject'] = y_test.values\n",
    "    X_embedded.to_csv('../analysis/personalization/embeddings_tsne/all.csv')\n",
    "else:\n",
    "    X_embedded = pd.read_csv('../analysis/personalization/embeddings_tsne/all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted = pd.melt(X_embedded, id_vars=['Projected Axis 1', 'Projected Axis 2'], \n",
    "                    value_vars=['Subject', 'Beat'], \n",
    "                    var_name='Color', value_name='Color_')\n",
    "\n",
    "g = sns.FacetGrid(df_melted, col='Color', height=5, aspect=1)\n",
    "\n",
    "g.map(sns.scatterplot, 'Projected Axis 1', 'Projected Axis 2', 'Color_', s=1, palette='tab10')\n",
    "\n",
    "g.set_axis_labels(\"\",\"\")\n",
    "\n",
    "for i, ax in enumerate(g.axes.flat):\n",
    "    if i == 0:\n",
    "        ax.set_yticks([-100, 0, 100])\n",
    "\n",
    "plt.legend(markerscale=7, loc='upper left')\n",
    "plt.tight_layout()\n",
    "fig = g.figure\n",
    "fig.savefig('../analysis/media/embedding_icentia.png' , dpi=DPI, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have seen a strong clustering behavior with respect to the subjects, we would like to investigate the individual embeddings based on their personalized Mdoels. Therefore, we load the subjects' personalized embeddings and embed them individually (i.e., unlike in the previous calculation, all together but each one separately) into 2-dimensional points with TSNE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_PRECOMPUTED:\n",
    "    for subject in subjects:\n",
    "        print(subject)\n",
    "        df = pd.read_csv('../analysis/personalization/embeddings_vae/' + str(subject) + '.csv', index_col=0)\n",
    "        X_embedded = TSNE(n_components=2).fit_transform(df.iloc[:, 0:ld])\n",
    "        X_embedded = pd.DataFrame(X_embedded, columns=['Projected Axis 1', 'Projected Axis 2'])\n",
    "        X_embedded['beat'] = df.beat\n",
    "        X_embedded['segment'] = df.segment\n",
    "        X_embedded.beat = X_embedded.beat.replace(0.0, 'Normal').replace(1.0, 'Unclassified').replace(2.0, 'PAC').replace(3.0, 'PVC')\n",
    "        X_embedded = X_embedded[X_embedded.beat != 'Unclassified']\n",
    "        cols = {'beat': 'Beat'}\n",
    "        X_embedded = X_embedded.rename(columns=cols)\n",
    "        X_embedded.to_csv('../analysis/personalization/embeddings_tsne_small/' + str(subject) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for path in glob.glob('../analysis/personalization/embeddings_tsne_small/*.csv'):\n",
    "    subject = path.split('/')[-1][:-4]\n",
    "    if subject != 'all':\n",
    "        X_embedded = pd.read_csv(path, index_col=0)\n",
    "        X_embedded['subject'] = subject\n",
    "        df = pd.concat([df, X_embedded])\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "cols = {'subject': 'Subject'}\n",
    "df = df.rename(columns=cols)\n",
    "df.Subject = df.Subject.astype(int)\n",
    "df['Subject'] = pd.Categorical(df['Subject'], categories=custom_sort_order, ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(df, col=\"Subject\", col_wrap=3, palette=palette, hue=\"Beat\", sharex=True, sharey=False)\n",
    "g.map(sns.scatterplot, \"Projected Axis 1\", \"Projected Axis 2\", s=1)\n",
    "g.set_axis_labels(\"\", \"\")\n",
    "\n",
    "for i, ax in enumerate(g.axes):\n",
    "    ax.set_xlabel('')\n",
    "    if i % 3 != 0:\n",
    "        ax.set_ylabel('')\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "g.fig.subplots_adjust(wspace=0.1, hspace=0.01)\n",
    "\n",
    "handles, labels = g.axes[0].get_legend_handles_labels()\n",
    "sorted_handles_labels = sorted(zip(handles, labels), key=lambda x: x[1])\n",
    "sorted_handles, sorted_labels = zip(*sorted_handles_labels)\n",
    "\n",
    "g.fig.legend(sorted_handles, sorted_labels, markerscale=7, loc='upper center', bbox_to_anchor=(0.5, 1.05), ncol=3, borderaxespad=0., edgecolor='white')\n",
    "\n",
    "plt.tight_layout()\n",
    "fig = g.figure\n",
    "\n",
    "fig.savefig('../analysis/media/tsne_embedding_personalization.png', dpi=DPI, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personalized Models: Explainability Pathologies along the axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this experiment, we reload the embeddings of the personalized models. We expect a separating behavior on the fourth dimension, which is related to the S-wave, the Q-wave and thus the width of the QRS complex, one of the most important morphological changes in PVC. The same applies to the P wave and the PAC. The convincingly selected subjects who had either a high number (for significance) of PAC or PVCs were used to create the diagram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pers = pd.DataFrame()\n",
    "for k in subjects:\n",
    "    df_per = pd.read_csv('../analysis/personalization/embeddings_vae_small/' + k + '.csv')\n",
    "    df_per.beat = df_per.beat.replace(0.0, 'Normal').replace(1.0, 'Unclassified').replace(2.0, 'PAC').replace(3.0, 'PVC')\n",
    "    df_per = df_per[df_per.beat != 'Unclassified'].drop('Unnamed: 0', axis=1)\n",
    "    df_pers = pd.concat([df_pers, df_per])\n",
    "df_pers.reset_index(drop=True, inplace=True)\n",
    "cols = {\n",
    "    'split': 'Subject', 'beat': 'Beat', #'4': 'S-wave and Q-Wave (width)', '5': 'P-wave (height, width)', \n",
    "}\n",
    "df_pers = df_pers.rename(columns=cols)\n",
    "df_pers.Subject = df_pers.Subject.astype(int)\n",
    "df_pers.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pers_pac = df_pers[df_pers.Subject.isin([2602, 9225, 10973])]\n",
    "df_pers_pvc = df_pers[df_pers.Subject.isin([1851, 5938, 10146])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pers_pac = df_pers_pac.sort_values('Subject')\n",
    "df_pers_pvc = df_pers_pvc.sort_values('Subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(df_pers_pac, col=\"Subject\", col_wrap=3, hue=\"Beat\", palette=palette, sharey=False, aspect=1)\n",
    "g.map(sns.kdeplot, \"1\", common_norm=False, warn_singular=False)\n",
    "\n",
    "handles, labels = g.axes[0].get_legend_handles_labels()\n",
    "\n",
    "for i, ax in enumerate(g.axes):\n",
    "    ax.set_xlabel('')\n",
    "    if i == 0:\n",
    "        ax.set_yticklabels([])\n",
    "    if i > 0:\n",
    "        ax.set_ylabel('')\n",
    "        ax.set_yticklabels([])\n",
    "        ax.spines['left'].set_visible(False)\n",
    "        ax.tick_params(axis='y', which='both', left=False) \n",
    "\n",
    "sorted_handles_labels = sorted(zip(handles, labels), key=lambda x: x[1])\n",
    "sorted_handles, sorted_labels = zip(*sorted_handles_labels)\n",
    "\n",
    "g.fig.legend(sorted_handles, sorted_labels, loc='upper center', bbox_to_anchor=(0.5, 1.075), ncol=3, borderaxespad=0., edgecolor='white')\n",
    "g.fig.text(0.5, 0.1, 'Dimension 1', ha='center')\n",
    "g.fig.subplots_adjust(wspace=0.1)\n",
    "plt.show()\n",
    "\n",
    "fig = g.fig\n",
    "fig.savefig('../analysis/media/distribution_pac.png', dpi=DPI, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(df_pers_pvc, col=\"Subject\", col_wrap=3, hue=\"Beat\", palette=palette, sharey=False, aspect=1)\n",
    "g.map(sns.kdeplot, \"4\", common_norm=False, warn_singular=False)\n",
    "\n",
    "handles, labels = g.axes[0].get_legend_handles_labels()\n",
    "\n",
    "for i, ax in enumerate(g.axes):\n",
    "    ax.set_xlabel('')\n",
    "    if i == 0:\n",
    "        ax.set_yticklabels([])\n",
    "    if i > 0:\n",
    "        ax.set_ylabel('')\n",
    "        ax.set_yticklabels([])\n",
    "        ax.spines['left'].set_visible(False)\n",
    "        ax.tick_params(axis='y', which='both', left=False) \n",
    "\n",
    "sorted_handles_labels = sorted(zip(handles, labels), key=lambda x: x[1])\n",
    "sorted_handles, sorted_labels = zip(*sorted_handles_labels)\n",
    "\n",
    "g.fig.legend(sorted_handles, sorted_labels, loc='upper center', bbox_to_anchor=(0.5, 1.075), ncol=3, borderaxespad=0., edgecolor='white')\n",
    "g.fig.text(0.5, 0.1, 'Dimension 4', ha='center')\n",
    "g.fig.subplots_adjust(wspace=0.1)\n",
    "plt.show()\n",
    "\n",
    "# Save the figure\n",
    "fig = g.fig\n",
    "fig.savefig('../analysis/media/distribution_pvc.png', dpi=DPI, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, for all subjects and all axis, the distribution plot is generated. Note, that for several subjects there is a strong class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, k in enumerate(df_pers.columns[:ld]):\n",
    "    g = sns.FacetGrid(df_pers, col=\"Subject\", col_wrap=9, hue=\"Beat\", sharey=False, palette=palette)\n",
    "    g.map(sns.kdeplot, k, common_norm=False, warn_singular=False)\n",
    "    plt.legend()\n",
    "    fig = g.figure\n",
    "    fig.savefig('../analysis/media/distribution_personalization_all_' + str(i) + '.png' , dpi=300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
