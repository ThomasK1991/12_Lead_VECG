{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General\n",
    "\n",
    "This section of for imports, getting an overview of all experiments, and loading the most suitable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Project Root: /users/newc6477/VAE/12_Lead_VECG\n",
      "‚úÖ Updated sys.path:\n",
      "['/users/newc6477/Benchmark_ISIBrno/ENTER/envs/my_env/lib/python310.zip', '/users/newc6477/Benchmark_ISIBrno/ENTER/envs/my_env/lib/python3.10', '/users/newc6477/Benchmark_ISIBrno/ENTER/envs/my_env/lib/python3.10/lib-dynload', '', '/users/newc6477/Benchmark_ISIBrno/ENTER/envs/my_env/lib/python3.10/site-packages', '/users/newc6477/VAE/12_Lead_VECG', '/users/newc6477/VAE/12_Lead_VECG/src']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 16:59:58.863065: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-04 16:59:58.863292: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-04 16:59:58.865587: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-04 17:00:14.871130: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully imported `Helper` and `Visualizations`\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "from absl import logging as absl_logging\n",
    "\n",
    "# ‚úÖ Ensure Correct TensorFlow Configuration\n",
    "os.environ['TFDS_DATA_DIR'] = r\"/data/newc6477/VAE/Single_Beat/5_percent_Physionet/\"\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = \"0\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n",
    "\n",
    "# ‚úÖ Ensure Correct Working Directory\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "print(f\"üìÇ Project Root: {PROJECT_ROOT}\")\n",
    "\n",
    "# ‚úÖ Ensure `src/` is in Python's Path\n",
    "SRC_DIR = os.path.join(PROJECT_ROOT, \"src\")\n",
    "if SRC_DIR not in sys.path:\n",
    "    sys.path.append(SRC_DIR)\n",
    "\n",
    "print(f\"‚úÖ Updated sys.path:\\n{sys.path}\")\n",
    "\n",
    "# ‚úÖ Suppress Warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "absl_logging.set_verbosity(absl_logging.ERROR)\n",
    "\n",
    "# ‚úÖ Import Modules\n",
    "try:\n",
    "    from src.utils.helper import Helper\n",
    "    from src.evaluate.visualizations import Visualizations\n",
    "    print(\"‚úÖ Successfully imported `Helper` and `Visualizations`\")\n",
    "except ModuleNotFoundError as e:\n",
    "    print(f\"‚ùå Import Error: {e}\")\n",
    "    print(\"üîç Check if `src/` has `__init__.py` and is in `sys.path`.\")\n",
    "\n",
    "# ‚úÖ Import Other Required Libraries\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from neurokit2.signal import signal_smooth\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The resolution for saving images\n",
    "DPI = 300\n",
    "\n",
    "# The source path of the experiments and models\n",
    "PATH = r\"/users/newc6477/VAE/12_Lead_VECG/results/Hope/test_is_split1\"\n",
    "\n",
    "# Some operations take some time in computation.\n",
    "# Therefore, the stored intermediate results can be used to skip the respective computation.\n",
    "USE_PRECOMPUTED = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîπ Funcs used to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_models(df_physionet_train, df_physionet_test, hyperparams_list):\n",
    "    \"\"\"\n",
    "    Evaluate a list of models using KNN classification and return a summary table.\n",
    "    \n",
    "    Args:\n",
    "        df_physionet_train (List[pd.DataFrame]): List of train embedding DataFrames (1 per model).\n",
    "        df_physionet_test (List[pd.DataFrame]): List of test embedding DataFrames (1 per model).\n",
    "        hyperparams_list (List[dict]): Corresponding list of hyperparameter dictionaries.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Summary table with accuracy, F1 scores, hyperparameters.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for i in range(len(df_physionet_train)):\n",
    "        print(f\"\\nüîç Evaluating model {i+1}/{len(df_physionet_train)}...\")\n",
    "\n",
    "        # Extract hyperparameters and latent dimension\n",
    "        hparams = hyperparams_list[i]\n",
    "        latent_dim = hparams.get(\"latent_dimension\", 8)\n",
    "\n",
    "        # Prepare feature matrices and labels\n",
    "        X_train = df_physionet_train[i].iloc[:, :latent_dim].values  \n",
    "        X_test = df_physionet_test[i].iloc[:, :latent_dim].values  \n",
    "        y_train = np.array(df_physionet_train[i]['diagnostic'].tolist(), dtype=int)  \n",
    "        y_test = np.array(df_physionet_test[i]['diagnostic'].tolist(), dtype=int)  \n",
    "\n",
    "        # KNN classification with hyperparameter tuning\n",
    "        knn = KNeighborsClassifier()\n",
    "        multi_knn = MultiOutputClassifier(knn, n_jobs=-1)\n",
    "\n",
    "        param_grid = {\"estimator__n_neighbors\": [3, 5, 7, 9, 11]}\n",
    "        grid = GridSearchCV(multi_knn, param_grid, scoring=\"accuracy\", cv=3, n_jobs=-1)\n",
    "        grid.fit(X_train, y_train)\n",
    "\n",
    "        best_model = grid.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        # Evaluation metrics\n",
    "        overall_acc = accuracy_score(y_test, y_pred)\n",
    "        f1_micro = f1_score(y_test, y_pred, average=\"micro\")\n",
    "        f1_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "        accuracy_per_label = (y_pred == y_test).mean(axis=0)\n",
    "\n",
    "        # Print evaluation\n",
    "        print(\"‚úÖ Overall Accuracy:\", overall_acc)\n",
    "        print(\"‚úÖ F1 Score (Macro):\", f1_macro)\n",
    "        print(\"‚úÖ F1 Score (Micro):\", f1_micro)\n",
    "        print(\"‚úÖ Accuracy per label:\", accuracy_per_label)\n",
    "\n",
    "        # Classification report\n",
    "        print(\"‚úÖ Classification Report:\\n\")\n",
    "        print(classification_report(\n",
    "            y_test, y_pred,\n",
    "            target_names=[str(i) for i in range(y_test.shape[1])]\n",
    "        ))\n",
    "\n",
    "        # Collect results\n",
    "        results.append({\n",
    "            \"model_index\": i,\n",
    "            \"best_k\": grid.best_params_[\"estimator__n_neighbors\"],\n",
    "            \"accuracy\": overall_acc,\n",
    "            \"f1_micro\": f1_micro,\n",
    "            \"f1_macro\": f1_macro,\n",
    "            **hparams\n",
    "        })\n",
    "\n",
    "    summary_df = pd.DataFrame(results)\n",
    "    return summary_df\n",
    "\n",
    "\n",
    "def extract_hyperparams_from_json(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        params = json.load(f)\n",
    "\n",
    "    # Extract key hyperparameters\n",
    "    hyperparams = {\n",
    "        \"alpha\": params[\"coefficients\"][\"alpha\"],\n",
    "        \"beta\": params[\"coefficients\"][\"beta\"],\n",
    "        \"gamma\": params[\"coefficients\"][\"gamma\"],\n",
    "        \"latent_dimension\": params[\"latent_dimension\"],\n",
    "        \"learning_rate\": params[\"learning_rate\"],\n",
    "        \"epochs\": params[\"epochs\"]\n",
    "    }\n",
    "\n",
    "    return hyperparams\n",
    "\n",
    "from IPython.display import display\n",
    "def summarize_by_latent_dimension(results_df):\n",
    "    unique_dims = results_df[\"latent_dimension\"].unique()\n",
    "    summary_tables = {}\n",
    "\n",
    "    for dim in sorted(unique_dims):\n",
    "        filtered = results_df[results_df[\"latent_dimension\"] == dim]\n",
    "        sorted_table = filtered.sort_values(by=\"f1_macro\", ascending=False)\n",
    "        summary_tables[dim] = sorted_table\n",
    "\n",
    "        print(f\"\\nüìè Latent Dimension: {dim}\")\n",
    "        display(sorted_table)\n",
    "\n",
    "    return summary_tables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîπ Lead I Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /users/newc6477/VAE/12_Lead_VECG/results/Hope/test_is_split1/I/2025-03-25_22-44-31/model_best.keras\n",
      "Loading model from: /users/newc6477/VAE/12_Lead_VECG/results/Hope/test_is_split1/I/2025-03-25_22-58-08/model_best.keras\n",
      "Loading model from: /users/newc6477/VAE/12_Lead_VECG/results/Hope/test_is_split1/I/2025-03-25_23-11-36/model_best.keras\n",
      "Loading model from: /users/newc6477/VAE/12_Lead_VECG/results/Hope/test_is_split1/I/2025-03-25_23-25-03/model_best.keras\n",
      "Loading model from: /users/newc6477/VAE/12_Lead_VECG/results/Hope/test_is_split1/I/2025-03-25_23-37-01/model_best.keras\n",
      "Loading model from: /users/newc6477/VAE/12_Lead_VECG/results/Hope/test_is_split1/I/2025-03-25_23-46-05/model_best.keras\n",
      "Loading model from: /users/newc6477/VAE/12_Lead_VECG/results/Hope/test_is_split1/I/2025-03-25_23-59-37/model_best.keras\n",
      "Loading model from: /users/newc6477/VAE/12_Lead_VECG/results/Hope/test_is_split1/I/2025-03-26_00-13-04/model_best.keras\n",
      "Loading model from: /users/newc6477/VAE/12_Lead_VECG/results/Hope/test_is_split1/I/2025-03-26_00-21-53/model_best.keras\n",
      "Loading model from: /users/newc6477/VAE/12_Lead_VECG/results/Hope/test_is_split1/I/2025-03-26_00-30-40/model_best.keras\n",
      "Loading model from: /users/newc6477/VAE/12_Lead_VECG/results/Hope/test_is_split1/I/2025-03-26_00-42-57/model_best.keras\n",
      "Loading model from: /users/newc6477/VAE/12_Lead_VECG/results/Hope/test_is_split1/I/2025-03-26_00-55-01/model_best.keras\n",
      "Loading model from: /users/newc6477/VAE/12_Lead_VECG/results/Hope/test_is_split1/I/2025-03-26_01-08-34/model_best.keras\n",
      "Loading model from: /users/newc6477/VAE/12_Lead_VECG/results/Hope/test_is_split1/I/2025-03-26_01-21-00/model_best.keras\n",
      "Loading model from: /users/newc6477/VAE/12_Lead_VECG/results/Hope/test_is_split1/I/2025-03-26_01-32-53/model_best.keras\n",
      "Loading model from: /users/newc6477/VAE/12_Lead_VECG/results/Hope/test_is_split1/I/2025-03-26_01-45-06/model_best.keras\n",
      "Loading model from: /users/newc6477/VAE/12_Lead_VECG/results/Hope/test_is_split1/I/2025-03-26_01-56-28/model_best.keras\n",
      "Loading model from: /users/newc6477/VAE/12_Lead_VECG/results/Hope/test_is_split1/I/2025-03-26_02-03-12/model_best.keras\n",
      "Loaded 18 models successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "BASE = os.path.join(PATH,'I')  # Set the correct path to your BASE directory\n",
    "models = []\n",
    "hyperparams_list = []\n",
    "\n",
    "# Get all model folders in BASE directory\n",
    "folders = [f for f in os.listdir(BASE) if os.path.isdir(os.path.join(BASE, f))]\n",
    "\n",
    "for model in folders:\n",
    "    model_path = os.path.join(BASE,model,'model_best.keras')\n",
    "    hyperparams_path = os.path.join(BASE,model,'params.json')\n",
    "    hyperparams = extract_hyperparams_from_json(hyperparams_path)\n",
    "    hyperparams_list.append(hyperparams)\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"Loading model from: {model_path}\")\n",
    "        model = tf.keras.models.load_model(model_path,compile=False)\n",
    "        models.append(model)\n",
    "    else:\n",
    "        print(f\"Warning: Model file not found at {model_path}\")\n",
    "\n",
    "print(f\"Loaded {len(models)} models successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_splits = ['split2', 'split3', 'split4', 'split5']\n",
    "dataset_config = {\n",
    "    'name': ['physionet'],\n",
    "    'split': train_splits,\n",
    "    'shuffle_size': 1024,\n",
    "    'batch_size': 1024,\n",
    "}\n",
    "test_splits = ['split1']\n",
    "dataset_test = {\n",
    "    'name': ['physionet'],\n",
    "    'split': test_splits,\n",
    "    'shuffle_size': 1024,\n",
    "    'batch_size': 1024,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ Loading dataset 'physionet' with splits: ['split2', 'split3', 'split4', 'split5']\n",
      "üîç Processing lead: I\n",
      "     43/Unknown - 2s 35ms/step‚úÖ Generator exhausted normally.\n",
      "44/44 [==============================] - 2s 35ms/step\n",
      "     41/Unknown - 1s 31ms/step‚úÖ Generator exhausted normally.\n",
      "44/44 [==============================] - 1s 31ms/step\n",
      "     41/Unknown - 1s 32ms/step‚úÖ Generator exhausted normally.\n",
      "44/44 [==============================] - 2s 32ms/step\n",
      "     41/Unknown - 1s 33ms/step‚úÖ Generator exhausted normally.\n",
      "44/44 [==============================] - 2s 33ms/step\n",
      "     41/Unknown - 1s 34ms/step‚úÖ Generator exhausted normally.\n",
      "44/44 [==============================] - 2s 33ms/step\n",
      "     41/Unknown - 1s 33ms/step‚úÖ Generator exhausted normally.\n",
      "44/44 [==============================] - 2s 33ms/step\n",
      "     41/Unknown - 1s 32ms/step‚úÖ Generator exhausted normally.\n",
      "44/44 [==============================] - 1s 32ms/step\n",
      "     41/Unknown - 1s 33ms/step‚úÖ Generator exhausted normally.\n",
      "44/44 [==============================] - 2s 32ms/step\n",
      "     41/Unknown - 1s 33ms/step‚úÖ Generator exhausted normally.\n",
      "44/44 [==============================] - 1s 32ms/step\n",
      "     41/Unknown - 1s 33ms/step‚úÖ Generator exhausted normally.\n",
      "44/44 [==============================] - 2s 32ms/step\n",
      "     41/Unknown - 1s 34ms/step‚úÖ Generator exhausted normally.\n",
      "44/44 [==============================] - 2s 33ms/step\n",
      "     41/Unknown - 1s 33ms/step‚úÖ Generator exhausted normally.\n",
      "44/44 [==============================] - 2s 33ms/step\n",
      "     42/Unknown - 1s 31ms/step‚úÖ Generator exhausted normally.\n",
      "44/44 [==============================] - 1s 31ms/step\n",
      "     43/Unknown - 1s 32ms/step‚úÖ Generator exhausted normally.\n",
      "44/44 [==============================] - 2s 32ms/step\n",
      "     41/Unknown - 1s 33ms/step‚úÖ Generator exhausted normally.\n",
      "44/44 [==============================] - 2s 33ms/step\n",
      "     42/Unknown - 2s 34ms/step‚úÖ Generator exhausted normally.\n",
      "44/44 [==============================] - 2s 34ms/step\n",
      "     42/Unknown - 1s 33ms/step‚úÖ Generator exhausted normally.\n",
      "44/44 [==============================] - 2s 33ms/step\n",
      "     41/Unknown - 1s 33ms/step‚úÖ Generator exhausted normally.\n",
      "44/44 [==============================] - 2s 33ms/step\n",
      "\n",
      "üì¶ Loading dataset 'physionet' with splits: ['split1']\n",
      "üîç Processing lead: I\n",
      "     10/Unknown - 0s 27ms/step‚úÖ Generator exhausted normally.\n",
      "11/11 [==============================] - 0s 28ms/step\n",
      "      9/Unknown - 0s 27ms/step‚úÖ Generator exhausted normally.\n",
      "11/11 [==============================] - 0s 27ms/step\n",
      "     10/Unknown - 0s 26ms/step‚úÖ Generator exhausted normally.\n",
      "11/11 [==============================] - 0s 29ms/step\n",
      "     10/Unknown - 0s 26ms/step‚úÖ Generator exhausted normally.\n",
      "11/11 [==============================] - 0s 26ms/step\n",
      "      8/Unknown - 0s 29ms/step‚úÖ Generator exhausted normally.\n",
      "11/11 [==============================] - 0s 27ms/step\n",
      "      9/Unknown - 0s 24ms/step‚úÖ Generator exhausted normally.\n",
      "11/11 [==============================] - 0s 25ms/step\n",
      "     10/Unknown - 0s 25ms/step‚úÖ Generator exhausted normally.\n",
      "11/11 [==============================] - 0s 25ms/step\n",
      "     10/Unknown - 0s 26ms/step‚úÖ Generator exhausted normally.\n",
      "11/11 [==============================] - 0s 26ms/step\n",
      "      9/Unknown - 0s 24ms/step‚úÖ Generator exhausted normally.\n",
      "11/11 [==============================] - 0s 24ms/step\n",
      "     10/Unknown - 0s 25ms/step‚úÖ Generator exhausted normally.\n",
      "11/11 [==============================] - 0s 26ms/step\n",
      "      8/Unknown - 0s 24ms/step‚úÖ Generator exhausted normally.\n",
      "11/11 [==============================] - 0s 25ms/step\n",
      "     10/Unknown - 0s 26ms/step‚úÖ Generator exhausted normally.\n",
      "11/11 [==============================] - 0s 27ms/step\n",
      "     10/Unknown - 0s 24ms/step‚úÖ Generator exhausted normally.\n",
      "11/11 [==============================] - 0s 25ms/step\n",
      "      8/Unknown - 0s 26ms/step‚úÖ Generator exhausted normally.\n",
      "11/11 [==============================] - 0s 26ms/step\n",
      "      9/Unknown - 0s 25ms/step‚úÖ Generator exhausted normally.\n",
      "11/11 [==============================] - 0s 26ms/step\n",
      "     10/Unknown - 0s 26ms/step‚úÖ Generator exhausted normally.\n",
      "11/11 [==============================] - 0s 27ms/step\n",
      "     10/Unknown - 0s 28ms/step‚úÖ Generator exhausted normally.\n",
      "11/11 [==============================] - 0s 29ms/step\n",
      "      9/Unknown - 0s 25ms/step‚úÖ Generator exhausted normally.\n",
      "11/11 [==============================] - 0s 26ms/step\n"
     ]
    }
   ],
   "source": [
    "df_physionet_train, ld = Helper.get_embeddings_multiple_model(models, datasets=dataset_config, lead='I')\n",
    "df_physionet_test, ld = Helper.get_embeddings_multiple_model(models, datasets=dataset_test, lead='I')\n",
    "\n",
    "#df_physionet_train = df_physionet_train[0]\n",
    "#df_physionet_test = df_physionet_test[0]\n",
    "#print(type(df_physionet_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Evaluating model 1/18...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Overall Accuracy: 0.2704626334519573\n",
      "‚úÖ F1 Score (Macro): 0.08984689221908834\n",
      "‚úÖ F1 Score (Micro): 0.23345764517847628\n",
      "‚úÖ Accuracy per label: [0.92686833 0.89519573 0.97437722 0.99928826 0.98505338 0.95542705\n",
      " 0.97046263 0.98096085 0.93131673 0.97758007 0.99724199 0.98122776\n",
      " 0.97989324 0.98816726 0.72758007 0.94741993 0.99297153 0.99119217\n",
      " 0.98451957 0.97642349 0.9730427  0.96530249 0.88585409 0.87241993\n",
      " 0.88763345 0.9725089 ]\n",
      "‚úÖ Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.01      0.02       791\n",
      "           1       0.42      0.05      0.09      1155\n",
      "           2       0.00      0.00      0.00       272\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.21      0.13      0.16       124\n",
      "           5       0.64      0.31      0.41       580\n",
      "           6       0.07      0.00      0.01       319\n",
      "           7       0.00      0.00      0.00       186\n",
      "           8       0.12      0.01      0.01       740\n",
      "           9       0.00      0.00      0.00       249\n",
      "          10       0.00      0.00      0.00        30\n",
      "          11       0.00      0.00      0.00       208\n",
      "          12       0.00      0.00      0.00       222\n",
      "          13       0.00      0.00      0.00       128\n",
      "          14       0.52      0.36      0.43      3135\n",
      "          15       0.00      0.00      0.00       574\n",
      "          16       0.69      0.20      0.31        89\n",
      "          17       0.00      0.00      0.00        99\n",
      "          18       0.00      0.00      0.00       164\n",
      "          19       0.00      0.00      0.00       261\n",
      "          20       0.18      0.13      0.15       203\n",
      "          21       0.01      0.00      0.01       296\n",
      "          22       0.47      0.25      0.32      1247\n",
      "          23       0.53      0.27      0.36      1473\n",
      "          24       0.34      0.03      0.06      1229\n",
      "          25       0.00      0.00      0.00       288\n",
      "\n",
      "   micro avg       0.47      0.16      0.23     14068\n",
      "   macro avg       0.17      0.07      0.09     14068\n",
      "weighted avg       0.33      0.16      0.20     14068\n",
      " samples avg       0.19      0.16      0.17     14068\n",
      "\n",
      "\n",
      "üîç Evaluating model 2/18...\n",
      "‚úÖ Overall Accuracy: 0.24039145907473308\n",
      "‚úÖ F1 Score (Macro): 0.04686460545530584\n",
      "‚úÖ F1 Score (Micro): 0.1580090391500851\n",
      "‚úÖ Accuracy per label: [0.92900356 0.89448399 0.97357651 0.99875445 0.98825623 0.94795374\n",
      " 0.97144128 0.98336299 0.9338968  0.97784698 0.99733096 0.98149466\n",
      " 0.98016014 0.98852313 0.73798932 0.94875445 0.99225979 0.99119217\n",
      " 0.98540925 0.97677936 0.97562278 0.97161922 0.87651246 0.85836299\n",
      " 0.888879   0.97428826]\n",
      "‚úÖ Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.00      0.00       791\n",
      "           1       0.29      0.02      0.04      1155\n",
      "           2       0.00      0.00      0.00       272\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.00      0.00      0.00       124\n",
      "           5       0.47      0.07      0.12       580\n",
      "           6       0.00      0.00      0.00       319\n",
      "           7       0.00      0.00      0.00       186\n",
      "           8       0.20      0.00      0.00       740\n",
      "           9       0.00      0.00      0.00       249\n",
      "          10       0.00      0.00      0.00        30\n",
      "          11       0.00      0.00      0.00       208\n",
      "          12       0.00      0.00      0.00       222\n",
      "          13       0.00      0.00      0.00       128\n",
      "          14       0.56      0.27      0.36      3135\n",
      "          15       0.00      0.00      0.00       574\n",
      "          16       1.00      0.02      0.04        89\n",
      "          17       0.00      0.00      0.00        99\n",
      "          18       0.00      0.00      0.00       164\n",
      "          19       0.00      0.00      0.00       261\n",
      "          20       0.26      0.18      0.21       203\n",
      "          21       0.04      0.00      0.01       296\n",
      "          22       0.36      0.14      0.20      1247\n",
      "          23       0.39      0.15      0.21      1473\n",
      "          24       0.22      0.01      0.01      1229\n",
      "          25       0.00      0.00      0.00       288\n",
      "\n",
      "   micro avg       0.45      0.10      0.16     14068\n",
      "   macro avg       0.15      0.03      0.05     14068\n",
      "weighted avg       0.29      0.10      0.13     14068\n",
      " samples avg       0.12      0.10      0.11     14068\n",
      "\n",
      "\n",
      "üîç Evaluating model 3/18...\n",
      "‚úÖ Overall Accuracy: 0.23781138790035586\n",
      "‚úÖ F1 Score (Macro): 0.0531051123609955\n",
      "‚úÖ F1 Score (Micro): 0.16863854100536735\n",
      "‚úÖ Accuracy per label: [0.92918149 0.89475089 0.97535587 0.99911032 0.98033808 0.95115658\n",
      " 0.97161922 0.98345196 0.93309609 0.97784698 0.99733096 0.98149466\n",
      " 0.98024911 0.9886121  0.72713523 0.94830961 0.99225979 0.99119217\n",
      " 0.98514235 0.97677936 0.97357651 0.97241993 0.87927046 0.86494662\n",
      " 0.88950178 0.97428826]\n",
      "‚úÖ Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.01      0.01       791\n",
      "           1       0.29      0.02      0.03      1155\n",
      "           2       0.00      0.00      0.00       272\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.10      0.10      0.10       124\n",
      "           5       0.68      0.10      0.17       580\n",
      "           6       0.00      0.00      0.00       319\n",
      "           7       0.00      0.00      0.00       186\n",
      "           8       0.07      0.00      0.00       740\n",
      "           9       0.00      0.00      0.00       249\n",
      "          10       0.00      0.00      0.00        30\n",
      "          11       0.00      0.00      0.00       208\n",
      "          12       0.00      0.00      0.00       222\n",
      "          13       0.00      0.00      0.00       128\n",
      "          14       0.52      0.29      0.38      3135\n",
      "          15       0.00      0.00      0.00       574\n",
      "          16       1.00      0.02      0.04        89\n",
      "          17       0.00      0.00      0.00        99\n",
      "          18       0.00      0.00      0.00       164\n",
      "          19       0.00      0.00      0.00       261\n",
      "          20       0.22      0.18      0.20       203\n",
      "          21       0.00      0.00      0.00       296\n",
      "          22       0.39      0.16      0.23      1247\n",
      "          23       0.45      0.13      0.21      1473\n",
      "          24       0.26      0.01      0.01      1229\n",
      "          25       0.00      0.00      0.00       288\n",
      "\n",
      "   micro avg       0.45      0.10      0.17     14068\n",
      "   macro avg       0.17      0.04      0.05     14068\n",
      "weighted avg       0.31      0.10      0.14     14068\n",
      " samples avg       0.13      0.11      0.12     14068\n",
      "\n",
      "\n",
      "üîç Evaluating model 4/18...\n",
      "‚úÖ Overall Accuracy: 0.2356761565836299\n",
      "‚úÖ F1 Score (Macro): 0.06244689836430938\n",
      "‚úÖ F1 Score (Micro): 0.18980417897385407\n",
      "‚úÖ Accuracy per label: [0.91814947 0.89243772 0.97491103 0.99893238 0.98807829 0.94048043\n",
      " 0.97099644 0.98185053 0.93122776 0.97775801 0.99733096 0.98140569\n",
      " 0.9794484  0.98816726 0.71343416 0.9477758  0.99172598 0.99119217\n",
      " 0.98514235 0.97651246 0.97437722 0.97117438 0.88870107 0.85987544\n",
      " 0.88745552 0.97366548]\n",
      "‚úÖ Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.01      0.01       791\n",
      "           1       0.31      0.04      0.07      1155\n",
      "           2       0.00      0.00      0.00       272\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.32      0.07      0.12       124\n",
      "           5       0.25      0.07      0.11       580\n",
      "           6       0.23      0.01      0.02       319\n",
      "           7       0.00      0.00      0.00       186\n",
      "           8       0.03      0.00      0.00       740\n",
      "           9       0.00      0.00      0.00       249\n",
      "          10       0.00      0.00      0.00        30\n",
      "          11       0.00      0.00      0.00       208\n",
      "          12       0.00      0.00      0.00       222\n",
      "          13       0.00      0.00      0.00       128\n",
      "          14       0.48      0.29      0.36      3135\n",
      "          15       0.00      0.00      0.00       574\n",
      "          16       0.17      0.01      0.02        89\n",
      "          17       0.00      0.00      0.00        99\n",
      "          18       0.00      0.00      0.00       164\n",
      "          19       0.00      0.00      0.00       261\n",
      "          20       0.24      0.20      0.22       203\n",
      "          21       0.09      0.01      0.02       296\n",
      "          22       0.50      0.27      0.35      1247\n",
      "          23       0.43      0.23      0.30      1473\n",
      "          24       0.26      0.02      0.03      1229\n",
      "          25       0.00      0.00      0.00       288\n",
      "\n",
      "   micro avg       0.41      0.12      0.19     14068\n",
      "   macro avg       0.13      0.05      0.06     14068\n",
      "weighted avg       0.27      0.12      0.16     14068\n",
      " samples avg       0.15      0.13      0.13     14068\n",
      "\n",
      "\n",
      "üîç Evaluating model 5/18...\n",
      "‚úÖ Overall Accuracy: 0.253202846975089\n",
      "‚úÖ F1 Score (Macro): 0.07402017411163263\n",
      "‚úÖ F1 Score (Micro): 0.21973670127368083\n",
      "‚úÖ Accuracy per label: [0.92758007 0.89048043 0.9752669  0.99937722 0.98425267 0.94919929\n",
      " 0.96975089 0.98096085 0.93220641 0.97766904 0.99733096 0.98122776\n",
      " 0.97962633 0.98790036 0.73016014 0.9452847  0.99065836 0.99119217\n",
      " 0.98354093 0.97677936 0.975      0.9725089  0.88505338 0.86094306\n",
      " 0.88460854 0.97428826]\n",
      "‚úÖ Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.05      0.09       791\n",
      "           1       0.28      0.04      0.07      1155\n",
      "           2       0.00      0.00      0.00       272\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.09      0.05      0.06       124\n",
      "           5       0.51      0.27      0.35       580\n",
      "           6       0.14      0.01      0.02       319\n",
      "           7       0.00      0.00      0.00       186\n",
      "           8       0.24      0.01      0.03       740\n",
      "           9       0.00      0.00      0.00       249\n",
      "          10       0.00      0.00      0.00        30\n",
      "          11       0.00      0.00      0.00       208\n",
      "          12       0.33      0.03      0.06       222\n",
      "          13       0.00      0.00      0.00       128\n",
      "          14       0.53      0.34      0.41      3135\n",
      "          15       0.04      0.00      0.01       574\n",
      "          16       0.06      0.01      0.02        89\n",
      "          17       0.00      0.00      0.00        99\n",
      "          18       0.04      0.01      0.01       164\n",
      "          19       0.00      0.00      0.00       261\n",
      "          20       0.08      0.03      0.05       203\n",
      "          21       0.16      0.01      0.02       296\n",
      "          22       0.47      0.24      0.32      1247\n",
      "          23       0.45      0.26      0.32      1473\n",
      "          24       0.21      0.02      0.04      1229\n",
      "          25       0.47      0.02      0.05       288\n",
      "\n",
      "   micro avg       0.44      0.15      0.22     14068\n",
      "   macro avg       0.17      0.05      0.07     14068\n",
      "weighted avg       0.33      0.15      0.19     14068\n",
      " samples avg       0.17      0.15      0.16     14068\n",
      "\n",
      "\n",
      "üîç Evaluating model 6/18...\n",
      "‚úÖ Overall Accuracy: 0.24012455516014236\n",
      "‚úÖ F1 Score (Macro): 0.08368200673196559\n",
      "‚úÖ F1 Score (Micro): 0.2322455836684824\n",
      "‚úÖ Accuracy per label: [0.92411032 0.89101423 0.97562278 0.99937722 0.9519573  0.95186833\n",
      " 0.96966192 0.98033808 0.92268683 0.97784698 0.99724199 0.98140569\n",
      " 0.97891459 0.98763345 0.73576512 0.9480427  0.9908363  0.99119217\n",
      " 0.98478648 0.97597865 0.97455516 0.95685053 0.89670819 0.85880783\n",
      " 0.8816726  0.97339858]\n",
      "‚úÖ Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.02      0.04       791\n",
      "           1       0.35      0.07      0.12      1155\n",
      "           2       0.00      0.00      0.00       272\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.05      0.18      0.08       124\n",
      "           5       0.57      0.29      0.38       580\n",
      "           6       0.00      0.00      0.00       319\n",
      "           7       0.05      0.01      0.02       186\n",
      "           8       0.04      0.01      0.01       740\n",
      "           9       0.50      0.01      0.02       249\n",
      "          10       0.00      0.00      0.00        30\n",
      "          11       0.00      0.00      0.00       208\n",
      "          12       0.06      0.00      0.01       222\n",
      "          13       0.00      0.00      0.00       128\n",
      "          14       0.54      0.38      0.44      3135\n",
      "          15       0.19      0.01      0.01       574\n",
      "          16       0.21      0.06      0.09        89\n",
      "          17       0.00      0.00      0.00        99\n",
      "          18       0.00      0.00      0.00       164\n",
      "          19       0.00      0.00      0.00       261\n",
      "          20       0.24      0.18      0.21       203\n",
      "          21       0.01      0.00      0.00       296\n",
      "          22       0.57      0.27      0.37      1247\n",
      "          23       0.44      0.26      0.33      1473\n",
      "          24       0.18      0.02      0.04      1229\n",
      "          25       0.18      0.01      0.02       288\n",
      "\n",
      "   micro avg       0.41      0.16      0.23     14068\n",
      "   macro avg       0.17      0.07      0.08     14068\n",
      "weighted avg       0.32      0.16      0.20     14068\n",
      " samples avg       0.19      0.17      0.17     14068\n",
      "\n",
      "\n",
      "üîç Evaluating model 7/18...\n",
      "‚úÖ Overall Accuracy: 0.27455516014234876\n",
      "‚úÖ F1 Score (Macro): 0.10989057358300498\n",
      "‚úÖ F1 Score (Micro): 0.26476658476658477\n",
      "‚úÖ Accuracy per label: [0.92357651 0.89021352 0.97482206 0.99919929 0.98718861 0.9477758\n",
      " 0.96637011 0.97962633 0.92864769 0.97642349 0.99724199 0.98042705\n",
      " 0.97793594 0.98692171 0.72651246 0.94715302 0.99128114 0.9911032\n",
      " 0.98345196 0.97517794 0.97677936 0.96405694 0.88585409 0.86281139\n",
      " 0.87775801 0.9705516 ]\n",
      "‚úÖ Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.03      0.06       791\n",
      "           1       0.36      0.09      0.15      1155\n",
      "           2       0.00      0.00      0.00       272\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.31      0.14      0.19       124\n",
      "           5       0.49      0.28      0.36       580\n",
      "           6       0.05      0.01      0.02       319\n",
      "           7       0.00      0.00      0.00       186\n",
      "           8       0.14      0.02      0.03       740\n",
      "           9       0.14      0.01      0.02       249\n",
      "          10       0.00      0.00      0.00        30\n",
      "          11       0.00      0.00      0.00       208\n",
      "          12       0.00      0.00      0.00       222\n",
      "          13       0.00      0.00      0.00       128\n",
      "          14       0.51      0.39      0.44      3135\n",
      "          15       0.05      0.00      0.00       574\n",
      "          16       0.40      0.21      0.28        89\n",
      "          17       0.00      0.00      0.00        99\n",
      "          18       0.08      0.01      0.02       164\n",
      "          19       0.00      0.00      0.00       261\n",
      "          20       0.33      0.27      0.30       203\n",
      "          21       0.07      0.03      0.04       296\n",
      "          22       0.48      0.42      0.45      1247\n",
      "          23       0.47      0.33      0.39      1473\n",
      "          24       0.20      0.04      0.07      1229\n",
      "          25       0.15      0.03      0.05       288\n",
      "\n",
      "   micro avg       0.43      0.19      0.26     14068\n",
      "   macro avg       0.17      0.09      0.11     14068\n",
      "weighted avg       0.31      0.19      0.23     14068\n",
      " samples avg       0.23      0.19      0.20     14068\n",
      "\n",
      "\n",
      "üîç Evaluating model 8/18...\n",
      "‚úÖ Overall Accuracy: 0.2318505338078292\n",
      "‚úÖ F1 Score (Macro): 0.05849181558272346\n",
      "‚úÖ F1 Score (Micro): 0.18161447537953057\n",
      "‚úÖ Accuracy per label: [0.92891459 0.89519573 0.97375445 0.99928826 0.98905694 0.95044484\n",
      " 0.97126335 0.98336299 0.93380783 0.9774911  0.99733096 0.98149466\n",
      " 0.98024911 0.98843416 0.72411032 0.94866548 0.99234875 0.99119217\n",
      " 0.98540925 0.97677936 0.97553381 0.97064057 0.86272242 0.85898577\n",
      " 0.88950178 0.97428826]\n",
      "‚úÖ Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.00      0.01       791\n",
      "           1       0.29      0.01      0.03      1155\n",
      "           2       0.00      0.00      0.00       272\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.56      0.04      0.08       124\n",
      "           5       0.60      0.12      0.20       580\n",
      "           6       0.00      0.00      0.00       319\n",
      "           7       0.00      0.00      0.00       186\n",
      "           8       0.25      0.00      0.01       740\n",
      "           9       0.00      0.00      0.00       249\n",
      "          10       0.00      0.00      0.00        30\n",
      "          11       0.00      0.00      0.00       208\n",
      "          12       0.00      0.00      0.00       222\n",
      "          13       0.00      0.00      0.00       128\n",
      "          14       0.51      0.29      0.37      3135\n",
      "          15       0.00      0.00      0.00       574\n",
      "          16       1.00      0.03      0.07        89\n",
      "          17       0.00      0.00      0.00        99\n",
      "          18       0.00      0.00      0.00       164\n",
      "          19       0.00      0.00      0.00       261\n",
      "          20       0.25      0.18      0.21       203\n",
      "          21       0.03      0.00      0.01       296\n",
      "          22       0.34      0.26      0.29      1247\n",
      "          23       0.41      0.18      0.25      1473\n",
      "          24       0.28      0.01      0.01      1229\n",
      "          25       0.33      0.00      0.01       288\n",
      "\n",
      "   micro avg       0.43      0.12      0.18     14068\n",
      "   macro avg       0.19      0.04      0.06     14068\n",
      "weighted avg       0.31      0.12      0.15     14068\n",
      " samples avg       0.14      0.12      0.13     14068\n",
      "\n",
      "\n",
      "üîç Evaluating model 9/18...\n",
      "‚úÖ Overall Accuracy: 0.2659252669039146\n",
      "‚úÖ F1 Score (Macro): 0.09222835785403768\n",
      "‚úÖ F1 Score (Micro): 0.24141806293420515\n",
      "‚úÖ Accuracy per label: [0.91841637 0.89128114 0.97508897 0.99786477 0.98905694 0.95302491\n",
      " 0.96841637 0.98007117 0.93158363 0.97704626 0.99724199 0.98131673\n",
      " 0.97900356 0.98701068 0.72001779 0.9452847  0.99208185 0.9911032\n",
      " 0.9844306  0.97580071 0.9725089  0.97010676 0.89092527 0.8547153\n",
      " 0.88202847 0.97339858]\n",
      "‚úÖ Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.03      0.05       791\n",
      "           1       0.27      0.03      0.06      1155\n",
      "           2       0.00      0.00      0.00       272\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.52      0.12      0.20       124\n",
      "           5       0.59      0.29      0.39       580\n",
      "           6       0.18      0.03      0.05       319\n",
      "           7       0.00      0.00      0.00       186\n",
      "           8       0.28      0.03      0.05       740\n",
      "           9       0.09      0.00      0.01       249\n",
      "          10       0.00      0.00      0.00        30\n",
      "          11       0.25      0.00      0.01       208\n",
      "          12       0.00      0.00      0.00       222\n",
      "          13       0.00      0.00      0.00       128\n",
      "          14       0.50      0.35      0.41      3135\n",
      "          15       0.02      0.00      0.00       574\n",
      "          16       0.50      0.07      0.12        89\n",
      "          17       0.00      0.00      0.00        99\n",
      "          18       0.00      0.00      0.00       164\n",
      "          19       0.00      0.00      0.00       261\n",
      "          20       0.21      0.19      0.20       203\n",
      "          21       0.05      0.01      0.01       296\n",
      "          22       0.51      0.40      0.45      1247\n",
      "          23       0.42      0.27      0.33      1473\n",
      "          24       0.19      0.02      0.04      1229\n",
      "          25       0.13      0.01      0.01       288\n",
      "\n",
      "   micro avg       0.43      0.17      0.24     14068\n",
      "   macro avg       0.19      0.07      0.09     14068\n",
      "weighted avg       0.31      0.17      0.20     14068\n",
      " samples avg       0.20      0.17      0.18     14068\n",
      "\n",
      "\n",
      "üîç Evaluating model 10/18...\n",
      "‚úÖ Overall Accuracy: 0.2501779359430605\n",
      "‚úÖ F1 Score (Macro): 0.06535349768708676\n",
      "‚úÖ F1 Score (Micro): 0.2065860142136386\n",
      "‚úÖ Accuracy per label: [0.92206406 0.89466192 0.97508897 0.99911032 0.98647687 0.95\n",
      " 0.96565836 0.98309609 0.93220641 0.97758007 0.99733096 0.98122776\n",
      " 0.98016014 0.9883452  0.70533808 0.94733096 0.99163701 0.99119217\n",
      " 0.9841637  0.97651246 0.97891459 0.9727758  0.89741993 0.85996441\n",
      " 0.88683274 0.97375445]\n",
      "‚úÖ Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.01      0.01       791\n",
      "           1       0.24      0.01      0.02      1155\n",
      "           2       0.00      0.00      0.00       272\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.24      0.10      0.15       124\n",
      "           5       0.54      0.19      0.29       580\n",
      "           6       0.00      0.00      0.00       319\n",
      "           7       0.00      0.00      0.00       186\n",
      "           8       0.00      0.00      0.00       740\n",
      "           9       0.00      0.00      0.00       249\n",
      "          10       0.00      0.00      0.00        30\n",
      "          11       0.00      0.00      0.00       208\n",
      "          12       0.00      0.00      0.00       222\n",
      "          13       0.00      0.00      0.00       128\n",
      "          14       0.46      0.31      0.37      3135\n",
      "          15       0.00      0.00      0.00       574\n",
      "          16       0.14      0.01      0.02        89\n",
      "          17       0.00      0.00      0.00        99\n",
      "          18       0.00      0.00      0.00       164\n",
      "          19       0.00      0.00      0.00       261\n",
      "          20       0.19      0.05      0.08       203\n",
      "          21       0.14      0.01      0.01       296\n",
      "          22       0.56      0.35      0.43      1247\n",
      "          23       0.44      0.23      0.30      1473\n",
      "          24       0.21      0.01      0.02      1229\n",
      "          25       0.00      0.00      0.00       288\n",
      "\n",
      "   micro avg       0.44      0.14      0.21     14068\n",
      "   macro avg       0.12      0.05      0.07     14068\n",
      "weighted avg       0.27      0.14      0.17     14068\n",
      " samples avg       0.17      0.14      0.15     14068\n",
      "\n",
      "\n",
      "üîç Evaluating model 11/18...\n",
      "‚úÖ Overall Accuracy: 0.26263345195729537\n",
      "‚úÖ F1 Score (Macro): 0.0745512764553743\n",
      "‚úÖ F1 Score (Micro): 0.23995843076123669\n",
      "‚úÖ Accuracy per label: [0.92357651 0.89483986 0.97508897 0.99866548 0.97953737 0.94501779\n",
      " 0.96983986 0.98229537 0.92962633 0.97758007 0.99733096 0.98096085\n",
      " 0.9797153  0.98781139 0.72562278 0.94706406 0.99119217 0.9911032\n",
      " 0.98505338 0.97642349 0.97677936 0.96850534 0.89608541 0.86085409\n",
      " 0.88487544 0.97322064]\n",
      "‚úÖ Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.03      0.05       791\n",
      "           1       0.36      0.03      0.06      1155\n",
      "           2       0.00      0.00      0.00       272\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.08      0.08      0.08       124\n",
      "           5       0.41      0.16      0.23       580\n",
      "           6       0.05      0.00      0.01       319\n",
      "           7       0.07      0.01      0.01       186\n",
      "           8       0.12      0.01      0.02       740\n",
      "           9       0.00      0.00      0.00       249\n",
      "          10       0.00      0.00      0.00        30\n",
      "          11       0.00      0.00      0.00       208\n",
      "          12       0.00      0.00      0.00       222\n",
      "          13       0.09      0.01      0.01       128\n",
      "          14       0.51      0.38      0.44      3135\n",
      "          15       0.04      0.00      0.00       574\n",
      "          16       0.19      0.03      0.06        89\n",
      "          17       0.00      0.00      0.00        99\n",
      "          18       0.00      0.00      0.00       164\n",
      "          19       0.00      0.00      0.00       261\n",
      "          20       0.22      0.11      0.15       203\n",
      "          21       0.02      0.00      0.01       296\n",
      "          22       0.55      0.36      0.44      1247\n",
      "          23       0.45      0.31      0.37      1473\n",
      "          24       0.14      0.01      0.02      1229\n",
      "          25       0.00      0.00      0.00       288\n",
      "\n",
      "   micro avg       0.45      0.16      0.24     14068\n",
      "   macro avg       0.13      0.06      0.07     14068\n",
      "weighted avg       0.30      0.16      0.20     14068\n",
      " samples avg       0.20      0.17      0.18     14068\n",
      "\n",
      "\n",
      "üîç Evaluating model 12/18...\n",
      "‚úÖ Overall Accuracy: 0.26147686832740213\n",
      "‚úÖ F1 Score (Macro): 0.09873228441766103\n",
      "‚úÖ F1 Score (Micro): 0.25471227685249825\n",
      "‚úÖ Accuracy per label: [0.91886121 0.89243772 0.97535587 0.99848754 0.98496441 0.94928826\n",
      " 0.96699288 0.98176157 0.9230427  0.97704626 0.99733096 0.98104982\n",
      " 0.9794484  0.98718861 0.71975089 0.94653025 0.99128114 0.99119217\n",
      " 0.98434164 0.97580071 0.97411032 0.96939502 0.89172598 0.86103203\n",
      " 0.87927046 0.97259786]\n",
      "‚úÖ Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.04      0.06       791\n",
      "           1       0.41      0.11      0.17      1155\n",
      "           2       0.22      0.01      0.01       272\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.25      0.18      0.21       124\n",
      "           5       0.52      0.28      0.37       580\n",
      "           6       0.14      0.03      0.05       319\n",
      "           7       0.00      0.00      0.00       186\n",
      "           8       0.06      0.01      0.02       740\n",
      "           9       0.09      0.00      0.01       249\n",
      "          10       0.00      0.00      0.00        30\n",
      "          11       0.00      0.00      0.00       208\n",
      "          12       0.00      0.00      0.00       222\n",
      "          13       0.10      0.02      0.03       128\n",
      "          14       0.50      0.36      0.41      3135\n",
      "          15       0.03      0.00      0.00       574\n",
      "          16       0.29      0.07      0.11        89\n",
      "          17       0.00      0.00      0.00        99\n",
      "          18       0.00      0.00      0.00       164\n",
      "          19       0.00      0.00      0.00       261\n",
      "          20       0.23      0.19      0.21       203\n",
      "          21       0.02      0.00      0.01       296\n",
      "          22       0.52      0.36      0.42      1247\n",
      "          23       0.46      0.37      0.41      1473\n",
      "          24       0.19      0.03      0.06      1229\n",
      "          25       0.08      0.01      0.01       288\n",
      "\n",
      "   micro avg       0.43      0.18      0.25     14068\n",
      "   macro avg       0.16      0.08      0.10     14068\n",
      "weighted avg       0.31      0.18      0.22     14068\n",
      " samples avg       0.21      0.18      0.19     14068\n",
      "\n",
      "\n",
      "üîç Evaluating model 13/18...\n",
      "‚úÖ Overall Accuracy: 0.24030249110320284\n",
      "‚úÖ F1 Score (Macro): 0.12681214152810344\n",
      "‚úÖ F1 Score (Micro): 0.2639309648398054\n",
      "‚úÖ Accuracy per label: [0.91058719 0.88540925 0.97633452 0.99884342 0.98879004 0.95533808\n",
      " 0.96263345 0.97802491 0.92108541 0.97508897 0.99679715 0.98016014\n",
      " 0.97713523 0.9838968  0.70747331 0.94403915 0.99243772 0.99092527\n",
      " 0.98256228 0.97419929 0.97393238 0.96023132 0.86370107 0.85685053\n",
      " 0.86903915 0.96779359]\n",
      "‚úÖ Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.07      0.10       791\n",
      "           1       0.36      0.14      0.21      1155\n",
      "           2       0.67      0.04      0.08       272\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.48      0.19      0.28       124\n",
      "           5       0.61      0.38      0.47       580\n",
      "           6       0.08      0.03      0.04       319\n",
      "           7       0.04      0.02      0.02       186\n",
      "           8       0.07      0.02      0.03       740\n",
      "           9       0.00      0.00      0.00       249\n",
      "          10       0.00      0.00      0.00        30\n",
      "          11       0.00      0.00      0.00       208\n",
      "          12       0.05      0.01      0.02       222\n",
      "          13       0.04      0.02      0.02       128\n",
      "          14       0.47      0.38      0.42      3135\n",
      "          15       0.09      0.01      0.02       574\n",
      "          16       0.54      0.30      0.39        89\n",
      "          17       0.00      0.00      0.00        99\n",
      "          18       0.00      0.00      0.00       164\n",
      "          19       0.03      0.00      0.01       261\n",
      "          20       0.27      0.27      0.27       203\n",
      "          21       0.05      0.03      0.03       296\n",
      "          22       0.38      0.38      0.38      1247\n",
      "          23       0.44      0.37      0.40      1473\n",
      "          24       0.17      0.05      0.08      1229\n",
      "          25       0.08      0.02      0.04       288\n",
      "\n",
      "   micro avg       0.37      0.20      0.26     14068\n",
      "   macro avg       0.20      0.11      0.13     14068\n",
      "weighted avg       0.30      0.20      0.23     14068\n",
      " samples avg       0.23      0.20      0.21     14068\n",
      "\n",
      "\n",
      "üîç Evaluating model 14/18...\n",
      "‚úÖ Overall Accuracy: 0.2600533807829182\n",
      "‚úÖ F1 Score (Macro): 0.06784131161924514\n",
      "‚úÖ F1 Score (Micro): 0.20793554439600465\n",
      "‚úÖ Accuracy per label: [0.92864769 0.89243772 0.97491103 0.99911032 0.98914591 0.95160142\n",
      " 0.97144128 0.98336299 0.9338968  0.97784698 0.99733096 0.98149466\n",
      " 0.98024911 0.9886121  0.72909253 0.94813167 0.99234875 0.99119217\n",
      " 0.98523132 0.97677936 0.9747331  0.96895018 0.87597865 0.86734875\n",
      " 0.88950178 0.97366548]\n",
      "‚úÖ Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.00      0.01       791\n",
      "           1       0.32      0.04      0.07      1155\n",
      "           2       0.00      0.00      0.00       272\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.67      0.03      0.06       124\n",
      "           5       0.66      0.13      0.21       580\n",
      "           6       0.25      0.00      0.01       319\n",
      "           7       0.00      0.00      0.00       186\n",
      "           8       0.29      0.00      0.01       740\n",
      "           9       0.00      0.00      0.00       249\n",
      "          10       0.00      0.00      0.00        30\n",
      "          11       0.00      0.00      0.00       208\n",
      "          12       0.00      0.00      0.00       222\n",
      "          13       0.00      0.00      0.00       128\n",
      "          14       0.52      0.30      0.38      3135\n",
      "          15       0.00      0.00      0.00       574\n",
      "          16       1.00      0.03      0.07        89\n",
      "          17       0.00      0.00      0.00        99\n",
      "          18       0.00      0.00      0.00       164\n",
      "          19       0.00      0.00      0.00       261\n",
      "          20       0.24      0.18      0.21       203\n",
      "          21       0.07      0.01      0.02       296\n",
      "          22       0.42      0.29      0.34      1247\n",
      "          23       0.49      0.26      0.34      1473\n",
      "          24       0.36      0.01      0.03      1229\n",
      "          25       0.17      0.01      0.01       288\n",
      "\n",
      "   micro avg       0.46      0.13      0.21     14068\n",
      "   macro avg       0.22      0.05      0.07     14068\n",
      "weighted avg       0.34      0.13      0.17     14068\n",
      " samples avg       0.16      0.14      0.15     14068\n",
      "\n",
      "\n",
      "üîç Evaluating model 15/18...\n",
      "‚úÖ Overall Accuracy: 0.24092526690391458\n",
      "‚úÖ F1 Score (Macro): 0.09652289036215933\n",
      "‚úÖ F1 Score (Micro): 0.24667300380228138\n",
      "‚úÖ Accuracy per label: [0.91432384 0.88807829 0.9752669  0.99866548 0.95791815 0.94857651\n",
      " 0.96725979 0.97846975 0.92535587 0.97615658 0.99724199 0.98024911\n",
      " 0.97419929 0.98674377 0.71370107 0.9455516  0.98905694 0.9908363\n",
      " 0.98460854 0.97544484 0.97295374 0.96725979 0.89483986 0.85587189\n",
      " 0.86628114 0.96494662]\n",
      "‚úÖ Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.04      0.06       791\n",
      "           1       0.29      0.06      0.10      1155\n",
      "           2       0.00      0.00      0.00       272\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.06      0.19      0.09       124\n",
      "           5       0.50      0.25      0.34       580\n",
      "           6       0.11      0.02      0.04       319\n",
      "           7       0.17      0.08      0.11       186\n",
      "           8       0.15      0.03      0.05       740\n",
      "           9       0.09      0.01      0.01       249\n",
      "          10       0.00      0.00      0.00        30\n",
      "          11       0.00      0.00      0.00       208\n",
      "          12       0.03      0.01      0.01       222\n",
      "          13       0.00      0.00      0.00       128\n",
      "          14       0.48      0.35      0.41      3135\n",
      "          15       0.03      0.00      0.00       574\n",
      "          16       0.17      0.10      0.13        89\n",
      "          17       0.00      0.00      0.00        99\n",
      "          18       0.00      0.00      0.00       164\n",
      "          19       0.06      0.00      0.01       261\n",
      "          20       0.22      0.20      0.21       203\n",
      "          21       0.03      0.01      0.01       296\n",
      "          22       0.53      0.40      0.46      1247\n",
      "          23       0.44      0.39      0.41      1473\n",
      "          24       0.12      0.03      0.05      1229\n",
      "          25       0.02      0.01      0.01       288\n",
      "\n",
      "   micro avg       0.37      0.18      0.25     14068\n",
      "   macro avg       0.14      0.08      0.10     14068\n",
      "weighted avg       0.29      0.18      0.22     14068\n",
      " samples avg       0.21      0.19      0.19     14068\n",
      "\n",
      "\n",
      "üîç Evaluating model 16/18...\n",
      "‚úÖ Overall Accuracy: 0.23683274021352313\n",
      "‚úÖ F1 Score (Macro): 0.08847820356181645\n",
      "‚úÖ F1 Score (Micro): 0.23917698538311144\n",
      "‚úÖ Accuracy per label: [0.91912811 0.88487544 0.97508897 0.99759786 0.95765125 0.94003559\n",
      " 0.95213523 0.98007117 0.91886121 0.97464413 0.99697509 0.98096085\n",
      " 0.97686833 0.98505338 0.70711744 0.94430605 0.9816726  0.99039146\n",
      " 0.98380783 0.97508897 0.97322064 0.96503559 0.8866548  0.85809609\n",
      " 0.8725089  0.9680605 ]\n",
      "‚úÖ Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.06      0.09       791\n",
      "           1       0.27      0.07      0.11      1155\n",
      "           2       0.00      0.00      0.00       272\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.05      0.16      0.08       124\n",
      "           5       0.35      0.19      0.25       580\n",
      "           6       0.06      0.05      0.06       319\n",
      "           7       0.00      0.00      0.00       186\n",
      "           8       0.07      0.02      0.03       740\n",
      "           9       0.00      0.00      0.00       249\n",
      "          10       0.00      0.00      0.00        30\n",
      "          11       0.12      0.00      0.01       208\n",
      "          12       0.09      0.02      0.03       222\n",
      "          13       0.00      0.00      0.00       128\n",
      "          14       0.47      0.40      0.43      3135\n",
      "          15       0.07      0.01      0.01       574\n",
      "          16       0.05      0.07      0.06        89\n",
      "          17       0.00      0.00      0.00        99\n",
      "          18       0.05      0.01      0.01       164\n",
      "          19       0.00      0.00      0.00       261\n",
      "          20       0.24      0.23      0.24       203\n",
      "          21       0.06      0.02      0.03       296\n",
      "          22       0.48      0.33      0.39      1247\n",
      "          23       0.45      0.34      0.38      1473\n",
      "          24       0.19      0.05      0.08      1229\n",
      "          25       0.03      0.01      0.01       288\n",
      "\n",
      "   micro avg       0.35      0.18      0.24     14068\n",
      "   macro avg       0.13      0.08      0.09     14068\n",
      "weighted avg       0.28      0.18      0.21     14068\n",
      " samples avg       0.21      0.19      0.19     14068\n",
      "\n",
      "\n",
      "üîç Evaluating model 17/18...\n",
      "‚úÖ Overall Accuracy: 0.24172597864768683\n",
      "‚úÖ F1 Score (Macro): 0.07175053818692863\n",
      "‚úÖ F1 Score (Micro): 0.21259302264210694\n",
      "‚úÖ Accuracy per label: [0.91681495 0.89199288 0.97517794 0.99937722 0.98336299 0.94679715\n",
      " 0.96788256 0.98274021 0.93220641 0.9774911  0.99733096 0.98131673\n",
      " 0.97935943 0.98825623 0.71281139 0.94724199 0.99137011 0.9911032\n",
      " 0.9844306  0.97633452 0.97455516 0.97117438 0.89475089 0.85747331\n",
      " 0.87909253 0.97224199]\n",
      "‚úÖ Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.01      0.02       791\n",
      "           1       0.26      0.03      0.05      1155\n",
      "           2       0.00      0.00      0.00       272\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.18      0.14      0.15       124\n",
      "           5       0.46      0.18      0.25       580\n",
      "           6       0.00      0.00      0.00       319\n",
      "           7       0.00      0.00      0.00       186\n",
      "           8       0.13      0.01      0.01       740\n",
      "           9       0.00      0.00      0.00       249\n",
      "          10       0.00      0.00      0.00        30\n",
      "          11       0.00      0.00      0.00       208\n",
      "          12       0.00      0.00      0.00       222\n",
      "          13       0.17      0.01      0.01       128\n",
      "          14       0.48      0.32      0.38      3135\n",
      "          15       0.00      0.00      0.00       574\n",
      "          16       0.00      0.00      0.00        89\n",
      "          17       0.00      0.00      0.00        99\n",
      "          18       0.00      0.00      0.00       164\n",
      "          19       0.00      0.00      0.00       261\n",
      "          20       0.20      0.14      0.16       203\n",
      "          21       0.15      0.02      0.04       296\n",
      "          22       0.55      0.30      0.39      1247\n",
      "          23       0.43      0.29      0.35      1473\n",
      "          24       0.13      0.02      0.03      1229\n",
      "          25       0.07      0.01      0.01       288\n",
      "\n",
      "   micro avg       0.41      0.14      0.21     14068\n",
      "   macro avg       0.13      0.06      0.07     14068\n",
      "weighted avg       0.27      0.14      0.18     14068\n",
      " samples avg       0.17      0.15      0.15     14068\n",
      "\n",
      "\n",
      "üîç Evaluating model 18/18...\n",
      "‚úÖ Overall Accuracy: 0.23896797153024912\n",
      "‚úÖ F1 Score (Macro): 0.07725145920630415\n",
      "‚úÖ F1 Score (Micro): 0.22849558425647046\n",
      "‚úÖ Accuracy per label: [0.92108541 0.88843416 0.97535587 0.99875445 0.9844306  0.94919929\n",
      " 0.96859431 0.98185053 0.92624555 0.97758007 0.99733096 0.98104982\n",
      " 0.97838078 0.98709964 0.70124555 0.94626335 0.99119217 0.9911032\n",
      " 0.9841637  0.97606762 0.97820285 0.97081851 0.90177936 0.84955516\n",
      " 0.87740214 0.97224199]\n",
      "‚úÖ Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.03      0.06       791\n",
      "           1       0.20      0.03      0.05      1155\n",
      "           2       0.00      0.00      0.00       272\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.14      0.08      0.10       124\n",
      "           5       0.52      0.18      0.27       580\n",
      "           6       0.03      0.00      0.01       319\n",
      "           7       0.09      0.01      0.02       186\n",
      "           8       0.09      0.01      0.02       740\n",
      "           9       0.00      0.00      0.00       249\n",
      "          10       0.00      0.00      0.00        30\n",
      "          11       0.00      0.00      0.00       208\n",
      "          12       0.00      0.00      0.00       222\n",
      "          13       0.05      0.01      0.01       128\n",
      "          14       0.46      0.36      0.40      3135\n",
      "          15       0.08      0.01      0.01       574\n",
      "          16       0.14      0.02      0.04        89\n",
      "          17       0.00      0.00      0.00        99\n",
      "          18       0.00      0.00      0.00       164\n",
      "          19       0.10      0.00      0.01       261\n",
      "          20       0.28      0.13      0.18       203\n",
      "          21       0.08      0.01      0.02       296\n",
      "          22       0.59      0.36      0.45      1247\n",
      "          23       0.39      0.27      0.32      1473\n",
      "          24       0.14      0.02      0.04      1229\n",
      "          25       0.04      0.00      0.01       288\n",
      "\n",
      "   micro avg       0.41      0.16      0.23     14068\n",
      "   macro avg       0.14      0.06      0.08     14068\n",
      "weighted avg       0.28      0.16      0.19     14068\n",
      " samples avg       0.19      0.16      0.17     14068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_df = evaluate_models(df_physionet_train,df_physionet_test, hyperparams_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_k</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>gamma</th>\n",
       "      <th>latent_dimension</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>0.240302</td>\n",
       "      <td>0.263931</td>\n",
       "      <td>0.126812</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.005</td>\n",
       "      <td>16</td>\n",
       "      <td>0.002</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.274555</td>\n",
       "      <td>0.264767</td>\n",
       "      <td>0.109891</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.005</td>\n",
       "      <td>12</td>\n",
       "      <td>0.002</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>0.261477</td>\n",
       "      <td>0.254712</td>\n",
       "      <td>0.098732</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.300</td>\n",
       "      <td>12</td>\n",
       "      <td>0.002</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>0.240925</td>\n",
       "      <td>0.246673</td>\n",
       "      <td>0.096523</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.050</td>\n",
       "      <td>16</td>\n",
       "      <td>0.002</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.265925</td>\n",
       "      <td>0.241418</td>\n",
       "      <td>0.092228</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.050</td>\n",
       "      <td>12</td>\n",
       "      <td>0.002</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>0.270463</td>\n",
       "      <td>0.233458</td>\n",
       "      <td>0.089847</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.005</td>\n",
       "      <td>8</td>\n",
       "      <td>0.002</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>0.236833</td>\n",
       "      <td>0.239177</td>\n",
       "      <td>0.088478</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.100</td>\n",
       "      <td>16</td>\n",
       "      <td>0.002</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>0.240125</td>\n",
       "      <td>0.232246</td>\n",
       "      <td>0.083682</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.300</td>\n",
       "      <td>8</td>\n",
       "      <td>0.002</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9</td>\n",
       "      <td>0.238968</td>\n",
       "      <td>0.228496</td>\n",
       "      <td>0.077251</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.300</td>\n",
       "      <td>16</td>\n",
       "      <td>0.002</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.262633</td>\n",
       "      <td>0.239958</td>\n",
       "      <td>0.074551</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.200</td>\n",
       "      <td>12</td>\n",
       "      <td>0.002</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0.253203</td>\n",
       "      <td>0.219737</td>\n",
       "      <td>0.074020</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.200</td>\n",
       "      <td>8</td>\n",
       "      <td>0.002</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11</td>\n",
       "      <td>0.241726</td>\n",
       "      <td>0.212593</td>\n",
       "      <td>0.071751</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.200</td>\n",
       "      <td>16</td>\n",
       "      <td>0.002</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11</td>\n",
       "      <td>0.260053</td>\n",
       "      <td>0.207936</td>\n",
       "      <td>0.067841</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.010</td>\n",
       "      <td>16</td>\n",
       "      <td>0.002</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>0.250178</td>\n",
       "      <td>0.206586</td>\n",
       "      <td>0.065353</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.100</td>\n",
       "      <td>12</td>\n",
       "      <td>0.002</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>0.235676</td>\n",
       "      <td>0.189804</td>\n",
       "      <td>0.062447</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.100</td>\n",
       "      <td>8</td>\n",
       "      <td>0.002</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>0.231851</td>\n",
       "      <td>0.181614</td>\n",
       "      <td>0.058492</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.010</td>\n",
       "      <td>12</td>\n",
       "      <td>0.002</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0.237811</td>\n",
       "      <td>0.168639</td>\n",
       "      <td>0.053105</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.050</td>\n",
       "      <td>8</td>\n",
       "      <td>0.002</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>0.240391</td>\n",
       "      <td>0.158009</td>\n",
       "      <td>0.046865</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.010</td>\n",
       "      <td>8</td>\n",
       "      <td>0.002</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    best_k  accuracy  f1_micro  f1_macro  alpha  beta  gamma  \\\n",
       "12       5  0.240302  0.263931  0.126812   0.05  0.02  0.005   \n",
       "6        7  0.274555  0.264767  0.109891   0.05  0.02  0.005   \n",
       "11       9  0.261477  0.254712  0.098732   0.30  1.20  0.300   \n",
       "14       7  0.240925  0.246673  0.096523   0.05  0.20  0.050   \n",
       "8        9  0.265925  0.241418  0.092228   0.05  0.20  0.050   \n",
       "0       11  0.270463  0.233458  0.089847   0.05  0.02  0.005   \n",
       "15       5  0.236833  0.239177  0.088478   0.10  0.40  0.100   \n",
       "5       11  0.240125  0.232246  0.083682   0.30  1.20  0.300   \n",
       "17       9  0.238968  0.228496  0.077251   0.30  1.20  0.300   \n",
       "10      11  0.262633  0.239958  0.074551   0.20  0.80  0.200   \n",
       "4       11  0.253203  0.219737  0.074020   0.20  0.80  0.200   \n",
       "16      11  0.241726  0.212593  0.071751   0.20  0.80  0.200   \n",
       "13      11  0.260053  0.207936  0.067841   0.01  0.04  0.010   \n",
       "9       11  0.250178  0.206586  0.065353   0.10  0.40  0.100   \n",
       "3       11  0.235676  0.189804  0.062447   0.10  0.40  0.100   \n",
       "7       11  0.231851  0.181614  0.058492   0.01  0.04  0.010   \n",
       "2       11  0.237811  0.168639  0.053105   0.05  0.20  0.050   \n",
       "1       11  0.240391  0.158009  0.046865   0.01  0.04  0.010   \n",
       "\n",
       "    latent_dimension  learning_rate  epochs  \n",
       "12                16          0.002     100  \n",
       "6                 12          0.002     100  \n",
       "11                12          0.002     100  \n",
       "14                16          0.002     100  \n",
       "8                 12          0.002     100  \n",
       "0                  8          0.002     100  \n",
       "15                16          0.002     100  \n",
       "5                  8          0.002     100  \n",
       "17                16          0.002     100  \n",
       "10                12          0.002     100  \n",
       "4                  8          0.002     100  \n",
       "16                16          0.002     100  \n",
       "13                16          0.002     100  \n",
       "9                 12          0.002     100  \n",
       "3                  8          0.002     100  \n",
       "7                 12          0.002     100  \n",
       "2                  8          0.002     100  \n",
       "1                  8          0.002     100  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df = results_df.drop(columns=[\"model_index\"])\n",
    "\n",
    "display(results_df.sort_values(by=\"f1_macro\", ascending=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
